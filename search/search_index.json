{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Neurotech Development Kit","text":"<p>The Neurotech Development Kit (NDK) is an open-source, community-driven software library designed to lower the barrier of entry to the next generation of neurotechnology for current researchers and companies. It also enables software developers without access to hardware and human subjects to solve open problems in the field. The initial release of NDK provides support for transcranial focused ultrasound stimulation, along with comprehensive documentation, API flexibility, and 2D/3D visualizations. Future areas of interest may include photoacoustic and optical whole-brain imaging.</p> <p>As a community-driven project, we encourage you to contribute code, feedback, and features to help accelerate the development of transformative neurotechnology.</p> <p></p> <p>Check out the NDK documentation page.</p>"},{"location":"#running","title":"Running","text":""},{"location":"#docker","title":"Docker","text":"<p>You can run <code>neurotechdevkit</code> inside a docker container with just a couple of steps:</p> <ol> <li> <p>Install docker</p> </li> <li> <p>Run the following command:</p> <pre><code>docker run -p 8888:8888 -it ghcr.io/agencyenterprise/neurotechdevkit:latest\n</code></pre> <p>The command above will start a Jupyter notebook server with example notebooks you can use to explore <code>neurotechdevkit</code>. Use the printed URL to open it in your browser or connect to it using your IDE.</p> <p>All changes you make to these files will be lost once you stop the docker container.</p> </li> </ol> <p>Note:</p> <p>You can have persisting Jupyter notebooks by running    <pre><code>docker run -p 8888:8888  -v $(pwd)/notebooks:/ndk/notebooks -it ghcr.io/agencyenterprise/neurotechdevkit:latest\n</code></pre>    The command above will create a folder <code>notebooks</code> in your current directory where you can put your jupyter notebooks.</p> <p>We recommend downloading the <code>.zip</code> file with example notebooks from this link, and extracting it into your local <code>notebooks</code> folder so you can access them from the docker.</p>"},{"location":"#local-installation","title":"Local installation","text":"<p>To install and run neurotechdevkit locally check the installation page.</p>"},{"location":"#usage","title":"Usage","text":"<pre><code>import neurotechdevkit as ndk\nscenario = ndk.make('scenario-0-v0')\nresult = scenario.simulate_steady_state()\nresult.render_steady_state_amplitudes(show_material_outlines=False)\n</code></pre>"},{"location":"#acknowledgements","title":"Acknowledgements","text":"<p>Thanks to Fred Ehrsam for supporting this project, Quintin Frerichs and Milan Cvitkovic for providing direction, and to Sumner Norman for his ultrasound and neuroscience expertise. Thanks to Stride for facilitating ultrasound simulations and providing an MIT license for usage within NDK, Devito for providing the backend solver, Napari for great 3D visualization, and to Jean-Francois Aubry, et al. for the basis of the simulation scenarios.</p>"},{"location":"contributing/","title":"Contributing","text":"<p>You can contribute to NDK by creating GitHub issues or by submitting pull requests.</p>"},{"location":"contributing/#reporting-issues","title":"Reporting issues","text":"<p>Feel free to open an issue if you would like to discuss a new feature request or report a bug. When creating a bug report, please include as much information as possible to help us reproduce the bug as well as what the actual and expected behavior is.</p>"},{"location":"contributing/#contributing-code","title":"Contributing code","text":""},{"location":"contributing/#standards","title":"Standards","text":"<p>To ensure efficient collaborative development, a variety of standards are utilized in this project.</p> <ul> <li>Black code formatter is used.</li> <li>Flake8 is used for linting.</li> <li>isort is used for sorting the imports.</li> <li>pyright is used for static type checking.</li> <li>Type hinting is used.<ul> <li>And checked using mypy.</li> </ul> </li> <li>Pylint is used for spell checking.</li> </ul>"},{"location":"contributing/#preparing-your-environment","title":"Preparing your environment","text":"<p>Start by cloning the repository:</p> <pre><code>git clone https://github.com/agencyenterprise/neurotechdevkit.git\ncd neurotechdevkit\n</code></pre>"},{"location":"contributing/#running-on-docker","title":"Running on docker","text":"<p>If you don't want to install NDK's dependencies on your machine, you can run it in a container:</p> <ul> <li> <p>Install Docker.</p> </li> <li> <p>Run the container, which will start a jupyter notebook server:    <pre><code>docker compose up\n</code></pre></p> </li> <li> <p>Connect to the jupyter notebook directly in your browser or with your IDE.</p> </li> </ul>"},{"location":"contributing/#running-locally","title":"Running locally","text":"<p>This project requires Python <code>&gt;=3.9</code> and <code>&lt;3.11</code> to be installed. You can find the Python version you have installed by running <code>python --version</code> in a terminal. If you don't have Python installed or are running an unsupported version, you can download a supported version from python.org.</p> <p>We use poetry to manage dependencies and virtual environments. Follow the instructions from poetry's documentation to install it if you don't have it on your system.</p> <p>Install the dependencies by running the following command in a shell within the project directory:</p> <pre><code>poetry install\n</code></pre> <p>This will resolve and install the dependencies from <code>poetry.lock</code> and will install the <code>neurotechdevkit</code> package in editable mode.</p> <p>Install stride with:</p> <pre><code>$ poetry run pip install git+https://github.com/trustimaging/stride\n</code></pre> <p>Follow the steps described in Setting up a compiler.</p>"},{"location":"contributing/#using-the-environment","title":"Using the environment","text":"<p>If you are not already using a virtual environment, <code>poetry</code> will create one for you by default. You will need to use this virtual env when using or working on the package.</p> <p>Activate the environment directly via:</p> <pre><code>poetry shell\n</code></pre> <p>If you are already using your own virtual environment, you should not need to change anything.</p>"},{"location":"contributing/#code-requirements-and-conventions","title":"Code requirements and conventions","text":"<p>Note</p> <p>The following commands require <code>GNU make</code> to be installed, on Windows you can install it with Chocolatey:</p> <p><code>choco install make</code></p> <p>Before opening a pull request, please make sure that all of the following requirements are met:</p> <ol> <li>all unit and integration tests are passing:    <pre><code>make test\n</code></pre></li> <li>the code is linted and formatted:    <pre><code>make lint\n</code></pre></li> <li>type hinting is used on all function and method parameters and return values, excluding tests</li> <li>docstring usage conforms to the following:<ol> <li>all docstrings should follow PEP257 Docstring Conventions</li> <li>all public API classes, functions, methods, and properties have docstrings and follow the Google Python Style Guide</li> <li>docstrings on private objects are not required, but are encouraged where they would significantly aid understanding</li> </ol> </li> <li>testing is done using the pytest library, and test coverage should not unnecessarily decrease.</li> </ol>"},{"location":"contributing/#process","title":"Process","text":""},{"location":"contributing/#versioning","title":"Versioning","text":"<p>NDK uses semantic versioning to identify its releases.</p> <p>We use the release on push github action to generate the new version for each release. This github action generates the version based on a pull request label assigned before merge. The supported labels are:</p> <ul> <li><code>release-patch</code></li> <li><code>release-minor</code></li> <li><code>release-major</code></li> <li><code>norelease</code></li> </ul>"},{"location":"contributing/#automatic-release","title":"Automatic release","text":"<p>Merged pull requests with one of the labels <code>release-patch</code>, <code>release-minor</code> or <code>release-major</code> will trigger a release job on CI.</p> <p>The release job will:</p> <ol> <li>generate a new package version using semantic versioning provided by release on push</li> <li>update the <code>pyproject.toml</code> version using <code>poetry</code></li> <li>commit the updated <code>pyproject.toml</code> file using the git-auto-commit action</li> <li>push the package to pypi using poetry publish</li> <li>build a new docker image and tag it with the previously generated semantic version</li> </ol> <p>Pull requests merged with the tag <code>norelease</code> will not trigger any of the actions listed above.</p>"},{"location":"contributing/#gallery-of-examples","title":"Gallery of examples","text":"<p>The examples you can find in the official documentation are python scripts executed in CI.</p> <p>Running these scripts is a resource intensive and time consuming task, for this reason we are using CircleCI instead of Github Actions (as we can choose a more powerful machine to execute the job).</p>"},{"location":"contributing/#checking-ndk-documentation-on-ci","title":"Checking NDK documentation on CI","text":"<p>All pull requests trigger a CI job that builds the documentation and makes the built files available.</p> <p>To check the generated documentation in a pull request:</p> <ol> <li>Scroll to the bottom of the page and click on the <code>Show all checks</code> link.</li> <li>Click on the details link of the <code>Check the rendered docs here!</code> job.        </li> </ol> <p>Note</p> <p>The <code>Examples</code> section is not properly rendered when the documentation is built   on CI. The links of the thumbnails in <code>gallery/index.html</code> point to broken paths,   in order to check one of the examples you will have to click on the left panel,   as shown in the image below:       Within each example, the outputs of cells are also not properly displayed.</p>"},{"location":"conventions/","title":"Conventions","text":"<p>Below are some of the conventions that we are or would like to follow in NDK. This page should be considered incomplete as there are conventions being followed in the codebase which are not described here. We should add to this doc incrementally as part of relevant PRs.</p>"},{"location":"conventions/#units-of-measurement","title":"Units of Measurement","text":"<p>Unit of measurement (uom) labels should be used wherever relevant throughout docstrings, documentation, plots, and textual output.</p> <p>For internal methods and computation steps, always express values using uom without scale prefixes (eg. m rather than mm or km). When values are provided by the user (via parameters) or shown directly to the user (via plots or textual output) scaling prefixes can be used if there is a clear convention in the ultrasound community for which prefix should be used.</p>"},{"location":"conventions/#in-docstrings","title":"In docstrings","text":"<ul> <li>include units for all parameters and return values that have meaningful units<ul> <li>put the uom in parentheses after \"in\". Eg: \"distance (in meters)\"</li> </ul> </li> <li>when the uom has an SI name, write out the name fully with the correct capitalization (eg. seconds, meters, pascals)</li> <li>when the uom does not have an SI name, use the equation specifying the uom (eg. m/s, W/cm\u00b2)</li> </ul>"},{"location":"conventions/#in-plots","title":"In plots","text":"<ul> <li>for axis labels, use the uom abbreviation in parentheses. eg: \"Pressure (Pa)\"</li> </ul>"},{"location":"conventions/#for-metrics","title":"For metrics","text":"<ul> <li>include a specific uom in the output for each metric</li> </ul>"},{"location":"conventions/#adding-to-conventions","title":"Adding to Conventions","text":"<p>Whenever new conventions are used, they should be added to this document within the PR where the conventions were first added.</p> <p>Whenever existing conventions are discovered or refined (such as through PR review discussion), the conventions should be added or updated in this document as part of that PR.</p>"},{"location":"installation/","title":"Installation","text":"<p>You can run NDK without installing the package using docker, as shown here. However, if you'd like to install it, please follow the instructions below.</p> Before installing on Windows <ol> <li> <p>Install Ubuntu on WSL.</p> </li> <li> <p>Follow the the <code>Linux</code> steps described in this page inside your Ubuntu shell.</p> </li> </ol> <p><code>neurotechdevkit</code> requires Python <code>&gt;=3.9</code> and <code>&lt;3.11</code> to be installed. You can find which Python version you have installed by running <code>python --version</code> in a terminal.</p> <p>If you don't have Python installed, or you are running an unsupported version, you can download it from python.org. Python environment managers like pyenv, conda, and poetry are all perfectly suitable as well.</p> Before installing on Linux <ol> <li> <p>In order to install <code>neurotechdevkit</code> you must first install <code>g++</code> and the <code>python-dev</code> package for your python version.</p> <p>Both packages can be installed with: <pre><code>apt-get install -y g++ python3.10-dev\n</code></pre></p> <p>Important: You must replace <code>3.10</code> with your python version when running the command above.</p> </li> </ol> <p>You can install the <code>neurotechdevkit</code> package using:</p> <pre><code>pip install neurotechdevkit\n</code></pre> <p>You also have to install stride, it can be done running:</p> <pre><code>pip install git+https://github.com/trustimaging/stride\n</code></pre>"},{"location":"installation/#setting-up-a-compiler","title":"Setting up a compiler","text":"<p>NDK uses devito to perform the heavy computational operations. Devito generates, compiles and runs C code to achieve better performance. The compiler used by Devito has to be selected, and paths for the linker might also be added as environment variables.</p> <p>As a last step before running NDK, follow the instructions below depending on your OS.</p> Before running on MacOS <p>The two main compiler options for MacOS are clang and gcc.</p> Before running on Linux <ol> <li> <p>Export the <code>DEVITO_ARCH</code> environment variable, or add it to your shell profile:</p> <pre><code>export DEVITO_ARCH=\"gcc\"\n</code></pre> <p>The supported values for <code>DEVITO_ARCH</code> are: <code>'custom', 'gnu', 'gcc', 'clang', 'aomp', 'pgcc', 'pgi', 'nvc', 'nvc++', 'nvidia', 'cuda', 'osx', 'intel', 'icpc', 'icc', 'intel-knl', 'knl', 'dpcpp', 'gcc-4.9', 'gcc-5', 'gcc-6', 'gcc-7', 'gcc-8', 'gcc-9', 'gcc-10', 'gcc-11'</code>.</p> </li> </ol> <p>Note</p> <p>After installing <code>neurotechdevkit</code> you can use Jupyter to explore the package.</p> <p>To get started, we recommend downloading the example notebooks from this link.</p> <p>On Linux you can download and extract the notebooks running the following commands:</p> <ol> <li><code>sudo apt-get update &amp;&amp; sudo apt-get install -y unzip wget</code></li> <li><code>wget \"https://agencyenterprise.github.io/neurotechdevkit/generated/gallery/gallery_jupyter.zip\" -O temp.zip &amp;&amp; unzip temp.zip &amp;&amp; rm temp.zip</code></li> </ol>"},{"location":"installation/#clang","title":"clang","text":"<p>If you prefer to use clang you will have to install <code>libomp</code> and <code>llvm</code>, you will also have to export a few environment variables needed by the compiler.</p> <ol> <li> <p>Install libomp</p> <pre><code>brew install libomp\n</code></pre> </li> <li> <p>Run the following command to export a new environment variable <code>CPATH</code> with the path for <code>libomp</code> headers:</p> <pre><code>echo 'export CPATH=\"'$(brew --prefix)'/opt/libomp/include\"' &gt;&gt; ~/.zshrc\n</code></pre> </li> <li> <p>Install <code>llvm</code>:</p> <pre><code>brew install llvm\n</code></pre> </li> <li> <p>Run the following commands to export the <code>llvm</code> environment variables:</p> <pre><code>echo 'export PATH=\"'$(brew --prefix)'/opt/llvm/bin:$PATH\"' &gt;&gt; ~/.zshrc\necho 'export LDFLAGS=\"-L'$(brew --prefix)'/opt/llvm/lib\"' &gt;&gt; ~/.zshrc\necho 'export CPPFLAGS=\"-I'$(brew --prefix)'/opt/llvm/include\"' &gt;&gt; ~/.zshrc\n</code></pre> </li> <li> <p>The following command will export the <code>DEVITO_ARCH</code> environment variable:</p> <pre><code>echo 'export DEVITO_ARCH=\"clang\"' &gt;&gt; ~/.zshrc\n</code></pre> </li> <li> <p>Load the modified zsh configuration file:</p> <pre><code>source ~/.zshrc\n</code></pre> </li> </ol>"},{"location":"installation/#gcc","title":"gcc","text":"<p>On MacOS the <code>gcc</code> executable is a symbolic link to <code>clang</code>, so by defining DEVITO_ARCH=gcc devito will try to add <code>gcc</code> flags to the <code>clang</code> compiler, and the compilation will most probably fail.</p> <p>You can tell devito to use the correct <code>gcc</code> compiler doing the following:</p> <ol> <li> <p>Install gcc-11</p> <pre><code>brew install gcc@11\n</code></pre> </li> <li> <p>Run the command that exports the <code>DEVITO_ARCH</code> environment variable:</p> <pre><code>echo 'export DEVITO_ARCH=\"gcc-11\"' &gt;&gt; ~/.zshrc\n</code></pre> </li> <li> <p>Load the modified zsh configuration file:</p> <pre><code>source ~/.zshrc\n</code></pre> </li> </ol>"},{"location":"api/make/","title":"NDK Interface","text":""},{"location":"api/make/#neurotechdevkit.make","title":"<code>neurotechdevkit.make(scenario_id, complexity='fast')</code>","text":"<p>Initialize a scenario and return an object which represents the simulation.</p> <p>Parameters:</p> Name Type Description Default <code>scenario_id</code> <code>str</code> <p>the id of the scenario to load. Supported scenarios are:</p> <ul> <li>Scenario 0</li> <li>Scenario 1 2D</li> <li>Scenario 1 3D</li> <li>Scenario 2 2D</li> <li>Scenario 2 3D</li> </ul> required <code>complexity</code> <code>str</code> <p>allow the user to choose from a few pre-selected options for parameters such as PPP and PPW that determine the compute, memory, and time requirements of a simulation as well as the accuracy of the simulation results. Defaults to \"fast\".</p> <code>'fast'</code> <p>Raises:</p> Type Description <code>ScenarioNotFoundError</code> <p>Raised when the scenario id is not found.</p> <p>Returns:</p> Type Description <code>scenarios.Scenario</code> <p>An object representing the simulation.</p>"},{"location":"api/results/","title":"Results","text":""},{"location":"api/results/#neurotechdevkit.results.PulsedResult","title":"<code>PulsedResult</code>  <code>dataclass</code>","text":"<p>         Bases: <code>Result</code></p> <p>A base container for holding the results of a pulsed simulation.</p> <p>This class should not be instantiated, use PulsedResult2D or PulsedResult3D.</p> <p>Parameters:</p> Name Type Description Default <code>scenario</code> <code>scenario.Scenario</code> <p>the scenario from which this result came.</p> required <code>center_frequency</code> <code>float</code> <p>the center frequency (in hertz) of the sources.</p> required <code>effective_dt</code> <code>float</code> <p>the effective time step (in seconds) along the time axis of the wavefield. This can differ from the simulation dt if the recording undersampling factor is larger than 1.</p> required <code>pde</code> <code>stride.Operator</code> <p>the stride Operator that was executed to run the simulation.</p> required <code>shot</code> <code>stride.Shot</code> <p>the stride Shot which was used for the simulation.</p> required <code>wavefield</code> <code>npt.NDArray[np.float_]</code> <p>an array containing the resulting simulation data.</p> required <code>traces</code> <code>stride.Traces</code> <p>the stride Traces object returned from executing the pde.</p> required"},{"location":"api/results/#neurotechdevkit.results.PulsedResult2D","title":"<code>PulsedResult2D</code>","text":"<p>         Bases: <code>PulsedResult</code></p> <p>A container for holding the results of a 2D pulsed simulation.</p> <p>Parameters:</p> Name Type Description Default <code>scenario</code> <code>scenarios.Scenario2D</code> <p>the 2D scenario from which this result came.</p> required <code>center_frequency</code> <code>float</code> <p>the center frequency (in hertz) of the sources.</p> required <code>effective_dt</code> <code>float</code> <p>the effective time step (in seconds) along the time axis of the wavefield. This can differ from the simulation dt if the recording downsampling factor is larger than 1.</p> required <code>pde</code> <code>stride.Operator</code> <p>the stride Operator that was executed to run the simulation.</p> required <code>shot</code> <code>stride.Shot</code> <p>the stride Shot which was used for the simulation.</p> required <code>wavefield</code> <code>npt.NDArray[np.float_]</code> <p>a 3 dimensional array (two axes for space and one for time) containing the resulting simulation data.</p> required <code>traces</code> <code>stride.Traces</code> <p>the stride Traces object returned from executing the pde.</p> required"},{"location":"api/results/#neurotechdevkit.results._results.PulsedResult2D.create_video_file","title":"<code>create_video_file(file_name, show_sources=True, show_target=True, show_material_outlines=True, n_frames_undersampling=1, time_lim=None, norm='linear', fps=25, dpi=100, bitrate=2500, overwrite=False)</code>","text":"<p>Save a <code>mp4</code> animation file to disk with the results of the simulation.</p> <p>Currently only mp4 format supported. <code>ffmpeg</code> command line tools needs to be installed.</p> <p>Parameters:</p> Name Type Description Default <code>file_name</code> <code>str</code> <p>the file with path an extension where the animation would be saved. Currently only supports mp4 extension.</p> required <code>show_sources</code> <code>bool</code> <p>whether or not to show the source transducer layer.</p> <code>True</code> <code>show_target</code> <code>bool</code> <p>whether or not to show the target layer.</p> <code>True</code> <code>show_material_outlines</code> <code>bool</code> <p>whether or not to display a thin white outline of the transition between different materials.</p> <code>True</code> <code>n_frames_undersampling</code> <code>int</code> <p>the number of time steps to be skipped when creating the animation.</p> <code>1</code> <code>time_lim</code> <code>tuple[np.float_, np.float_] | None</code> <p>the input time limit tuple to validate. The expected format is (minimum_time, maximum_time).</p> <code>None</code> <code>norm</code> <code>str</code> <p>the normalization method used to scale scalar data to the [0, 1] range before mapping to colors using cmap. For a list of available scales, call <code>matplotlib.scale.get_scale_names()</code>.</p> <code>'linear'</code> <code>fps</code> <code>int</code> <p>the frames per second in the animation.</p> <code>25</code> <code>dpi</code> <code>int</code> <p>the number of dots per inch in the frames of the animation.</p> <code>100</code> <code>bitrate</code> <code>int</code> <p>the bitrate for the saved movie file, which is one way to control the output file size and quality.</p> <code>2500</code> <code>overwrite</code> <code>bool</code> <p>a boolean that allows the animation to be saved with the same file name that is already exists.</p> <code>False</code>"},{"location":"api/results/#neurotechdevkit.results._results.PulsedResult2D.render_pulsed_simulation_animation","title":"<code>render_pulsed_simulation_animation(show_sources=True, show_target=True, show_material_outlines=True, n_frames_undersampling=1, time_lim=None, norm='linear')</code>","text":"<p>Create a matplotlib animation with the time evolution of the wavefield.</p> <p>The created animation will be displayed as an interactive widget in a IPython or Jupyter Notebook environment. In a non-interactive environment (script) the result of this animation would be lost. Use <code>create_video_file</code> method instead.</p> <p>Parameters:</p> Name Type Description Default <code>show_sources</code> <code>bool</code> <p>whether or not to show the source transducer layer.</p> <code>True</code> <code>show_target</code> <code>bool</code> <p>whether or not to show the target layer.</p> <code>True</code> <code>show_material_outlines</code> <code>bool</code> <p>whether or not to display a thin white outline of the transition between different materials.</p> <code>True</code> <code>n_frames_undersampling</code> <code>int</code> <p>the number of time steps to be skipped when creating the animation.</p> <code>1</code> <code>time_lim</code> <code>tuple[np.float_, np.float_] | None</code> <p>the input time limit tuple to validate. The expected format is (minimum_time, maximum_time).</p> <code>None</code> <code>norm</code> <code>str</code> <p>the normalization method used to scale scalar data to the [0, 1] range before mapping to colors using cmap. For a list of available scales, call <code>matplotlib.scale.get_scale_names()</code>.</p> <code>'linear'</code> <p>Returns:</p> Type Description <code>FuncAnimation</code> <p>An matplotlib animation object.</p>"},{"location":"api/results/#neurotechdevkit.results.PulsedResult3D","title":"<code>PulsedResult3D</code>","text":"<p>         Bases: <code>PulsedResult</code></p> <p>A container for holding the results of a 3D pulsed simulation.</p> <p>Parameters:</p> Name Type Description Default <code>scenario</code> <code>scenarios.Scenario3D</code> <p>the 3D scenario from which this result came.</p> required <code>center_frequency</code> <code>float</code> <p>the center frequency (in hertz) of the sources.</p> required <code>effective_dt</code> <code>float</code> <p>the effective time step (in seconds) along the time axis of the wavefield. This can differ from the simulation dt if the recording downsampling factor is larger than 1.</p> required <code>pde</code> <code>stride.Operator</code> <p>the stride Operator that was executed to run the simulation.</p> required <code>shot</code> <code>stride.Shot</code> <p>the stride Shot which was used for the simulation.</p> required <code>wavefield</code> <code>npt.NDArray[np.float_]</code> <p>a 4 dimensional array (three axes for space and one for time) containing the resulting simulation data.</p> required <code>traces</code> <code>stride.Traces</code> <p>the stride Traces object returned from executing the pde.</p> required"},{"location":"api/results/#neurotechdevkit.results._results.PulsedResult3D.create_video_file","title":"<code>create_video_file(file_name, show_sources=True, show_target=True, show_material_outlines=True, n_frames_undersampling=1, slice_axis=None, slice_position=None, time_lim=None, norm='linear', fps=25, dpi=100, bitrate=2500, overwrite=False)</code>","text":"<p>Save a <code>mp4</code> animation file to disk with the results of the simulation.</p> <p>Currently only mp4 format supported. <code>ffmpeg</code> command line tools needs to be installed.</p> <p>Parameters:</p> Name Type Description Default <code>file_name</code> <code>str</code> <p>the file with path an extension where the animation would be saved. Currently only supports mp4 extension.</p> required <code>show_sources</code> <code>bool</code> <p>whether or not to show the source transducer layer.</p> <code>True</code> <code>show_target</code> <code>bool</code> <p>whether or not to show the target layer.</p> <code>True</code> <code>show_material_outlines</code> <code>bool</code> <p>whether or not to display a thin white outline of the transition between different materials.</p> <code>True</code> <code>n_frames_undersampling</code> <code>int</code> <p>the number of time steps to be skipped when creating the animation.</p> <code>1</code> <code>slice_axis</code> <code>int | None</code> <p>the axis along which to slice. If None, then the value returned by <code>scenario.get_default_slice_axis()</code> is used.</p> <code>None</code> <code>slice_position</code> <code>float | None</code> <p>the position (in meters) along the slice axis at which the slice should be made. If None, then the value returned by <code>scenario.get_default_slice_position()</code> is used.</p> <code>None</code> <code>time_lim</code> <code>tuple[np.float_, np.float_] | None</code> <p>the input time limit tuple to validate. The expected format is (minimum_time, maximum_time).</p> <code>None</code> <code>norm</code> <code>str</code> <p>the normalization method used to scale scalar data to the [0, 1] range before mapping to colors using cmap. For a list of available scales, call <code>matplotlib.scale.get_scale_names()</code>.</p> <code>'linear'</code> <code>fps</code> <code>int</code> <p>the frames per second in the animation.</p> <code>25</code> <code>dpi</code> <code>int</code> <p>the number of dots per inch in the frames of the animation.</p> <code>100</code> <code>bitrate</code> <code>int</code> <p>the bitrate for the saved movie file, which is one way to control the output file size and quality.</p> <code>2500</code> <code>overwrite</code> <code>bool</code> <p>a boolean that allows the animation to be saved with the same file name that is already exists.</p> <code>False</code>"},{"location":"api/results/#neurotechdevkit.results._results.PulsedResult3D.render_pulsed_simulation_animation","title":"<code>render_pulsed_simulation_animation(show_sources=True, show_target=True, show_material_outlines=True, n_frames_undersampling=1, slice_axis=None, slice_position=None, time_lim=None, norm='linear')</code>","text":"<p>Create a matplotlib animation with the time evolution of the wavefield.</p> <p>The created animation will be displayed as an interactive widget in a IPython or Jupyter Notebook environment. In a non-interactive environment (script) the result of this animation would be lost. Use <code>create_video_file</code> method instead.</p> <p>Parameters:</p> Name Type Description Default <code>show_sources</code> <code>bool</code> <p>whether or not to show the source transducer layer.</p> <code>True</code> <code>show_target</code> <code>bool</code> <p>whether or not to show the target layer.</p> <code>True</code> <code>show_material_outlines</code> <code>bool</code> <p>whether or not to display a thin white outline of the transition between different materials.</p> <code>True</code> <code>n_frames_undersampling</code> <code>int</code> <p>the number of time steps to be skipped when creating the animation.</p> <code>1</code> <code>slice_axis</code> <code>int | None</code> <p>the axis along which to slice. If None, then the value returned by <code>scenario.get_default_slice_axis()</code> is used.</p> <code>None</code> <code>slice_position</code> <code>float | None</code> <p>the position (in meters) along the slice axis at which the slice should be made. If None, then the value returned by <code>scenario.get_default_slice_position()</code> is used.</p> <code>None</code> <code>time_lim</code> <code>tuple[np.float_, np.float_] | None</code> <p>the input time limit tuple to validate. The expected format is (minimum_time, maximum_time).</p> <code>None</code> <code>norm</code> <code>str</code> <p>the normalization method used to scale scalar data to the [0, 1] range before mapping to colors using cmap. For a list of available scales, call <code>matplotlib.scale.get_scale_names()</code>.</p> <code>'linear'</code> <p>Returns:</p> Type Description <code>FuncAnimation</code> <p>An matplotlib animation object.</p>"},{"location":"api/results/#neurotechdevkit.results.Result","title":"<code>Result</code>  <code>dataclass</code>","text":"<p>         Bases: <code>abc.ABC</code></p> <p>A base container for holding the results of a simulation.</p> <p>This class should not be instantiated, use SteadyStateResult2D, SteadyStateResult3D, PulsedResult2D, or PulsedResult3D.</p> <p>Parameters:</p> Name Type Description Default <code>scenario</code> <code>scenarios.Scenario</code> <p>the scenario from which this result came.</p> required <code>center_frequency</code> <code>float</code> <p>the center frequency (in hertz) of the sources.</p> required <code>effective_dt</code> <code>float</code> <p>the effective time step (in seconds) along the time axis of the wavefield. This can differ from the simulation dt if the recording undersampling factor is larger than 1.</p> required <code>pde</code> <code>stride.Operator</code> <p>the stride Operator that was executed to run the simulation.</p> required <code>shot</code> <code>stride.Shot</code> <p>the stride Shot which was used for the simulation.</p> required <code>wavefield</code> <code>npt.NDArray[np.float_]</code> <p>an array containing the resulting simulation data.</p> required <code>traces</code> <code>stride.Traces</code> <p>the stride Traces object returned from executing the pde.</p> required"},{"location":"api/results/#neurotechdevkit.results._results.Result.save_to_disk","title":"<code>save_to_disk(filepath)</code>","text":"<p>Save the result to a tarball containing the data as a gzip compressed file.</p> <p>The resulting tarball will contain two files:</p> <ul> <li><code>data.gz</code>: gzip compressed file which is a pickle object.</li> <li><code>VERSION</code>: a text file containing the <code>neurotechdevkit</code> version.</li> </ul> <p>Warning</p> <p>This functionality is experimental, so do do not be surprised if you encounter issues calling this function.</p> <p>This function is particularly useful if simulation is performed in the cloud but the user would like to download the results in order to visualize them locally in 3D.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str | pathlib.Path</code> <p>the path to the file where the results should be exported. Usually a .tar.gz file.</p> required"},{"location":"api/results/#neurotechdevkit.results.SteadyStateResult","title":"<code>SteadyStateResult</code>  <code>dataclass</code>","text":"<p>         Bases: <code>Result</code></p> <p>A base container for holding the results of a steady-state simulation.</p> <p>This class should not be instantiated, use SteadyStateResult2D or SteadyStateResult3D.</p> <p>Parameters:</p> Name Type Description Default <code>scenario</code> <code>scenario.Scenario</code> <p>the scenario from which this result came.</p> required <code>center_frequency</code> <code>float</code> <p>the center frequency (in hertz) of the sources.</p> required <code>effective_dt</code> <code>float</code> <p>the effective time step (in seconds) along the time axis of the wavefield. This can differ from the simulation dt if the recording undersampling factor is larger than 1.</p> required <code>pde</code> <code>stride.Operator</code> <p>the stride Operator that was executed to run the simulation.</p> required <code>shot</code> <code>stride.Shot</code> <p>the stride Shot which was used for the simulation.</p> required <code>wavefield</code> <code>npt.NDArray[np.float_]</code> <p>an array containing the resulting simulation data.</p> required <code>traces</code> <code>stride.Traces</code> <p>the stride Traces object returned from executing the pde.</p> required"},{"location":"api/results/#neurotechdevkit.results._results.SteadyStateResult.metrics","title":"<code>metrics: dict[str, dict[str, str | float]]</code>  <code>property</code>","text":"<p>A dictionary containing metrics and their descriptions.</p> <p>The keys for the dictionary are the names of the metrics. The value for each metric is another dictionary containing the following:</p> <ul> <li>value: the value of the metric.</li> <li>unit-of-measurement: the unit of measurement for the metric.</li> <li>description: A text description of the metric.</li> </ul>"},{"location":"api/results/#neurotechdevkit.results._results.SteadyStateResult.get_steady_state","title":"<code>get_steady_state()</code>","text":"<p>Return the steady-state array and while computing it if necessary.</p> <p>Returns:</p> Type Description <code>npt.NDArray[np.float_]</code> <p>An array containing steady-state pressure wave amplitudes (in pascals).</p>"},{"location":"api/results/#neurotechdevkit.results.SteadyStateResult2D","title":"<code>SteadyStateResult2D</code>","text":"<p>         Bases: <code>SteadyStateResult</code></p> <p>A container for holding the results of a 2D steady-state simulation.</p> <p>Parameters:</p> Name Type Description Default <code>scenario</code> <code>scenarios.Scenario2D</code> <p>the 2D scenario from which this result came.</p> required <code>center_frequency</code> <code>float</code> <p>the center frequency (in hertz) of the sources.</p> required <code>effective_dt</code> <code>float</code> <p>the effective time step (in seconds) along the time axis of the wavefield. This can differ from the simulation dt if the recording downsampling factor is larger than 1.</p> required <code>pde</code> <code>stride.Operator</code> <p>the stride Operator that was executed to run the simulation.</p> required <code>shot</code> <code>stride.Shot</code> <p>the stride Shot which was used for the simulation.</p> required <code>wavefield</code> <code>npt.NDArray[np.float_]</code> <p>a 3 dimensional array (two axes for space and one for time) containing the resulting simulation data.</p> required <code>traces</code> <code>stride.Traces</code> <p>the stride Traces object returned from executing the pde.</p> required"},{"location":"api/results/#neurotechdevkit.results._results.SteadyStateResult2D.render_steady_state_amplitudes","title":"<code>render_steady_state_amplitudes(show_sources=True, show_target=True, show_material_outlines=True)</code>","text":"<p>Create a matplotlib figure with the steady-state pressure wave amplitude.</p> <p>The grid can be turned on via: <code>plt.grid(True)</code></p> <p>Parameters:</p> Name Type Description Default <code>show_sources</code> <code>bool</code> <p>whether or not to show the source transducer layer.</p> <code>True</code> <code>show_target</code> <code>bool</code> <p>whether or not to show the target layer.</p> <code>True</code> <code>show_material_outlines</code> <code>bool</code> <p>whether or not to display a thin white outline of the transition between different materials.</p> <code>True</code>"},{"location":"api/results/#neurotechdevkit.results.SteadyStateResult3D","title":"<code>SteadyStateResult3D</code>","text":"<p>         Bases: <code>SteadyStateResult</code></p> <p>A container for holding the results of a 3D steady-state simulation.</p> <p>Parameters:</p> Name Type Description Default <code>scenario</code> <code>scenarios.Scenario3D</code> <p>the 3D scenario from which this result came.</p> required <code>center_frequency</code> <code>float</code> <p>the center frequency (in hertz) of the sources.</p> required <code>effective_dt</code> <code>float</code> <p>the effective time step (in seconds) along the time axis of the wavefield. This can differ from the simulation dt if the recording downsampling factor is larger than 1.</p> required <code>pde</code> <code>stride.Operator</code> <p>the stride Operator that was executed to run the simulation.</p> required <code>shot</code> <code>stride.Shot</code> <p>the stride Shot which was used for the simulation.</p> required <code>wavefield</code> <code>npt.NDArray[np.float_]</code> <p>a 4 dimensional array (three axes for space and one for time) containing the resulting simulation data.</p> required <code>traces</code> <code>stride.Traces</code> <p>the stride Traces object returned from executing the pde.</p> required"},{"location":"api/results/#neurotechdevkit.results._results.SteadyStateResult3D.render_steady_state_amplitudes","title":"<code>render_steady_state_amplitudes(slice_axis=None, slice_position=None, show_sources=True, show_target=True, show_material_outlines=True)</code>","text":"<p>Create a matplotlib figure with the steady-state pressure wave amplitude.</p> <p>In order to visualize the 3D scenario in a 2D plot, a slice through the scenario needs to be specified via <code>slice_axis</code> and <code>slice_position</code>. Eg. to take a slice at z=0.01 m, use <code>slice_axis=2</code> and <code>slice_position=0.01</code>.</p> <p>The grid can be turned on via: <code>plt.grid(True)</code></p> <p>Parameters:</p> Name Type Description Default <code>slice_axis</code> <code>int | None</code> <p>the axis along which to slice. If None, then the value returned by <code>scenario.get_default_slice_axis()</code> is used.</p> <code>None</code> <code>slice_position</code> <code>float | None</code> <p>the position (in meters) along the slice axis at which the slice should be made. If None, then the value returned by <code>scenario.get_default_slice_position()</code> is used.</p> <code>None</code> <code>show_sources</code> <code>bool</code> <p>whether or not to show the source transducer layer.</p> <code>True</code> <code>show_target</code> <code>bool</code> <p>whether or not to show the target layer.</p> <code>True</code> <code>show_material_outlines</code> <code>bool</code> <p>whether or not to display a thin white outline of the transition between different materials.</p> <code>True</code>"},{"location":"api/results/#neurotechdevkit.results._results.SteadyStateResult3D.render_steady_state_amplitudes_3d","title":"<code>render_steady_state_amplitudes_3d()</code>","text":"<p>Render the steady-state simulation results in 3D using napari.</p> <p>This function requires the napari package to be installed.</p> <p>Warning</p> <p>Integration with napari is experimental, and do not be surprised if you encounter issues calling this function.</p> <p>This will open up the napari interactive GUI in a separate window. The GUI contains many different controls for controlling the view of the data as well as the rendering of the layers. Among these, you can drag the scenario to view it from different angles, zoom in our out, and turn layers on or off.</p> <p>See the napari documentation for more information on the GUI.</p>"},{"location":"api/results/#neurotechdevkit.results.create_pulsed_result","title":"<code>create_pulsed_result(scenario, center_frequency, effective_dt, pde, shot, wavefield, traces, recorded_slice=None)</code>","text":"<p>Create results from pulsed simulations.</p> <p>Creates a PulsedResult2D or PulsedResult3D depending on the number of wavefield spatial dimensions. If the ndim of the wavefield is N, then the wavefield has N-1 spatial dimensions and 1 time dimension.</p> <p>Parameters:</p> Name Type Description Default <code>scenario</code> <code>scenarios.Scenario</code> <p>the scenario from which this result came.</p> required <code>center_frequency</code> <code>float</code> <p>the center frequency (in hertz) of the sources.</p> required <code>effective_dt</code> <code>float</code> <p>the effective time step (in seconds) along the time axis of the wavefield. This can differ from the simulation dt if the recording downsampling factor is larger than 1.</p> required <code>pde</code> <code>stride.Operator</code> <p>the stride Operator that was executed to run the simulation.</p> required <code>shot</code> <code>stride.Shot</code> <p>the stride Shot which was used for the simulation.</p> required <code>wavefield</code> <code>npt.NDArray[np.float_]</code> <p>an array containing the resulting simulation data.</p> required <code>traces</code> <code>stride.Traces</code> <p>the stride Traces object returned from executing the pde.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if the ndim of the wavefield is less than 3 or more than 4.</p> <p>Returns:</p> Name Type Description <code>Result</code> <code>PulsedResult</code> <p>a PulsedResult2D or PulsedResult3D, depending on the wavefield shape.</p>"},{"location":"api/results/#neurotechdevkit.results.create_steady_state_result","title":"<code>create_steady_state_result(scenario, center_frequency, effective_dt, pde, shot, wavefield, traces)</code>","text":"<p>Create a steady state result.</p> <p>Creates a SteadyStateResult2D or SteadyStateResult3D depending on the number of wavefield spatial dimensions. If the ndim of the wavefield is N, then the wavefield has N-1 spatial dimensions and 1 time dimension.</p> <p>Parameters:</p> Name Type Description Default <code>scenario</code> <code>scenarios.Scenario</code> <p>the scenario from which this result came.</p> required <code>center_frequency</code> <code>float</code> <p>the center frequency (in hertz) of the sources.</p> required <code>effective_dt</code> <code>float</code> <p>the effective time step (in seconds) along the time axis of the wavefield. This can differ from the simulation dt if the recording downsampling factor is larger than 1.</p> required <code>pde</code> <code>stride.Operator</code> <p>the stride Operator that was executed to run the simulation.</p> required <code>shot</code> <code>stride.Shot</code> <p>the stride Shot which was used for the simulation.</p> required <code>wavefield</code> <code>npt.NDArray[np.float_]</code> <p>an array containing the resulting simulation data.</p> required <code>traces</code> <code>stride.Traces</code> <p>the stride Traces object returned from executing the pde.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if the ndim of the wavefield is less than 3 or more than 4.</p> <p>Returns:</p> Name Type Description <code>Result</code> <code>SteadyStateResult</code> <p>a SteadyStateResult2D or SteadyStateResult3D, depending on the wavefield shape.</p>"},{"location":"api/results/#neurotechdevkit.results.load_result_from_disk","title":"<code>load_result_from_disk(filepath)</code>","text":"<p>Load a result from the tarball file stored on disk.</p> <p>Warning</p> <p>This functionality is experimental, so do do not be surprised if you encounter issues calling this function.</p> <p>Load a file that was saved to disk via <code>Result.save_to_disk</code>.</p> <p>If the object saved in <code>filepath</code> is the result from a steady-state simulation the results will contain only the steady-state amplitudes. Instead, for pulsed simulations the result object will contain the original wavefield.</p> <p>This function is particularly useful if simulation is performed in the cloud but the user would like to download the results in order to visualize them locally in 3D.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str | pathlib.Path</code> <p>the path to an existing result file previously saved via Result.save_to_disk.</p> required <p>Returns:</p> Type Description <code>Result</code> <p>A Results object (SteadyStateResult or PulsedResult)</p>"},{"location":"api/scenarios/","title":"Scenarios","text":""},{"location":"api/scenarios/#neurotechdevkit.scenarios.Scenario","title":"<code>neurotechdevkit.scenarios.Scenario(origin, complexity='fast')</code>","text":"<p>         Bases: <code>abc.ABC</code></p> <p>The base scenario.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.complexity","title":"<code>complexity: str</code>  <code>property</code>","text":"<p>The complexity level to use when simulating this scenario.</p> <p>Note</p> <p>The only currently supported complexity is <code>fast</code>.</p> <p>Options are:</p> <ul> <li><code>fast</code>: uses a small grid size (large grid spacing) so that simulations are fast.</li> <li><code>accurate</code>: uses a large grid size (small grid spacing) so that simulation results are accurate.</li> <li><code>balanced</code>: a grid size and grid spacing balanced between <code>fast</code> and <code>accurate</code>.</li> </ul>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.current_target_id","title":"<code>current_target_id: str</code>  <code>writable</code> <code>property</code>","text":"<p>Get or set the id of the currently selected target.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.dt","title":"<code>dt: float</code>  <code>property</code>","text":"<p>The spacing (in seconds) between consecutive timesteps of the simulation.</p> <p>Only available once a simulation has been completed.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.dx","title":"<code>dx: float</code>  <code>property</code>","text":"<p>The spacing (in meters) between spatial grid points.</p> <p>Spacing is the same in each spatial direction.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.extent","title":"<code>extent: npt.NDArray[np.float_]</code>  <code>property</code>","text":"<p>The extent of the spatial grid (in meters).</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.layer_ids","title":"<code>layer_ids: Mapping[str, int]</code>  <code>property</code>","text":"<p>A map between material names and their layer id.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.material_colors","title":"<code>material_colors: dict[str, str]</code>  <code>property</code>","text":"<p>A map between material name and material render color.</p> <p>Returns:</p> Type Description <code>dict[str, str]</code> <p>dict[str, str]: keys are material names and values are the hex color</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.origin","title":"<code>origin: npt.NDArray[np.float_]</code>  <code>property</code>","text":"<p>The spatial coordinates of grid position (0, 0, 0).</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.ppp","title":"<code>ppp: float</code>  <code>property</code>","text":"<p>The number of points per period.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.ppw","title":"<code>ppw: float</code>  <code>property</code>","text":"<p>The number of points per wavelength.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.problem","title":"<code>problem: stride.Problem</code>  <code>property</code>","text":"<p>The stride Problem object.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.scenario_id","title":"<code>scenario_id: str</code>  <code>property</code>","text":"<p>The ID for this scenario.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.shape","title":"<code>shape: npt.NDArray[np.int_]</code>  <code>property</code>","text":"<p>The shape of the spatial grid (in number of grid points).</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.sources","title":"<code>sources: FrozenList[Source]</code>  <code>property</code>","text":"<p>The list of sources currently defined.</p> <p>The source list can be edited only before a simulation is run. Once a simulation is run, the source list will be frozen and can no longer be modified.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.t_max","title":"<code>t_max: float</code>  <code>property</code>","text":"<p>The maximum time (in seconds) of the simulation.</p> <p>Only available once a simulation has been completed.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.t_min","title":"<code>t_min: float</code>  <code>property</code>","text":"<p>The starting time (in seconds) of the simulation.</p> <p>Only available once a simulation has been completed.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.target","title":"<code>target: Target</code>  <code>property</code>","text":"<p>Details about the current target.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.target_center","title":"<code>target_center: npt.NDArray[np.float_]</code>  <code>property</code>","text":"<p>The coordinates of the center of the target region (in meters).</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.target_options","title":"<code>target_options: dict[str, str]</code>  <code>property</code>","text":"<p>Information about each of the available targets for the scenario.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.target_radius","title":"<code>target_radius: float</code>  <code>property</code>","text":"<p>The radius of the target region (in meters).</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.add_source","title":"<code>add_source(source)</code>","text":"<p>Add the specified source to the scenario.</p> <p>Sources can also be added or removed by modifying the Scenario.sources list.</p> <p>Changes can only be made to sources before a simulation has started.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>Source</code> <p>the source to add to the scenario.</p> required"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.get_default_source","title":"<code>get_default_source()</code>  <code>abstractmethod</code>","text":"<p>Create and returns a default source for this scenario.</p> <p>Returns:</p> Type Description <code>Source</code> <p>The default source.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.get_field_data","title":"<code>get_field_data(field)</code>","text":"<p>Return the array of field values across the scenario for a particular field.</p> <p>Common fields include:</p> <ul> <li>vp: the speed of sound (in m/s)</li> <li>rho: the density (in kg/m\u00b3)</li> <li>alpha: absorption (in dB/cm)</li> <li>layer: the layer id at each point over the grid</li> </ul> <p>Parameters:</p> Name Type Description Default <code>field</code> <code>str</code> <p>the name of the field to return.</p> required <p>Returns:</p> Type Description <code>npt.NDArray[np.float_]</code> <p>An array containing the field data.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.get_layer_mask","title":"<code>get_layer_mask(layer_name)</code>","text":"<p>Return the mask for the desired layer.</p> <p>The mask is <code>True</code> at each gridpoint where the requested layer exists, and <code>False</code> elsewhere.</p> <p>Parameters:</p> Name Type Description Default <code>layer_name</code> <code>str</code> <p>the name of the desired layer.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>layer_name</code> does not match the name of one of the existing layers.</p> <p>Returns:</p> Type Description <code>npt.NDArray[np.bool_]</code> <p>A boolean array indicating which gridpoints correspond to the desired layer.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.get_materials","title":"<code>get_materials(center_frequency=float)</code>","text":"<p>Return a map between material name and material properties.</p> <ul> <li>vp: the speed of sound (in m/s).</li> <li>rho: the mass density (in kg/m\u00b3).</li> <li>alpha: the absorption (in dB/cm).</li> <li>render_color: the color used when rendering this material in the scenario layout plot.</li> </ul>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.get_target_mask","title":"<code>get_target_mask()</code>  <code>abstractmethod</code>","text":"<p>Return the mask for the target region.</p> <p>Returns:</p> Type Description <code>npt.NDArray[np.bool_]</code> <p>A boolean array indicating which gridpoints correspond to the target region.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.reset","title":"<code>reset()</code>","text":"<p>Reset the scenario to initial state.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.simulate_pulse","title":"<code>simulate_pulse(center_frequency=500000.0, points_per_period=24, simulation_time=None, recording_time_undersampling=4, n_jobs=None)</code>","text":"<p>Execute a pulsed simulation in 2D.</p> <p>In this simulation, the sources will emit a pulse containing a few cycles of oscillation and then let the pulse propagate out to all edges of the scenario.</p> <p>Warning</p> <p>A poor choice of arguments to this function can lead to a failed simulation. Make sure you understand the impact of supplying parameter values other than the default if you chose to do so.</p> <p>Parameters:</p> Name Type Description Default <code>center_frequency</code> <code>float</code> <p>the center frequency (in hertz) to use for the continuous-wave source output.</p> <code>500000.0</code> <code>points_per_period</code> <code>int</code> <p>the number of points in time to simulate for each cycle of the wave.</p> <code>24</code> <code>simulation_time</code> <code>float | None</code> <p>the amount of time (in seconds) the simulation should run. If the value is None, this time will automatically be set to the amount of time it would take to propagate from one corner to the opposite in the medium with the slowest speed of sound in the scenario.</p> <code>None</code> <code>recording_time_undersampling</code> <code>int</code> <p>the undersampling factor to apply to the time axis when recording simulation results. One out of every this many consecutive time points will be recorded and all others will be dropped.</p> <code>4</code> <code>n_jobs</code> <code>int | None</code> <p>the number of threads to be used for the computation. Use None to leverage Devito automatic tuning.</p> <code>None</code> <p>Returns:</p> Type Description <code>results.PulsedResult</code> <p>An object containing the result of the 2D pulsed simulation.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.simulate_steady_state","title":"<code>simulate_steady_state(center_frequency=500000.0, points_per_period=24, n_cycles_steady_state=10, time_to_steady_state=None, recording_time_undersampling=4, n_jobs=None)</code>","text":"<p>Execute a steady-state simulation.</p> <p>In this simulation, the sources will emit pressure waves with a continuous waveform until steady-state has been reached. The steady-state wave amplitude is found by taking the Fourier transform of the last <code>n_cycles_steady_state</code> cycles of data and taking the amplitude of the component at the <code>center_frequency</code>.</p> <p>Warning</p> <p>A poor choice of arguments to this function can lead to a failed simulation. Make sure you understand the impact of supplying parameter values other than the default if you chose to do so.</p> <p>Parameters:</p> Name Type Description Default <code>center_frequency</code> <code>float</code> <p>the center frequency (in hertz) to use for the continuous-wave source output.</p> <code>500000.0</code> <code>points_per_period</code> <code>int</code> <p>the number of points in time to simulate for each cycle of the wave.</p> <code>24</code> <code>n_cycles_steady_state</code> <code>int</code> <p>the number of complete cycles to use when calculating the steady-state wave amplitudes.</p> <code>10</code> <code>time_to_steady_state</code> <code>float | None</code> <p>the amount of time (in seconds) the simulation should run before measuring the steady-state amplitude. If the value is None, this time will automatically be set to the amount of time it would take to propagate from one corner to the opposite and back in the medium with the slowest speed of sound in the scenario.</p> <code>None</code> <code>recording_time_undersampling</code> <code>int</code> <p>the undersampling factor to apply to the time axis when recording simulation results. One out of every this many consecutive time points will be recorded and all others will be dropped.</p> <code>4</code> <code>n_jobs</code> <code>int | None</code> <p>the number of threads to be used for the computation. Use None to leverage Devito automatic tuning.</p> <code>None</code> <p>Returns:</p> Type Description <code>results.SteadyStateResult</code> <p>An object containing the result of the steady-state simulation.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios.Scenario2D","title":"<code>neurotechdevkit.scenarios.Scenario2D</code>","text":"<p>         Bases: <code>Scenario</code></p> <p>A 2D scenario.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario2D.get_target_mask","title":"<code>get_target_mask()</code>","text":"<p>Return the mask for the target region.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario2D.render_layout","title":"<code>render_layout(show_sources=True, show_target=True, show_material_outlines=False)</code>","text":"<p>Create a matplotlib figure showing the 2D scenario layout.</p> <p>The grid can be turned on via: <code>plt.grid(True)</code></p> <p>Parameters:</p> Name Type Description Default <code>show_sources</code> <code>bool</code> <p>whether or not to show the source transducer layer.</p> <code>True</code> <code>show_target</code> <code>bool</code> <p>whether or not to show the target layer.</p> <code>True</code> <code>show_material_outlines</code> <code>bool</code> <p>whether or not to display a thin white outline of the transition between different materials.</p> <code>False</code>"},{"location":"api/scenarios/#neurotechdevkit.scenarios.Scenario3D","title":"<code>neurotechdevkit.scenarios.Scenario3D</code>","text":"<p>         Bases: <code>Scenario</code></p> <p>A 3D scenario.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario3D.viewer_config_3d","title":"<code>viewer_config_3d: rendering.ViewerConfig3D</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Configuration parameters for 3D visualization of this scenario.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario3D.get_default_slice_axis","title":"<code>get_default_slice_axis()</code>  <code>abstractmethod</code>","text":"<p>Return the default slice_axis for this scenario.</p> <p>This field is used if the slice_axis is not specified when plotting 3D data in 2D.</p> <p>Returns:</p> Type Description <code>int</code> <p>The default slice_axis for this scenario.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario3D.get_default_slice_position","title":"<code>get_default_slice_position(axis)</code>  <code>abstractmethod</code>","text":"<p>Return the default slice_position (in meters) for this scenario.</p> <p>This field is used if the slice_position is not specified when plotting 3D data in 2D.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>int</code> <p>the slice axis.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The default slice_position for this scenario along the given axis.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario3D.get_target_mask","title":"<code>get_target_mask()</code>","text":"<p>Return the mask for the target region.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario3D.render_layout","title":"<code>render_layout(slice_axis=None, slice_position=None, show_sources=True, show_target=True, show_material_outlines=False)</code>","text":"<p>Create a matplotlib figure showing a 2D slice of the scenario layout.</p> <p>In order to visualize the 3D scenario in a 2D plot, a slice through the scenario needs to be specified via <code>slice_axis</code> and <code>slice_position</code>. Eg. to take a slice at z=0.01 m, use <code>slice_axis=2</code> and <code>slice_position=0.01</code>.</p> <p>The grid can be turned on via: <code>plt.grid(True)</code></p> <p>Parameters:</p> Name Type Description Default <code>slice_axis</code> <code>int | None</code> <p>the axis along which to slice. If None, then the value returned by <code>scenario.get_default_slice_axis()</code> is used.</p> <code>None</code> <code>slice_position</code> <code>float | None</code> <p>the position (in meters) along the slice axis at which the slice should be made. If None, then the value returned by <code>scenario.get_default_slice_position()</code> is used.</p> <code>None</code> <code>show_sources</code> <code>bool</code> <p>whether or not to show the source transducer layer.</p> <code>True</code> <code>show_target</code> <code>bool</code> <p>whether or not to show the target layer.</p> <code>True</code> <code>show_material_outlines</code> <code>bool</code> <p>whether or not to display a thin white outline of the transition between different materials.</p> <code>False</code>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario3D.render_layout_3d","title":"<code>render_layout_3d()</code>","text":"<p>Render the scenario layout in 3D using napari.</p> <p>This function requires the napari package to be installed.</p> <p>Warning</p> <p>Integration with napari is experimental, so do not be surprised if you encounter issues calling this function.</p> <p>This will open up the napari interactive GUI in a separate window. The GUI contains many different controls for controlling the view of the data as well as the rendering of the layers. Among these, you can drag the scenario to view it from different angles, zoom in our out, and turn layers on or off.</p> <p>See napari documentation for more information on the GUI: documentation</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario3D.simulate_pulse","title":"<code>simulate_pulse(center_frequency=500000.0, points_per_period=24, simulation_time=None, recording_time_undersampling=4, n_jobs=None, slice_axis=None, slice_position=None)</code>","text":"<p>Execute a pulsed simulation in 3D.</p> <p>In this simulation, the sources will emit a pulse containing a few cycles of oscillation and then let the pulse propagate out to all edges of the scenario.</p> <p>Warning</p> <p>A poor choice of arguments to this function can lead to a failed simulation. Make sure you understand the impact of supplying parameter values other than the default if you chose to do so.</p> <p>Parameters:</p> Name Type Description Default <code>center_frequency</code> <code>float</code> <p>the center frequency (in hertz) to use for the continuous-wave source output.</p> <code>500000.0</code> <code>points_per_period</code> <code>int</code> <p>the number of points in time to simulate for each cycle of the wave.</p> <code>24</code> <code>simulation_time</code> <code>float | None</code> <p>the amount of time (in seconds) the simulation should run. If the value is None, this time will automatically be set to the amount of time it would take to propagate from one corner to the opposite in the medium with the slowest speed of sound in the scenario.</p> <code>None</code> <code>recording_time_undersampling</code> <code>int</code> <p>the undersampling factor to apply to the time axis when recording simulation results. One out of every this many consecutive time points will be recorded and all others will be dropped.</p> <code>4</code> <code>n_jobs</code> <code>int | None</code> <p>the number of threads to be used for the computation. Use None to leverage Devito automatic tuning.</p> <code>None</code> <code>slice_axis</code> <code>int | None</code> <p>the axis along which to slice the 3D field to be recorded. If None, then the complete field will be recorded. Use 0 for X axis, 1 for Y axis and 2 for Z axis. Only valid if <code>slice_position</code> is not None.</p> <code>None</code> <code>slice_position</code> <code>float | None</code> <p>the position (in meters) along the slice axis at which the slice of the 3D field should be made. Only valid if <code>slice_axis</code> is not None.</p> <code>None</code> <p>Returns:</p> Type Description <code>results.PulsedResult</code> <p>An object containing the result of the 3D pulsed simulation.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios.Scenario0","title":"<code>neurotechdevkit.scenarios.Scenario0(complexity='fast')</code>","text":"<p>         Bases: <code>Scenario2D</code></p> <p>Scenario 0.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._scenario_0.Scenario0._SCENARIO_ID","title":"<code>_SCENARIO_ID = 'scenario-0-v0'</code>  <code>class-attribute</code>","text":""},{"location":"api/scenarios/#neurotechdevkit.scenarios.Scenario1_2D","title":"<code>neurotechdevkit.scenarios.Scenario1_2D(complexity='fast')</code>","text":"<p>         Bases: <code>Scenario1</code>, <code>Scenario2D</code></p> <p>A 2D implementation of scenario 1.</p> Scenario 1 is based on benchmark 4 of the following paper <p>Jean-Francois Aubry, Oscar Bates, Christian Boehm, et al., \"Benchmark problems for transcranial ultrasound simulation: Intercomparison of compressional wave models\", The Journal of the Acoustical Society of America 152, 1003 (2022); doi: 10.1121/10.0013426 https://asa.scitation.org/doi/pdf/10.1121/10.0013426</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._scenario_1.Scenario1_2D._SCENARIO_ID","title":"<code>_SCENARIO_ID = 'scenario-1-2d-v0'</code>  <code>class-attribute</code>","text":""},{"location":"api/scenarios/#neurotechdevkit.scenarios.Scenario1_3D","title":"<code>neurotechdevkit.scenarios.Scenario1_3D(complexity='fast')</code>","text":"<p>         Bases: <code>Scenario1</code>, <code>Scenario3D</code></p> <p>A 3D implementation of scenario 1.</p> Scenario 1 is based on benchmark 4 of the following paper <p>Jean-Francois Aubry, Oscar Bates, Christian Boehm, et al., \"Benchmark problems for transcranial ultrasound simulation: Intercomparison of compressional wave models\", The Journal of the Acoustical Society of America 152, 1003 (2022); doi: 10.1121/10.0013426 https://asa.scitation.org/doi/pdf/10.1121/10.0013426</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._scenario_1.Scenario1_3D._SCENARIO_ID","title":"<code>_SCENARIO_ID = 'scenario-1-3d-v0'</code>  <code>class-attribute</code>","text":""},{"location":"api/scenarios/#neurotechdevkit.scenarios.Scenario2_2D","title":"<code>neurotechdevkit.scenarios.Scenario2_2D(complexity='fast')</code>","text":"<p>         Bases: <code>Scenario2</code>, <code>Scenario2D</code></p> <p>A 2D implementation of scenario 2.</p> Scenario 2 is based on benchmark 8 of the following paper <p>Jean-Francois Aubry, Oscar Bates, Christian Boehm, et al., \"Benchmark problems for transcranial ultrasound simulation: Intercomparison of compressional wave models\", The Journal of the Acoustical Society of America 152, 1003 (2022); doi: 10.1121/10.0013426 https://asa.scitation.org/doi/pdf/10.1121/10.0013426</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._scenario_2.Scenario2_2D._SCENARIO_ID","title":"<code>_SCENARIO_ID = 'scenario-2-2d-v0'</code>  <code>class-attribute</code>","text":""},{"location":"api/scenarios/#neurotechdevkit.scenarios.Scenario2_3D","title":"<code>neurotechdevkit.scenarios.Scenario2_3D(complexity='fast')</code>","text":"<p>         Bases: <code>Scenario2</code>, <code>Scenario3D</code></p> <p>A 3D implementation of scenario 2.</p> Scenario 2 is based on benchmark 8 of the following paper <p>Jean-Francois Aubry, Oscar Bates, Christian Boehm, et al., \"Benchmark problems for transcranial ultrasound simulation: Intercomparison of compressional wave models\", The Journal of the Acoustical Society of America 152, 1003 (2022); doi: 10.1121/10.0013426 https://asa.scitation.org/doi/pdf/10.1121/10.0013426</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._scenario_2.Scenario2_3D._SCENARIO_ID","title":"<code>_SCENARIO_ID = 'scenario-2-3d-v0'</code>  <code>class-attribute</code>","text":""},{"location":"api/scenarios/#neurotechdevkit.scenarios.Target","title":"<code>neurotechdevkit.scenarios.Target</code>  <code>dataclass</code>","text":"<p>A class for containing metadata for a target.</p> <p>Attributes:</p> Name Type Description <code>target_id</code> <code>str</code> <p>the string id of the target.</p> <code>center</code> <code>npt.NDArray[np.float_]</code> <p>the location of the center of the target (in meters).</p> <code>radius</code> <code>float</code> <p>the radius of the target (in meters).</p> <code>description</code> <code>str</code> <p>a text describing the target.</p>"},{"location":"api/sources/","title":"Sources","text":""},{"location":"api/sources/#neurotechdevkit.sources.FocusedSource2D","title":"<code>FocusedSource2D</code>","text":"<p>         Bases: <code>Source</code></p> <p>A focused source in 2D.</p> <p>This source is shaped like an arc and has a circular focus. It is created by taking an arc of a circle and distributing point sources evenly along that arc.</p> <p>See Circular arc for relevant geometrical calculations.</p>"},{"location":"api/sources/#neurotechdevkit.sources.FocusedSource2D.calculate_waveform_scale","title":"<code>calculate_waveform_scale(dx)</code>","text":"<p>Calculate the scale factor to apply to waveforms from this source.</p> <p>The scale is equal to the ratio between the density of grid points along a line and the density of source points along the arc.</p> <p>Parameters:</p> Name Type Description Default <code>dx</code> <code>float</code> <p>the separation between gridpoints (in meters). Assumed to be the same in both directions.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The scale factor to apply to the waveform.</p>"},{"location":"api/sources/#neurotechdevkit.sources.FocusedSource3D","title":"<code>FocusedSource3D</code>","text":"<p>         Bases: <code>Source</code></p> <p>A focused source in 3D.</p> <p>This source is shaped like a bowl and has a spherical focus. It is created by taking a section of a spherical shell and distributing source points over the surface. Points are distributed according to Fibonacci spirals.</p> <p>See Spherical cap for relevant geometrical calculations.</p>"},{"location":"api/sources/#neurotechdevkit.sources.FocusedSource3D.calculate_waveform_scale","title":"<code>calculate_waveform_scale(dx)</code>","text":"<p>Calculate the scale factor to apply to waveforms from this source.</p> <p>The scale is equal to the ratio between the density of grid points in a plane and the density of source points along the bowl surface.</p> <p>Parameters:</p> Name Type Description Default <code>dx</code> <code>float</code> <p>the separation between gridpoints (in meters). Assumed to be the same in all 3 directions.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The scale factor to apply to the waveform.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource","title":"<code>PhasedArraySource(*, position, direction, num_points, num_elements, pitch, element_width, tilt_angle=0.0, focal_length=np.inf, delay=0.0, element_delays=None)</code>","text":"<p>         Bases: <code>Source</code></p> <p>A base class for phased array sources.</p> <p>Parameters:</p> Name Type Description Default <code>position</code> <code>npt.NDArray[np.float_]</code> <p>a numpy float array indicating the coordinates (in meters) of the point at the center of the source, which is the point that bisects the line segment source.</p> required <code>direction</code> <code>npt.NDArray[np.float_]</code> <p>a numpy float array representing a vector located at position that is perpendicular to the plane of the source. Only the orientation of <code>direction</code> affects the source, the length of the vector has no affect. See the <code>unit_direction</code> property.</p> required <code>num_points</code> <code>int</code> <p>the number of point sources to use when simulating the source.</p> required <code>num_elements</code> <code>int</code> <p>the number of elements of the phased array.</p> required <code>pitch</code> <code>float</code> <p>the distance (in meters) between the centers of neighboring elements in the phased array.</p> required <code>element_width</code> <code>float</code> <p>the width (in meters) of each individual element of the array.</p> required <code>tilt_angle</code> <code>float</code> <p>the desired tilt angle (in degrees) of the wavefront. The angle is measured between the direction the wavefront travels and the normal to the surface of the transducer, with positive angles resulting in a counter-clockwise tilt away from the normal.</p> <code>0.0</code> <code>focal_length</code> <code>float</code> <p>the distance (in meters) from <code>position</code> to the focal point.</p> <code>np.inf</code> <code>delay</code> <code>float</code> <p>the delay (in seconds) that the source will wait before emitting.</p> <code>0.0</code> <code>element_delays</code> <code>npt.NDArray[np.float_] | None</code> <p>an 1D array with the delays (in seconds) for each element of the phased array. Delays from <code>element_delays</code> take precedence; No other argument affected the delays (<code>tilt_angle</code>, <code>focal_length</code> or <code>delay</code>) would be considered. ValueError will be raised if provided values for either <code>tilt_angle</code>, <code>focal_length</code> or <code>delay</code> are non-default.</p> <code>None</code>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource.aperture","title":"<code>aperture: float</code>  <code>property</code>","text":"<p>The width (in meters) of the source.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource.element_delays","title":"<code>element_delays: npt.NDArray[np.float_]</code>  <code>property</code>","text":"<p>The delay (in seconds) that each element should wait before emitting.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource.element_positions","title":"<code>element_positions: npt.NDArray[np.float_]</code>  <code>property</code>","text":"<p>An array with the position of the center of each element of the array.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource.element_width","title":"<code>element_width: float</code>  <code>property</code>","text":"<p>The width (in meters) of each element of the array.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource.num_elements","title":"<code>num_elements: int</code>  <code>property</code>","text":"<p>The number of elements in the source array.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource.pitch","title":"<code>pitch: float</code>  <code>property</code>","text":"<p>The <code>pitch</code> (in meters) of the source.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource.point_mapping","title":"<code>point_mapping: tuple[slice, ...]</code>  <code>property</code>","text":"<p>A tuple with the slices of source point indexes comprising each element.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource.point_source_delays","title":"<code>point_source_delays: npt.NDArray[np.float_]</code>  <code>property</code>","text":"<p>The delay before emitting (in seconds) for each point source.</p> <p>The delays are computed at the element level. All source points within an element will have the same delay.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource.spacing","title":"<code>spacing: float</code>  <code>property</code>","text":"<p>The separation (in meters) between elements of the array.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource.tilt_angle","title":"<code>tilt_angle: float</code>  <code>property</code>","text":"<p>The angle (in degrees) that the wave front is tilted.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource.focal_point","title":"<code>focal_point()</code>","text":"<p>Get or set the coordinates (in meters) of the focal point of the source.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource.txdelay","title":"<code>txdelay(tilt_angle, pitch, speed=1500)</code>  <code>staticmethod</code>","text":"<p>Compute the delay (in seconds) required to tilt the wavefront.</p> <p>The delays from element n to element n+1 to achieve a wavefront with <code>tilt_angle</code> respect to the normal. Positive angles lead to counter-clockwise rotations.</p> <p>Parameters:</p> Name Type Description Default <code>tilt_angle</code> <code>float</code> <p>angle (in degrees) between the vector normal to the source         and the wavefront.</p> required <code>pitch</code> <code>float</code> <p>the pitch (in meters) of the source.</p> required <code>speed</code> <code>float</code> <p>the speed of sound (in meters/second) of the material where    the source is placed.</p> <code>1500</code> <p>Returns:</p> Type Description <code>float</code> <p>The delay (in seconds) between two consecutive elements.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource2D","title":"<code>PhasedArraySource2D</code>","text":"<p>         Bases: <code>PhasedArraySource</code></p> <p>A phased array source in 2D.</p> <p>This source is shaped like multiple segments in a line. Each segment can emit waves independently. It has no focus currently. A focused implementation will be supported in the future. This source is composed of <code>num_points</code> point sources. Distributed evenly in <code>num_elements</code>.</p> <p>If the number of points can not be evenly distributed in the number of elements, the remainder number of points from the even division will be discarded.</p> <p>See Phased array ultras... for detailed explanation.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource2D.focal_point","title":"<code>focal_point: npt.NDArray[np.float_]</code>  <code>property</code>","text":"<p>The coordinates (in meters) of the point where the array focuses.</p> <p>If the array is unfocused it will return the focal point (inf, inf).</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource2D.calculate_waveform_scale","title":"<code>calculate_waveform_scale(dx)</code>","text":"<p>Calculate the scale factor to apply to waveforms from this source.</p> <p>The scale is equal to the ratio between the density of grid points along a line and the density of source points along the line segment source.</p> <p>Parameters:</p> Name Type Description Default <code>dx</code> <code>float</code> <p>the separation between gridpoints (in meters). Assumed to be the same in both directions.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The scale factor to apply to the waveform.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource3D","title":"<code>PhasedArraySource3D(*, position, direction, center_line, num_points, num_elements, pitch, height, element_width, tilt_angle=0.0, focal_length=np.inf, delay=0.0, element_delays=None)</code>","text":"<p>         Bases: <code>PhasedArraySource</code></p> <p>A linear phased array source in 3D.</p> <p>This source is shaped like multiple rectangular segments in a line. Each segment can emit waves independently. It has no focus currently. A focused implementation will be supported in the future. This source is composed of <code>num_points</code> point sources distributed evenly in <code>num_elements</code>.</p> <p>If the number of points can not be evenly distributed in the number of elements, the remainder number of points from the even division will be discarded.</p> <p>See Phased array ultras... for detailed explanation.</p> <p>Parameters:</p> Name Type Description Default <code>position</code> <code>npt.NDArray[np.float_]</code> <p>a numpy float array in 3D indicating the coordinates (in meters) of the point at the center of the source, which is the point that bisects both the height and the aperture of the source.</p> required <code>direction</code> <code>npt.NDArray[np.float_]</code> <p>a numpy float array in 3D representing a vector located at position that is perpendicular to the plane of the source. Only the orientation of <code>direction</code> affects the source, the length of the vector has no affect. See the <code>unit_direction</code> property.</p> required <code>center_line</code> <code>npt.NDArray[np.float_]</code> <p>A 3D vector which is parallel to the line through the centers of the elements in the linear array. This vector must be perpendicular to <code>direction</code>. If the vector is not perpendicular, only the perpendicular component will be considered. Only the orientation affects the source, the length of the vector has no effect. See <code>unit_center_line</code> property.</p> required <code>num_points</code> <code>int</code> <p>the number of point sources to use when simulating the source. If the number of points is not divisible evenly by the number of elements, the number of points would be truncated to a multiple of the maximum even divisor.</p> required <code>num_elements</code> <code>int</code> <p>the number of elements of the phased array.</p> required <code>pitch</code> <code>float</code> <p>the distance (in meters) between the centers of neighboring elements in the phased array.</p> required <code>height</code> <code>float</code> <p>the height (in meters) of the elements of the array. <code>height</code> is measured along the direction in the plane of the element that is perpendicular to <code>center_line</code>.</p> required <code>element_width</code> <code>float</code> <p>the width (in meters) of each individual element of the array.</p> required <code>tilt_angle</code> <code>float</code> <p>the desired tilt angle (in degrees) of the wavefront. The angle is measured between the direction the wavefront travels and the normal to the surface of the transducer, with positive angles resulting in a counter-clockwise tilt away from the normal.</p> <code>0.0</code> <code>focal_length</code> <code>float</code> <p>the distance (in meters) from <code>position</code> to the focal point.</p> <code>np.inf</code> <code>delay</code> <code>float</code> <p>the delay (in seconds) that the source will wait before emitting.</p> <code>0.0</code> <code>element_delays</code> <code>npt.NDArray[np.float_] | None</code> <p>an 1D array with the delays (in seconds) for each element of the phased array. Delays from <code>element_delays</code> take precedence; No other argument affected the delays (<code>tilt_angle</code>, <code>focal_length</code> or <code>delay</code>) would be considered. ValueError will be raised if provided values for either <code>tilt_angle</code>, <code>focal_length</code> or <code>delay</code> are non-default.</p> <code>None</code>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource3D.focal_point","title":"<code>focal_point: npt.NDArray[np.float_]</code>  <code>property</code>","text":"<p>The coordinates (in meters) of the point where the array focuses.</p> <p>If the array is unfocused it will return the focal point (inf, inf, inf).</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource3D.height","title":"<code>height: float</code>  <code>property</code>","text":"<p>The <code>height</code> (in meters) of the elements of the source.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource3D.unit_center_line","title":"<code>unit_center_line: npt.NDArray[np.float_]</code>  <code>property</code>","text":"<p>The unit direction of the line crossing the center of the array elements.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource3D.calculate_waveform_scale","title":"<code>calculate_waveform_scale(dx)</code>","text":"<p>Calculate the scale factor to apply to waveforms from this source.</p> <p>The scale is equal to the ratio between the density of grid points along a plane and the density of source points along the planar source.</p> <p>Parameters:</p> Name Type Description Default <code>dx</code> <code>float</code> <p>the separation between gridpoints (in meters). Assumed to be the same in both directions.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The scale factor to apply to the waveform.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PlanarSource2D","title":"<code>PlanarSource2D</code>","text":"<p>         Bases: <code>UnfocusedSource</code></p> <p>A planar source in 2D.</p> <p>This source is shaped like a line segment and has no focus. The source is composed of <code>num_points</code> point sources evenly distributed along the line segment.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PlanarSource2D.calculate_waveform_scale","title":"<code>calculate_waveform_scale(dx)</code>","text":"<p>Calculate the scale factor to apply to waveforms from this source.</p> <p>The scale is equal to the ratio between the density of grid points along a line and the density of source points along the line segment source.</p> <p>Parameters:</p> Name Type Description Default <code>dx</code> <code>float</code> <p>the separation between gridpoints (in meters). Assumed to be the same in both directions.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The scale factor to apply to the waveform.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PlanarSource3D","title":"<code>PlanarSource3D</code>","text":"<p>         Bases: <code>UnfocusedSource</code></p> <p>A planar source in 3D.</p> <p>This source is shaped like a disk and has no focus. It is created by defining a disk and distributing <code>num_points</code> point sources according to Fibonacci spirals.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PlanarSource3D.calculate_waveform_scale","title":"<code>calculate_waveform_scale(dx)</code>","text":"<p>Calculate the scale factor to apply to waveforms from this source.</p> <p>The scale is equal to the ratio between the density of grid points along a plane and the density of source points along the disk source.</p> <p>Parameters:</p> Name Type Description Default <code>dx</code> <code>float</code> <p>the separation between gridpoints (in meters). Assumed to be the same in both directions.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The scale factor to apply to the waveform.</p>"},{"location":"api/sources/#neurotechdevkit.sources.Source","title":"<code>Source(*, position, direction, aperture, focal_length, num_points, delay=0.0)</code>","text":"<p>         Bases: <code>abc.ABC</code></p> <p>An abstract class that represents a generic Source object.</p> <p>Sources can be 2D or 3D, which affects the shape of arrays representing coordinates or vectors. Sources are composed of point sources evenly distributed over the appropriate source geometry.</p> <p>Parameters:</p> Name Type Description Default <code>position</code> <code>npt.NDArray[np.float_]</code> <p>a numpy float array indicating the coordinates (in meters) of the point at the center of the source.</p> required <code>direction</code> <code>npt.NDArray[np.float_]</code> <p>a numpy float array representing a vector located at position and pointing towards the focal point. Only the orientation of <code>direction</code> affects the source, the length of the vector has no affect. See the <code>unit_direction</code> property.</p> required <code>aperture</code> <code>float</code> <p>the width (in meters) of the source.</p> required <code>focal_length</code> <code>float</code> <p>the distance (in meters) from <code>position</code> to the focal point.</p> required <code>num_points</code> <code>int</code> <p>the number of point sources to use when simulating the source.</p> required <code>delay</code> <code>float</code> <p>the delay (in seconds) that the source will wait before emitting. Defaults to 0.0.</p> <code>0.0</code>"},{"location":"api/sources/#neurotechdevkit.sources.Source.aperture","title":"<code>aperture: float</code>  <code>property</code>","text":"<p>The width (in meters) of the source.</p>"},{"location":"api/sources/#neurotechdevkit.sources.Source.coordinates","title":"<code>coordinates: npt.NDArray[np.float_]</code>  <code>property</code>","text":"<p>A 2D array containing the <code>coordinates</code> (in meters) of the source points.</p> <p>The length of this array along the first dimension is equal to <code>num_points</code>.</p>"},{"location":"api/sources/#neurotechdevkit.sources.Source.delay","title":"<code>delay: float</code>  <code>property</code>","text":"<p>The <code>delay</code> (in seconds) for the source as a whole.</p> <p><code>delay</code> should be non-negative.</p>"},{"location":"api/sources/#neurotechdevkit.sources.Source.focal_length","title":"<code>focal_length: float</code>  <code>property</code>","text":"<p>The distance (in meters) from <code>position</code> to the focal point.</p>"},{"location":"api/sources/#neurotechdevkit.sources.Source.num_points","title":"<code>num_points: int</code>  <code>property</code>","text":"<p>The number of point sources used to simulate the source.</p>"},{"location":"api/sources/#neurotechdevkit.sources.Source.point_source_delays","title":"<code>point_source_delays: npt.NDArray[np.float_]</code>  <code>property</code>","text":"<p>The delay before emitting (in seconds) for each point source.</p>"},{"location":"api/sources/#neurotechdevkit.sources.Source.position","title":"<code>position: npt.NDArray[np.float_]</code>  <code>property</code>","text":"<p>A numpy float array indicating the <code>position</code> (in meters) of the source.</p> <p>The position of the source is defined as the coordinates of the point at the center of symmetry of the source.</p>"},{"location":"api/sources/#neurotechdevkit.sources.Source.unit_direction","title":"<code>unit_direction: npt.NDArray[np.float_]</code>  <code>property</code>","text":"<p>A normalized vector indicating the orientation of the source.</p> <p>The vector is located at <code>position</code>, points towards the focal point, and has unit length. It points in the same direction as the <code>direction</code> parameter in <code>__init__</code>, except it is normalized.</p>"},{"location":"api/sources/#neurotechdevkit.sources.Source.calculate_waveform_scale","title":"<code>calculate_waveform_scale(dx)</code>  <code>abstractmethod</code>","text":"<p>Calculate the scale factor to apply to waveforms from this source.</p> <p>The scale depends on the relative density of source points vs grid points.</p> <p>This method must be implemented by all concrete Source classes.</p> <p>Parameters:</p> Name Type Description Default <code>dx</code> <code>float</code> <p>the separation (in meters) between gridpoints. Assumed to be the same in all directions.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The scale factor to apply to the waveform.</p>"},{"location":"api/sources/#neurotechdevkit.sources.UnfocusedSource","title":"<code>UnfocusedSource(*, position, direction, aperture, num_points, delay=0.0)</code>","text":"<p>         Bases: <code>Source</code></p> <p>A base class for unfocused sources.</p> <p>Automatically sets <code>focal_length</code> to <code>np.inf</code></p>"},{"location":"api/utils/","title":"Utils","text":""},{"location":"api/utils/#neurotechdevkit.scenarios.add_material_fields_to_problem","title":"<code>neurotechdevkit.scenarios.add_material_fields_to_problem(problem, materials, layer_ids, masks)</code>","text":"<p>Add material fields as media to the problem.</p> <p>Included fields are:</p> <ul> <li>the speed of sound (in m/s)</li> <li>density (in kg/m^3)</li> <li>absorption (in dB/cm)</li> </ul> <p>Parameters:</p> Name Type Description Default <code>problem</code> <code>stride.Problem</code> <p>the stride Problem object to which the media should be added.</p> required <code>materials</code> <code>Mapping[str, Struct]</code> <p>a mapping from material names to Structs containing the material properties.</p> required <code>layer_ids</code> <code>Mapping[str, int]</code> <p>a mapping from material names to integers representing the layer number for each material.</p> required <code>masks</code> <code>Mapping[str, npt.NDArray[np.bool_]]</code> <p>a mapping from material names to boolean masks indicating the gridpoints.</p> required"},{"location":"api/utils/#neurotechdevkit.scenarios.create_grid_circular_mask","title":"<code>neurotechdevkit.scenarios.create_grid_circular_mask(grid, origin, center, radius)</code>","text":"<p>Return a 2D mask array for a circle with the specified parameters.</p> <p>Array elements are True for the gridpoints within the circle and False otherwise.</p> <p>Parameters:</p> Name Type Description Default <code>grid</code> <code>stride.Grid</code> <p>the simulation grid.</p> required <code>origin</code> <code>npt.NDArray[np.float_]</code> <p>the coordinates (in meters) of the grid element (0, 0).</p> required <code>center</code> <code>npt.NDArray[np.float_]</code> <p>the coordinates (in meters) of the center of the circle.</p> required <code>a</code> <p>the radius (in meters) of the circle.</p> required <p>Returns:</p> Type Description <code>npt.NDArray[np.bool_]</code> <p>The 2D boolean mask where gridpoints within the circle are True.</p>"},{"location":"api/utils/#neurotechdevkit.scenarios.make_grid","title":"<code>neurotechdevkit.scenarios.make_grid(extent, dx, extra=50, absorbing=40)</code>","text":"<p>Create a stride Grid.</p> <p>Note that the time component of the grid is not defined here. That is created at simulation time because it depends on simulation parameters.</p> <p>Parameters:</p> Name Type Description Default <code>extent</code> <code>npt.NDArray[np.float_]</code> <p>a 2-tuple or 3-tuple containing the dimensions (in meters) of the simulation.</p> required <code>dx</code> <code>float</code> <p>a float describing the distance (in meters) between grid points.</p> required <code>extra</code> <code>int | Iterable[int]</code> <p>the number of gridpoints to add as boundary layers on each side of the grid. extras are added both before and after the grid on each axis.</p> <code>50</code> <code>absorbing</code> <code>int | Iterable[int]</code> <p>the number of gridpoints within the boundary layers that are absorbing.</p> <code>40</code> <p>Returns:</p> Type Description <code>stride.Grid</code> <p>The stride Grid object.</p>"},{"location":"generated/gallery/","title":"Examples","text":""},{"location":"generated/gallery/#examples","title":"Examples","text":"<p> Plot pulsed simulation </p> <p> Plot scenarios </p> <p> Save and load results </p> <p> Custom source </p> <p> Reading simulation metrics </p> <p> Custom center frequency </p> <p> Visualizing 3D results with Napari </p> <p> Adding multiple sources </p> <p> Phased array source </p> <p> Implementing a full scenario </p> <p> Download all examples in Python source code: gallery_python.zip</p> <p> Download all examples in Jupyter notebooks: gallery_jupyter.zip</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/mg_execution_times/","title":"Computation times","text":"<p>12:41.082 total execution time for generated_gallery files:</p> <p>+-------------------------------------------------------------------------------------------------------------------------------+-----------+--------+ | plot_phased_array_source (docs/examples/plot_phased_array_source.py)                         | 06:49.643 | 0.0 MB | +-------------------------------------------------------------------------------------------------------------------------------+-----------+--------+ | plot_pulsed_simulation (docs/examples/plot_pulsed_simulation.py)                               | 01:38.602 | 0.0 MB | +-------------------------------------------------------------------------------------------------------------------------------+-----------+--------+ | plot_multiple_sources (docs/examples/plot_multiple_sources.py)                                  | 01:21.806 | 0.0 MB | +-------------------------------------------------------------------------------------------------------------------------------+-----------+--------+ | plot_scenarios (docs/examples/plot_scenarios.py)                                                       | 01:02.143 | 0.0 MB | +-------------------------------------------------------------------------------------------------------------------------------+-----------+--------+ | plot_3d (docs/examples/plot_3d.py)                                                                            | 00:31.697 | 0.0 MB | +-------------------------------------------------------------------------------------------------------------------------------+-----------+--------+ | plot_full_scenario (docs/examples/plot_full_scenario.py)                                           | 00:21.832 | 0.0 MB | +-------------------------------------------------------------------------------------------------------------------------------+-----------+--------+ | plot_customized_center_frequency (docs/examples/plot_customized_center_frequency.py) | 00:17.113 | 0.0 MB | +-------------------------------------------------------------------------------------------------------------------------------+-----------+--------+ | plot_metrics (docs/examples/plot_metrics.py)                                                             | 00:12.988 | 0.0 MB | +-------------------------------------------------------------------------------------------------------------------------------+-----------+--------+ | plot_store_results (docs/examples/plot_store_results.py)                                           | 00:12.814 | 0.0 MB | +-------------------------------------------------------------------------------------------------------------------------------+-----------+--------+ | plot_adding_custom_source (docs/examples/plot_adding_custom_source.py)                      | 00:12.444 | 0.0 MB | +-------------------------------------------------------------------------------------------------------------------------------+-----------+--------+</p>"},{"location":"generated/gallery/plot_3d/","title":"Visualizing 3D results with Napari","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/gallery/plot_3d/#visualizing-3d-results-with-napari","title":"Visualizing 3D results with Napari","text":"<p>This example demonstrates how to render a steady state result for a 3D scenario using napari.</p> <p>Running such simulations is computationally expensive and can take a long time to complete. For this reason, we recommend running this simulation on an external machine, store the results in a file and then load them on your local machine for visualization.</p> <p>Check the gallery example Save and load results to learn how to save and load results.</p> <p>The following step downloads and loads a simulation executed on an external machine.</p> <pre><code>import pooch\nimport neurotechdevkit as ndk\nURL = \"https://neurotechdevkit.s3.us-west-2.amazonaws.com/result-scenario-2-3d.tz\"\nknown_hash = \"6a5de26466028c673d253ca014c75c719467ec6c28d7178baf9287b44ad15191\"\ndownloaded_file_path = pooch.retrieve(url=URL, known_hash=known_hash, progressbar=True)\nresult = ndk.load_result_from_disk(downloaded_file_path)\n</code></pre> <p>Out:</p> <pre><code>  0%|                                               | 0.00/443M [00:00&lt;?, ?B/s]\n0%|                                       | 61.4k/443M [00:00&lt;14:47, 499kB/s]\n0%|                                       | 315k/443M [00:00&lt;05:12, 1.41MB/s]\n0%|                                      | 1.28M/443M [00:00&lt;01:41, 4.34MB/s]\n1%|\u258e                                     | 4.17M/443M [00:00&lt;00:37, 11.8MB/s]\n2%|\u258c                                     | 7.09M/443M [00:00&lt;00:27, 16.1MB/s]\n2%|\u258a                                     | 9.79M/443M [00:00&lt;00:24, 18.0MB/s]\n3%|\u2588                                     | 12.8M/443M [00:00&lt;00:21, 20.1MB/s]\n4%|\u2588\u258e                                    | 15.8M/443M [00:00&lt;00:19, 21.4MB/s]\n4%|\u2588\u258c                                    | 18.9M/443M [00:01&lt;00:18, 22.5MB/s]\n5%|\u2588\u2589                                    | 21.9M/443M [00:01&lt;00:18, 22.9MB/s]\n6%|\u2588\u2588                                    | 24.8M/443M [00:01&lt;00:18, 22.7MB/s]\n6%|\u2588\u2588\u258e                                   | 27.5M/443M [00:01&lt;00:18, 22.4MB/s]\n7%|\u2588\u2588\u258c                                   | 30.2M/443M [00:01&lt;00:21, 19.0MB/s]\n7%|\u2588\u2588\u258a                                   | 32.7M/443M [00:01&lt;00:21, 19.3MB/s]\n8%|\u2588\u2588\u2588                                   | 35.6M/443M [00:01&lt;00:19, 20.5MB/s]\n9%|\u2588\u2588\u2588\u258e                                  | 38.5M/443M [00:02&lt;00:18, 21.4MB/s]\n9%|\u2588\u2588\u2588\u258c                                  | 41.3M/443M [00:02&lt;00:18, 21.8MB/s]\n10%|\u2588\u2588\u2588\u258a                                  | 44.1M/443M [00:02&lt;00:18, 22.0MB/s]\n11%|\u2588\u2588\u2588\u2588                                  | 46.9M/443M [00:02&lt;00:17, 22.1MB/s]\n11%|\u2588\u2588\u2588\u2588\u258e                                 | 49.7M/443M [00:02&lt;00:17, 22.2MB/s]\n12%|\u2588\u2588\u2588\u2588\u258c                                 | 52.5M/443M [00:02&lt;00:17, 22.3MB/s]\n12%|\u2588\u2588\u2588\u2588\u258b                                 | 55.2M/443M [00:02&lt;00:17, 22.3MB/s]\n13%|\u2588\u2588\u2588\u2588\u2589                                 | 58.0M/443M [00:02&lt;00:17, 22.4MB/s]\n14%|\u2588\u2588\u2588\u2588\u2588\u258f                                | 61.0M/443M [00:03&lt;00:16, 22.8MB/s]\n14%|\u2588\u2588\u2588\u2588\u2588\u258d                                | 63.8M/443M [00:03&lt;00:16, 22.9MB/s]\n15%|\u2588\u2588\u2588\u2588\u2588\u258b                                | 66.6M/443M [00:03&lt;00:16, 22.7MB/s]\n16%|\u2588\u2588\u2588\u2588\u2588\u2589                                | 69.4M/443M [00:03&lt;00:16, 22.6MB/s]\n16%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f                               | 72.2M/443M [00:03&lt;00:16, 22.5MB/s]\n17%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d                               | 74.9M/443M [00:03&lt;00:15, 23.4MB/s]\n18%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b                               | 78.2M/443M [00:03&lt;00:14, 24.5MB/s]\n18%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589                               | 81.6M/443M [00:03&lt;00:14, 25.3MB/s]\n19%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                              | 85.0M/443M [00:04&lt;00:13, 26.0MB/s]\n20%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                              | 88.4M/443M [00:04&lt;00:13, 26.4MB/s]\n21%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                              | 91.8M/443M [00:04&lt;00:13, 26.8MB/s]\n21%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                             | 95.2M/443M [00:04&lt;00:12, 28.6MB/s]\n22%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                             | 98.1M/443M [00:04&lt;00:12, 28.0MB/s]\n23%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                              | 101M/443M [00:04&lt;00:12, 26.7MB/s]\n23%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                             | 104M/443M [00:04&lt;00:12, 27.2MB/s]\n24%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                             | 107M/443M [00:04&lt;00:11, 28.9MB/s]\n25%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                             | 110M/443M [00:04&lt;00:11, 27.8MB/s]\n25%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                             | 113M/443M [00:05&lt;00:11, 27.8MB/s]\n26%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                            | 116M/443M [00:05&lt;00:11, 28.0MB/s]\n27%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                            | 119M/443M [00:05&lt;00:11, 28.5MB/s]\n28%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                            | 122M/443M [00:05&lt;00:11, 28.5MB/s]\n28%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                            | 125M/443M [00:05&lt;00:11, 28.8MB/s]\n29%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                           | 129M/443M [00:05&lt;00:10, 30.2MB/s]\n30%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                           | 132M/443M [00:05&lt;00:10, 28.8MB/s]\n30%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                           | 134M/443M [00:05&lt;00:10, 28.7MB/s]\n31%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                          | 138M/443M [00:05&lt;00:10, 29.7MB/s]\n32%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                          | 141M/443M [00:05&lt;00:10, 30.1MB/s]\n33%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                          | 144M/443M [00:06&lt;00:09, 29.9MB/s]\n33%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                          | 148M/443M [00:06&lt;00:09, 30.4MB/s]\n34%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                         | 151M/443M [00:06&lt;00:09, 31.2MB/s]\n35%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                         | 154M/443M [00:06&lt;00:09, 30.0MB/s]\n36%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                         | 157M/443M [00:06&lt;00:09, 30.6MB/s]\n36%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                        | 161M/443M [00:06&lt;00:08, 32.3MB/s]\n37%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                        | 164M/443M [00:06&lt;00:08, 31.4MB/s]\n38%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                        | 168M/443M [00:06&lt;00:08, 31.7MB/s]\n39%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                        | 172M/443M [00:06&lt;00:08, 32.9MB/s]\n40%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                       | 175M/443M [00:07&lt;00:07, 33.6MB/s]\n40%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                       | 178M/443M [00:07&lt;00:07, 33.4MB/s]\n41%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                       | 182M/443M [00:07&lt;00:07, 34.2MB/s]\n42%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                      | 186M/443M [00:07&lt;00:07, 34.3MB/s]\n43%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                      | 189M/443M [00:07&lt;00:07, 34.6MB/s]\n44%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                      | 194M/443M [00:07&lt;00:06, 36.8MB/s]\n45%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                     | 197M/443M [00:07&lt;00:06, 35.5MB/s]\n45%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                     | 201M/443M [00:07&lt;00:06, 36.2MB/s]\n46%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                     | 205M/443M [00:07&lt;00:06, 37.3MB/s]\n47%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                    | 209M/443M [00:07&lt;00:06, 36.7MB/s]\n48%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                    | 212M/443M [00:08&lt;00:06, 36.6MB/s]\n49%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                    | 217M/443M [00:08&lt;00:05, 38.7MB/s]\n50%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                   | 221M/443M [00:08&lt;00:05, 38.1MB/s]\n51%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                   | 225M/443M [00:08&lt;00:05, 38.1MB/s]\n52%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                  | 229M/443M [00:08&lt;00:05, 39.2MB/s]\n53%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                  | 233M/443M [00:08&lt;00:05, 38.8MB/s]\n53%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                  | 237M/443M [00:08&lt;00:05, 39.3MB/s]\n54%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                 | 241M/443M [00:08&lt;00:04, 40.6MB/s]\n55%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                 | 245M/443M [00:08&lt;00:05, 39.5MB/s]\n56%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                 | 249M/443M [00:08&lt;00:04, 40.2MB/s]\n57%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                | 254M/443M [00:09&lt;00:04, 41.2MB/s]\n58%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                | 258M/443M [00:09&lt;00:04, 40.1MB/s]\n59%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                | 262M/443M [00:09&lt;00:04, 40.9MB/s]\n60%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d               | 266M/443M [00:09&lt;00:04, 41.2MB/s]\n61%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a               | 271M/443M [00:09&lt;00:04, 42.1MB/s]\n62%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f              | 275M/443M [00:09&lt;00:03, 42.8MB/s]\n63%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c              | 280M/443M [00:09&lt;00:03, 42.3MB/s]\n64%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589              | 284M/443M [00:09&lt;00:03, 42.6MB/s]\n65%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d             | 289M/443M [00:09&lt;00:03, 43.7MB/s]\n66%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a             | 293M/443M [00:10&lt;00:03, 42.6MB/s]\n67%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f            | 297M/443M [00:10&lt;00:03, 43.3MB/s]\n68%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c            | 302M/443M [00:10&lt;00:03, 44.4MB/s]\n69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589            | 307M/443M [00:10&lt;00:03, 43.4MB/s]\n70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d           | 311M/443M [00:10&lt;00:03, 43.9MB/s]\n71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a           | 315M/443M [00:10&lt;00:02, 43.2MB/s]\n72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f          | 320M/443M [00:10&lt;00:02, 44.4MB/s]\n73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c          | 325M/443M [00:10&lt;00:02, 44.5MB/s]\n74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589          | 329M/443M [00:10&lt;00:02, 44.5MB/s]\n75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d         | 334M/443M [00:10&lt;00:02, 45.3MB/s]\n76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a         | 338M/443M [00:11&lt;00:02, 44.5MB/s]\n77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f        | 343M/443M [00:11&lt;00:02, 45.1MB/s]\n79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b        | 348M/443M [00:11&lt;00:02, 46.0MB/s]\n80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588        | 353M/443M [00:11&lt;00:02, 44.9MB/s]\n81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d       | 357M/443M [00:11&lt;00:01, 44.8MB/s]\n82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a       | 362M/443M [00:11&lt;00:01, 44.9MB/s]\n83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e      | 366M/443M [00:11&lt;00:01, 45.5MB/s]\n84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b      | 371M/443M [00:11&lt;00:01, 45.3MB/s]\n85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588      | 376M/443M [00:11&lt;00:01, 45.7MB/s]\n86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d     | 381M/443M [00:11&lt;00:01, 45.7MB/s]\n87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589     | 385M/443M [00:12&lt;00:01, 44.7MB/s]\n88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e    | 390M/443M [00:12&lt;00:01, 45.6MB/s]\n89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b    | 395M/443M [00:12&lt;00:01, 45.3MB/s]\n90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 399M/443M [00:12&lt;00:00, 44.6MB/s]\n91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 404M/443M [00:12&lt;00:00, 45.8MB/s]\n92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 409M/443M [00:12&lt;00:00, 45.6MB/s]\n93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 413M/443M [00:12&lt;00:00, 44.7MB/s]\n94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 418M/443M [00:12&lt;00:00, 46.2MB/s]\n95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 423M/443M [00:12&lt;00:00, 45.5MB/s]\n96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 427M/443M [00:12&lt;00:00, 44.5MB/s]\n98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 432M/443M [00:13&lt;00:00, 46.3MB/s]\n99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 437M/443M [00:13&lt;00:00, 45.0MB/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 442M/443M [00:13&lt;00:00, 44.1MB/s]\n0%|                                               | 0.00/443M [00:00&lt;?, ?B/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 443M/443M [00:00&lt;00:00, 492GB/s]\nRecreating the scenario for the result from saved metadata...\ncreating a grid with shape: (451, 341, 381) for extent: [0.225 0.17  0.19 ] m\n</code></pre> <p>In order to render the 3D results you will need to install Install <code>napari</code> via pip:</p> <pre><code>pip install \"napari[all]\"\n</code></pre> <p>Note for Mac M1 users: Qt5 does not support Mac M1, so you will need to install the Qt6 backend instead: <pre><code>pip install \"napari[pyqt6_experimental]\"\n</code></pre></p> <p>You can also follow the <code>napari</code> installation instructions: link.</p> <pre><code>try:\nimport napari  # noqa: F401\nassert isinstance(result, ndk.results.SteadyStateResult3D)\nresult.render_steady_state_amplitudes_3d()\nexcept ImportError:\nprint(\n\"napari has not been installed. Please install it with: pip install napari[all]\"\n)\n</code></pre> <p>Out:</p> <pre><code>napari has not been installed. Please install it with: pip install napari[all]\n</code></pre> <p>If you have napari installed you should see an output like the following:</p> <pre><code>Opening the napari viewer. The window might not show up on top of your notebook;\nlook through your open applications if it does not.\n</code></pre> <p>If you have napari installed you should have been able to see an image like the following: </p> <p>Total running time of the script: ( 0 minutes  31.697 seconds)</p> <p> Download Python source code: plot_3d.py</p> <p> Download Jupyter notebook: plot_3d.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/plot_adding_custom_source/","title":"Custom source","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/gallery/plot_adding_custom_source/#custom-source","title":"Custom source","text":"<p>Note</p> <p>NDK and its examples are under constant development, more information and content will be added to this example soon!</p> <p>This example demonstrates how to add a source to the simulation.</p> <p>A Source receives the following parameters:</p> <ul> <li>position <code>(npt.NDArray[np.float_])</code>: a numpy float array indicating the   coordinates (in meters) of the point at the center of the source.</li> <li>direction <code>(npt.NDArray[np.float_])</code>: a numpy float array representing a vector   located at position and pointing towards the focal point. Only the   orientation of <code>direction</code> affects the source, the length of the vector has   no affect. See the <code>unit_direction</code> property.</li> <li>aperture <code>(float)</code>: the width (in meters) of the source.</li> <li>focal_length <code>(float)</code>: the distance (in meters) from <code>position</code> to the focal   point.</li> <li>num_points <code>(int)</code>: the number of point sources to use when simulating the source.</li> <li>delay <code>(float, optional)</code>: the delay (in seconds) that the source will wait before   emitting. Defaults to 0.0.</li> </ul> <pre><code>import numpy as np\nimport neurotechdevkit as ndk\nsource = ndk.sources.FocusedSource2D(\nposition=np.array([0.00, 0.0]),\ndirection=np.array([0.9, 0.0]),\naperture=0.01,\nfocal_length=0.01,\nnum_points=1000,\n)\nscenario = ndk.make(\"scenario-0-v0\")\nscenario.add_source(source)\nresult = scenario.simulate_steady_state()\nassert isinstance(result, ndk.results.SteadyStateResult2D)\nresult.render_steady_state_amplitudes()\n</code></pre> <p></p> <p>Out:</p> <pre><code>creating a grid with shape: (101, 81) for extent: [0.05 0.04] m\nEstimated time to complete simulation: 44 seconds. Memory required is 8.09906664298232 GB (available 73.624408064 GB). These values are approximated.\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\n</code></pre> <p>Total running time of the script: ( 0 minutes  12.444 seconds)</p> <p> Download Python source code: plot_adding_custom_source.py</p> <p> Download Jupyter notebook: plot_adding_custom_source.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/plot_customized_center_frequency/","title":"Custom center frequency","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/gallery/plot_customized_center_frequency/#custom-center-frequency","title":"Custom center frequency","text":"<p>This example demonstrates how to use a customized center frequency using ndk</p> <p></p> <p>Out:</p> <pre><code>creating a grid with shape: (121, 97) for extent: [0.05 0.04] m\nEstimated time to complete simulation: 44 seconds. Memory required is 8.10010166030443 GB (available 73.624408064 GB). These values are approximated.\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\ngcc -O3 -g -fPIC -Wall -std=c99 -march=native -Wno-unused-result -Wno-unused-variable -Wno-unused-but-set-variable -ffast-math -shared -fopenmp /tmp/devito-jitcache-uid1001/5e93aad3fe47b34cc09b102dd111206c20f0f734.c -lm -o /tmp/devito-jitcache-uid1001/5e93aad3fe47b34cc09b102dd111206c20f0f734.so\n</code></pre> <p></p> <pre><code>import neurotechdevkit as ndk\nCENTER_FREQUENCY = 6e5\nscenario = ndk.make(\"scenario-0-v0\")\n# using default material layers\nscenario.material_layers = [\"water\", \"cortical_bone\", \"brain\", \"tumor\"]\n# Customizing material properties\nscenario.material_properties = {\n\"tumor\": ndk.materials.Material(\nvp=1850.0, rho=1250.0, alpha=0.8, render_color=\"#94332F\"\n),\n}\nresult = scenario.simulate_steady_state(center_frequency=CENTER_FREQUENCY)\nassert isinstance(result, ndk.results.SteadyStateResult2D)\nresult.render_steady_state_amplitudes(show_material_outlines=False)\n</code></pre> <p>Total running time of the script: ( 0 minutes  17.113 seconds)</p> <p> Download Python source code: plot_customized_center_frequency.py</p> <p> Download Jupyter notebook: plot_customized_center_frequency.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/plot_full_scenario/","title":"Implementing a full scenario","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/gallery/plot_full_scenario/#implementing-a-full-scenario","title":"Implementing a full scenario","text":"<p>Note</p> <p>NDK and its examples are under constant development, more information and content will be added to this example soon!</p> <p>The following code is a simplified implementation of NDK's Scenario 1.</p>"},{"location":"generated/gallery/plot_full_scenario/#implementing-a-scenario","title":"Implementing a Scenario","text":"<pre><code>import numpy as np\nimport stride\nfrom neurotechdevkit import sources\nfrom neurotechdevkit.results import SteadyStateResult2D\nfrom neurotechdevkit.scenarios import (\nScenario2D,\nTarget,\nadd_material_fields_to_problem,\nmake_grid,\n)\nclass FullScenario(Scenario2D):\n\"\"\"This Scenario is based on benchmark 4 of the following paper:\n    Jean-Francois Aubry, Oscar Bates, Christian Boehm, et al., \"Benchmark problems for\n    transcranial ultrasound simulation: Intercomparison of compressional wave models\",\n    The Journal of the Acoustical Society of America 152, 1003 (2022);\n    doi: 10.1121/10.0013426\n    https://asa.scitation.org/doi/pdf/10.1121/10.0013426\n    \"\"\"\n_SCENARIO_ID = \"the_id_for_this_scenario\"\n\"\"\"\n    Target attributes:\n        target_id: the string id of the target.\n        center: the location of the center of the target (in meters).\n        radius: the radius of the target (in meters).\n        description: a text describing the target.\n    \"\"\"\n_TARGET_OPTIONS = {\n\"target_1\": Target(\"target_1\", np.array([0.064, 0.0]), 0.004, \"\"),\n}\n\"\"\"\n    The order of returned materials defines the layering of the scenario.\n    \"\"\"\nmaterial_layers = [\n\"water\",\n\"skin\",\n\"cortical_bone\",\n\"trabecular_bone\",\n\"brain\",\n]\ndef __init__(self, complexity=\"fast\"):\n\"\"\"\n        Instantiate a new scenario.\n        The origin defines the spatial coordinates of grid position (0, 0, 0).\n        \"\"\"\nself._target_id = \"target_1\"\nsuper().__init__(\norigin=np.array([0.0, -0.035]),\ncomplexity=complexity,\n)\n@property\ndef _material_outline_upsample_factor(self) -&gt; int:\n\"\"\"\n        The factor to use when upsampling the material field before\n        detecting transitions between materials. If the factor is N, then each pixel\n        will be split into N^2 pixels. Defaults to 1 (no resampling).\n        \"\"\"\nreturn 8\ndef _compile_problem(self, center_frequency) -&gt; stride.Problem:\n\"\"\"The problem definition for the scenario.\"\"\"\nextent = np.array([0.12, 0.07])  # m\n# scenario constants\nspeed_water = 1500  # m/s\n# desired resolution for complexity=fast\nppw = 6\n# compute resolution\ndx = speed_water / center_frequency / ppw  # m\ngrid = make_grid(extent=extent, dx=dx)\nproblem = stride.Problem(\nname=f\"{self.scenario_id}-{self.complexity}\", grid=grid\n)\nproblem = add_material_fields_to_problem(\nproblem=problem,\nmaterials=self.get_materials(center_frequency),\nlayer_ids=self.layer_ids,\nmasks={\nname: _create_scenario_1_mask(name, problem.grid)\nfor name in self.material_layers\n},\n)\nreturn problem\ndef get_default_source(self) -&gt; sources.Source:\n\"\"\"The transducer source for the scenario.\"\"\"\nreturn sources.FocusedSource2D(\nposition=np.array([0.0, 0.0]),\ndirection=np.array([1.0, 0.0]),\naperture=0.064,\nfocal_length=0.064,\nnum_points=1000,\n)\ndef _create_scenario_1_mask(material, grid):\n# layers are defined by X position\ndx = grid.space.spacing[0]\nlayers_m = np.array(\n[\n0.026,  # water\n0.004,  # skin\n0.0015,  # cortical bone\n0.004,  # trabecular bone\n0.001,  # cortical bone\n0.0835,  # brain\n]\n)\ninterfaces = np.cumsum(layers_m)\nmask = np.zeros(grid.space.shape, dtype=bool)\nif material == \"water\":\n_fill_mask(mask, start=0, end=interfaces[0], dx=dx)\nelif material == \"skin\":\n_fill_mask(mask, start=interfaces[0], end=interfaces[1], dx=dx)\nelif material == \"cortical_bone\":\n_fill_mask(mask, start=interfaces[1], end=interfaces[2], dx=dx)\n_fill_mask(mask, start=interfaces[3], end=interfaces[4], dx=dx)\nelif material == \"trabecular_bone\":\n_fill_mask(mask, start=interfaces[2], end=interfaces[3], dx=dx)\nelif material == \"brain\":\n_fill_mask(mask, start=interfaces[4], end=None, dx=dx)\nelse:\nraise ValueError(material)\nreturn mask\ndef _fill_mask(mask, start, end, dx):\n# fill linearly along the x axis\nif end is None:\nn = int(start / dx)\nmask[n:] = True\nelse:\nn = int(start / dx)\nm = int(end / dx)\nmask[n:m] = True\n</code></pre>"},{"location":"generated/gallery/plot_full_scenario/#running-the-scenario","title":"Running the scenario","text":"<pre><code>scenario = FullScenario()\nresult = scenario.simulate_steady_state()\nassert isinstance(result, SteadyStateResult2D)\nresult.render_steady_state_amplitudes(show_material_outlines=False)\n</code></pre> <p>Out:</p> <pre><code>creating a grid with shape: (241, 141) for extent: [0.12 0.07] m\nEstimated time to complete simulation: 47 seconds. Memory required is 8.110059917325207 GB (available 73.624408064 GB). These values are approximated.\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\n</code></pre> <p>Total running time of the script: ( 0 minutes  21.832 seconds)</p> <p> Download Python source code: plot_full_scenario.py</p> <p> Download Jupyter notebook: plot_full_scenario.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/plot_metrics/","title":"Reading simulation metrics","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/gallery/plot_metrics/#reading-simulation-metrics","title":"Reading simulation metrics","text":"<p>Note</p> <p>NDK and its examples are under constant development, more information and content will be added to this example soon!</p> <p>This example demonstrates how to display the metrics collected from the simulation.</p>"},{"location":"generated/gallery/plot_metrics/#rendering-scenario","title":"Rendering scenario","text":"<pre><code>import neurotechdevkit as ndk\nscenario = ndk.make(\"scenario-0-v0\")\nresult = scenario.simulate_steady_state()\nassert isinstance(result, ndk.results.SteadyStateResult2D)\nresult.render_steady_state_amplitudes(show_material_outlines=False)\n</code></pre> <p>Out:</p> <pre><code>creating a grid with shape: (101, 81) for extent: [0.05 0.04] m\nEstimated time to complete simulation: 44 seconds. Memory required is 8.09906664298232 GB (available 73.624408064 GB). These values are approximated.\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\n</code></pre>"},{"location":"generated/gallery/plot_metrics/#printing-metrics","title":"Printing metrics","text":"<pre><code>for metric, metric_value in result.metrics.items():\nprint(f\"{metric}:\")\nprint(f\"\\t {metric_value['description']}\")\nprint(\nf\"\\t Unit: {metric_value['unit-of-measurement']} Value: {metric_value['value']}\"\n)\nprint()\n</code></pre> <p>Out:</p> <pre><code>focal_gain:\n         The ratio between the mean steady-state pressure amplitude inside the target and that of the ambient, expressed in Decibels. The ambient pressure is calculated by the mean steady-state pressure amplitude inside the brain but excluding the target.\n         Unit: dB Value: 0.5130329427483855\n\nI_ta_target:\n         The temporal-average intensity (ITA) within the target region. ITA is calculated by integrating the wave intensity over a full period and dividing by the period. An example FDA recommended limit for ITA is 720 mW/cm\u00b2 (the exact value can vary depending on the intended use).\n         Unit: mW/cm\u00b2 Value: 6.348843441125598e-05\n\nI_ta_off_target:\n         The temporal-average intensity (ITA) within the brain but outside of the target. ITA is calculated by integrating the wave intensity over a full period and dividing by the period. An example FDA recommended limit for ITA is 720 mW/cm\u00b2 (the exact value can vary depending on the intended use).\n         Unit: mW/cm\u00b2 Value: 6.270932089146393e-05\n\nI_pa_target:\n         The pulse-average intensity (IPA) within the target region. IPA is calculated by integrating the intensity over the pulse and dividing by the length of the pulse. For steady-state waves, IPA is equal to the temporal-average intensity. An example FDA recommended limit for IPA is 190 W/cm\u00b2 (the exact value can vary depending on the intended use).\n         Unit: W/cm\u00b2 Value: 6.348843441125598e-08\n\nI_pa_off_target:\n         The pulse-average intensity (IPA) within the brain but outside of the target. IPA is calculated by integrating the intensity over the pulse and dividing by the length of the pulse. For steady-state waves, IPA is equal to the temporal-average intensity. An example FDA recommended limit for IPA is 190 W/cm\u00b2 (the exact value can vary depending on the intended use).\n         Unit: W/cm\u00b2 Value: 6.270932089146393e-08\n\nmechanical_index_all:\n         The mechanical index (MI) over all materials in the full simulation volume. MI is defined as peak negative pressure divided by the square root of the frequency of the ultrasound wave. An example FDA recommended limit for MI is 1.9 (the exact value can vary depending on the intended use).\n         Unit: Pa \u221as\u0305 Value: 218.41479668179713\n\nmechanical_index_water:\n         The mechanical index (MI) within the water layer. The MI is defined as peak negative pressure divided by the square root of the frequency of the ultrasound wave. An example FDA recommended limit for MI is 1.9 (the exact value can vary depending on the intended use).\n         Unit: Pa \u221as\u0305 Value: 218.41479668179713\n\nmechanical_index_cortical_bone:\n         The mechanical index (MI) within the cortical_bone layer. The MI is defined as peak negative pressure divided by the square root of the frequency of the ultrasound wave. An example FDA recommended limit for MI is 1.9 (the exact value can vary depending on the intended use).\n         Unit: Pa \u221as\u0305 Value: 185.44533956305997\n\nmechanical_index_brain:\n         The mechanical index (MI) within the brain layer. The MI is defined as peak negative pressure divided by the square root of the frequency of the ultrasound wave. An example FDA recommended limit for MI is 1.9 (the exact value can vary depending on the intended use).\n         Unit: Pa \u221as\u0305 Value: 152.13549376135828\n\nmechanical_index_tumor:\n         The mechanical index (MI) within the tumor layer. The MI is defined as peak negative pressure divided by the square root of the frequency of the ultrasound wave. An example FDA recommended limit for MI is 1.9 (the exact value can vary depending on the intended use).\n         Unit: Pa \u221as\u0305 Value: 90.78413928036862\n</code></pre> <p>Total running time of the script: ( 0 minutes  12.988 seconds)</p> <p> Download Python source code: plot_metrics.py</p> <p> Download Jupyter notebook: plot_metrics.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/plot_multiple_sources/","title":"Adding multiple sources","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/gallery/plot_multiple_sources/#adding-multiple-sources","title":"Adding multiple sources","text":"<p>Note</p> <p>NDK and its examples are under constant development, more information and content will be added to this example soon!</p> <p>Adding multiple sources for transcranial ultrasound stimulation enables greater precision and control in targeting specific areas of the brain.</p> <p>By choosing the phase of ultrasound waves for each source, a combined beam can be created that is focused on the desired target precisely. This allows for complex wave patterns that open up new possibilities for therapies.</p> <p>Out:</p> <pre><code>creating a grid with shape: (101, 81) for extent: [0.05 0.04] m\nEstimated time to complete simulation: 2 minutes. Memory required is 27.853101606717864 GB (available 73.624408064 GB). These values are approximated.\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\ngcc -O3 -g -fPIC -Wall -std=c99 -march=native -Wno-unused-result -Wno-unused-variable -Wno-unused-but-set-variable -ffast-math -shared -fopenmp /tmp/devito-jitcache-uid1001/284ade1f61cfd35c1dc7508ee5c551ecfab22af0.c -lm -o /tmp/devito-jitcache-uid1001/284ade1f61cfd35c1dc7508ee5c551ecfab22af0.so\n/home/circleci/project/src/neurotechdevkit/rendering/_animations.py:118: UserWarning: You passed in an explicit save_count=142 which is being ignored in favor of frames=142.\n  anim = FuncAnimation(\n</code></pre> Once Loop Reflect <p></p> <pre><code>import numpy as np\nimport neurotechdevkit as ndk\nscenario = ndk.make(\"scenario-0-v0\")\ns1 = ndk.sources.FocusedSource2D(\nposition=np.array([0.01, 0.0]),\ndirection=np.array([0.92, 0.25]),\naperture=0.01,\nfocal_length=0.022,\nnum_points=1000,\n)\ns2 = ndk.sources.FocusedSource2D(\nposition=np.array([0.04, -0.002]),\ndirection=np.array([-0.85, 0.35]),\naperture=0.01,\nfocal_length=0.011,\nnum_points=1000,\ndelay=5.1e-6,\n)\nscenario.add_source(s1)\nscenario.add_source(s2)\nresult = scenario.simulate_pulse()\nassert isinstance(result, ndk.results.PulsedResult2D)\nresult.render_pulsed_simulation_animation()\n</code></pre> <p>Total running time of the script: ( 1 minutes  21.806 seconds)</p> <p> Download Python source code: plot_multiple_sources.py</p> <p> Download Jupyter notebook: plot_multiple_sources.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/plot_phased_array_source/","title":"Phased array source","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/gallery/plot_phased_array_source/#phased-array-source","title":"Phased array source","text":"<p>Phased arrays consist of multiple individual transducer elements arranged in a specific pattern, such as a linear or circle. Each element can be controlled independently, allowing for precise manipulation of the generated ultrasound waves. By adjusting the timing or phase of the signals sent to these elements, the ultrasound waves can be focused, steered, and shaped without mechanically moving the transducer.</p> <p>They are becoming increasingly popular in the field of transcranial ultrasound stimulation as they offer several advantages over traditional ultrasound transducers -- among others are precise targeting and better control over steering and shaping:</p> <ul> <li> <p>Precise targeting: as individual transducer elements can be individually controlled, it allows for the generation of a focused ultrasound beam with high spatial accuracy. This enables the stimulation of specific brain regions without affecting the surrounding healthy tissue and minimizes the risk of potential side effects.</p> </li> <li> <p>Steering and shaping: The phased array technology allows the ultrasound beam to be electronically steered and shaped in real-time without mechanically moving the transducers. This enables targeting of different brain regions or adjusting the stimulation pattern as needed during a session, making the procedure more versatile and adaptable.</p> </li> </ul> <p>These features allow the stimulation to be tailored to suit to more specific requirements. With ongoing research and development, they have the potential to revolutionize the field of brain stimulation and offer new treatment options for a range of neurological and psychiatric disorders.</p> <p>This notebook will show how to define a phased array within NDK and experiment with some of the available features. For more details, checkout the NDK documentation.</p>"},{"location":"generated/gallery/plot_phased_array_source/#phased-arrays-components","title":"Phased Arrays Components","text":"<ul> <li>Elements: A phased array consists of multiple transducer elements that can be individually controlled in terms of phase.</li> <li>Pitch: The pitch of a phased array refers to the distance between adjacent transducer elements, and affects the resolution of the array.</li> <li>Spacing: The spacing between transducer elements affects the width and shape of the ultrasound beam that is produced.</li> <li>Aperture: The aperture of a phased array refers to the total size of the array, and affects the power and focus of the ultrasound beam.</li> <li>Element width: The element width of a phased array refers to the size of each individual transducer element. Wider elements generally result in a more powerful and focused beam, while narrower elements can increase the resolution of the array.</li> <li>Tilt angle: The tilt angle of a phased array refers to the angle at which the ultrasound beam is directed relative to the normal of plane of the array. Tilt angle can be adjusted by controlling the phase (delays) of the individual transducer elements.</li> </ul> <p>The image above shows a schematic representation of a phased array.</p> <p></p> <p>The image above shows the axis definition and the look of a phased array in the real world. Image source link.</p> <p>Below we will go through some examples of how to use the NDK to API to simulate Phased Arrays in the most common settings. Examples we will cover:</p> <ul> <li>Setting up a tilted wavefront</li> <li>Focusing phased arrays</li> <li>Setting up custom delays per element</li> <li>Phased arrays in 3D</li> </ul>"},{"location":"generated/gallery/plot_phased_array_source/#phased-array-ndk-api","title":"Phased Array NDK API","text":"<p>A PhasedArraySource receives the following parameters:</p> <ul> <li>position <code>(npt.NDArray[np.float_])</code>: a numpy float array indicating     the coordinates (in meters) of the point at the center of the     source, which is the point that bisects the line segment source.</li> <li>direction <code>(npt.NDArray[np.float_])</code>: a numpy float array representing     a vector located at position that is perpendicular to the plane     of the source. Only the orientation of <code>direction</code> affects the     source, the length of the vector has no affect. See the     <code>unit_direction</code> property.</li> <li>num_points <code>(int)</code>: the number of point sources to use when simulating     the source.</li> <li>num_elements <code>(int)</code>: the number of elements of the phased array.</li> <li>pitch <code>(float)</code>: the distance (in meters) between the centers of neighboring     elements in the phased array.</li> <li>element_width <code>(float)</code>: the width (in meters) of each individual element of     the array.</li> <li>tilt_angle <code>(float)</code>: the desired tilt angle (in degrees) of the wavefront.     The angle is measured between the direction the wavefront travels and the     normal to the surface of the transducer, with positive angles resulting in a     counter-clockwise tilt away from the normal.</li> <li>focal_length <code>(float)</code>: the distance (in meters) from <code>position</code> to the focal     point.</li> <li>delay <code>(float, optional)</code>: the delay (in seconds) that the source will wait     before emitting.</li> <li>element_delays: an 1D array with the delays (in seconds) for each element of the     phased array. Delays from <code>element_delays</code> take precedence; No other     argument affected the delays (<code>tilt_angle</code>, <code>focal_length</code> or <code>delay</code>)     would be considered. ValueError will be raised if provided values for either     <code>tilt_angle</code>, <code>focal_length</code> or <code>delay</code> are non-default.</li> </ul>"},{"location":"generated/gallery/plot_phased_array_source/#tilting-the-wavefront","title":"Tilting the Wavefront","text":"<p>Tilting the wavefront can be achieved simply by setting the <code>tilt_angle</code> argument different than zero. Positive angles result in counter-clockwise rotations.</p> <pre><code>import numpy as np\nimport neurotechdevkit as ndk\n# define the source\nsource = ndk.sources.PhasedArraySource2D(\nposition=np.array([0.0, 0.0]),\ndirection=np.array([1.0, 0.0]),\nnum_elements=20,\npitch=1.5e-3,\nelement_width=1.2e-3,\ntilt_angle=30,\nnum_points=1000,\n)\nscenario = ndk.make(\"scenario-1-2d-v0\")\nscenario.add_source(source)\nresult = scenario.simulate_steady_state()\nassert isinstance(result, ndk.results.SteadyStateResult2D)\nresult.render_steady_state_amplitudes()\n</code></pre> <p></p> <p>Out:</p> <pre><code>creating a grid with shape: (241, 141) for extent: [0.12 0.07] m\nEstimated time to complete simulation: 46 seconds. Memory required is 8.11064033080535 GB (available 73.624408064 GB). These values are approximated.\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\ngcc -O3 -g -fPIC -Wall -std=c99 -march=native -Wno-unused-result -Wno-unused-variable -Wno-unused-but-set-variable -ffast-math -shared -fopenmp /tmp/devito-jitcache-uid1001/cca4a12a3521ab1de2785369917754e4dc60ea90.c -lm -o /tmp/devito-jitcache-uid1001/cca4a12a3521ab1de2785369917754e4dc60ea90.so\n</code></pre>"},{"location":"generated/gallery/plot_phased_array_source/#focusing","title":"Focusing","text":"<p>Similarly, a phased array can be focused by applying delays in a specific way. Such delays are automatically computed when <code>focal_length</code> is defined. Let's explore how the API looks like:</p> <pre><code>scenario = ndk.make(\"scenario-1-2d-v0\")\nphased_array = ndk.sources.PhasedArraySource2D(\nposition=np.array([0.0, 0.0]),\ndirection=np.array([1.0, 0.0]),\nnum_elements=20,\npitch=1.5e-3,\nelement_width=1.2e-3,\nfocal_length=0.03,\nnum_points=1000,\n)\nscenario.add_source(phased_array)\nprint(f\"Focal point is: {phased_array.focal_point}\")\n</code></pre> <p>Out:</p> <pre><code>Focal point is: [0.03 0.  ]\n</code></pre> <p><code>focal_point</code> shows the coordinates (in meters) where the array focuses.</p> <pre><code>result = scenario.simulate_steady_state()\nassert isinstance(result, ndk.results.SteadyStateResult2D)\nresult.render_steady_state_amplitudes()\n</code></pre> <p></p> <p>Out:</p> <pre><code>creating a grid with shape: (241, 141) for extent: [0.12 0.07] m\nEstimated time to complete simulation: 47 seconds. Memory required is 8.110192292329451 GB (available 73.624408064 GB). These values are approximated.\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\ngcc -O3 -g -fPIC -Wall -std=c99 -march=native -Wno-unused-result -Wno-unused-variable -Wno-unused-but-set-variable -ffast-math -shared -fopenmp /tmp/devito-jitcache-uid1001/fd8f46a495b0020134ca229700238e7d1d852637.c -lm -o /tmp/devito-jitcache-uid1001/fd8f46a495b0020134ca229700238e7d1d852637.so\n</code></pre> <p>We can see that the arrays focuses at a distance equal to <code>focal_length</code>.</p>"},{"location":"generated/gallery/plot_phased_array_source/#custom-wavefront-shapes","title":"Custom Wavefront Shapes","text":"<p>In the examples shown so far we specified high level arguments and the required delays were automatically computed. The NDK API offers also the possibility to specify delays directly to create arbitrary wavefront shapes.</p> <p>In the example below we apply monotonically increasing delays to mimic a counter-clockwise angle.</p> <pre><code>scenario = ndk.make(\"scenario-1-2d-v0\")\nphased_array = ndk.sources.PhasedArraySource2D(\nposition=np.array([0.0, 0.0]),\ndirection=np.array([1.0, 0.0]),\nnum_elements=20,\npitch=1.5e-3,\nelement_width=1.2e-3,\nelement_delays=np.linspace(0, 1e-5, 20),\nnum_points=1000,\n)\nscenario.add_source(phased_array)\nresult = scenario.simulate_steady_state()\nassert isinstance(result, ndk.results.SteadyStateResult2D)\nresult.render_steady_state_amplitudes()\n</code></pre> <p></p> <p>Out:</p> <pre><code>creating a grid with shape: (241, 141) for extent: [0.12 0.07] m\nEstimated time to complete simulation: 46 seconds. Memory required is 8.110670878883253 GB (available 73.624408064 GB). These values are approximated.\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\ngcc -O3 -g -fPIC -Wall -std=c99 -march=native -Wno-unused-result -Wno-unused-variable -Wno-unused-but-set-variable -ffast-math -shared -fopenmp /tmp/devito-jitcache-uid1001/0055a1babbb73e4e30c2b5026d34deb4bcb07a18.c -lm -o /tmp/devito-jitcache-uid1001/0055a1babbb73e4e30c2b5026d34deb4bcb07a18.so\n</code></pre>"},{"location":"generated/gallery/plot_phased_array_source/#phased-arrays-in-three-dimensions","title":"Phased Arrays In Three Dimensions","text":"<p>There are two extra details to consider when creating 3D phased array sources: the <code>height</code> of the elements and the position of the <code>center_line</code>.</p> <ul> <li>Height: Is the distance (in meters) of the element measured in a straight line   perpendicular to the <code>element_width</code> (see image below)</li> <li>Center line: As the name indicates, is the line that crosses the centers of the   elements. Must be orthogonal to the direction line.</li> </ul> <p></p> <p>The rest of the API is identical for both 2D and 3D scenarios.</p> <pre><code>scenario = ndk.make(\"scenario-1-3d-v0\")\nphased_3d = ndk.sources.PhasedArraySource3D(\nposition=np.array([0.0, 0.0, 0.0]),\ndirection=np.array([1.0, 0.0, 0.0]),\ncenter_line=np.array([0.0, 0.0, 1.0]),\nnum_points=20_000,\nnum_elements=16,\npitch=1.5e-3,\nelement_width=1.2e-3,\ntilt_angle=30,\nheight=5.0e-3,\n)\nscenario.add_source(phased_3d)\nresults = scenario.simulate_steady_state()\nassert isinstance(results, ndk.results.SteadyStateResult3D)\nresults.render_steady_state_amplitudes(slice_axis=1, slice_position=0.0)\n</code></pre> <p></p> <p>Out:</p> <pre><code>creating a grid with shape: (241, 141, 141) for extent: [0.12 0.07 0.07] m\nEstimated time to complete simulation: 17 minutes. Memory required is 10.12265384241533 GB (available 73.624408064 GB). These values are approximated.\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\ngcc -O3 -g -fPIC -Wall -std=c99 -march=native -Wno-unused-result -Wno-unused-variable -Wno-unused-but-set-variable -ffast-math -shared -fopenmp /tmp/devito-jitcache-uid1001/36788220aacf20ede390405a475fe425008c3199.c -lm -o /tmp/devito-jitcache-uid1001/36788220aacf20ede390405a475fe425008c3199.so\n</code></pre> <p>Total running time of the script: ( 6 minutes  49.643 seconds)</p> <p> Download Python source code: plot_phased_array_source.py</p> <p> Download Jupyter notebook: plot_phased_array_source.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/plot_pulsed_simulation/","title":"Plot pulsed simulation","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/gallery/plot_pulsed_simulation/#plot-pulsed-simulation","title":"Plot pulsed simulation","text":"<p>This example demonstrates how to execute a pulsed simulation using ndk</p> <pre><code>import neurotechdevkit as ndk\nscenario = ndk.make(\"scenario-0-v0\")\nresult = scenario.simulate_pulse()\nassert isinstance(result, ndk.results.PulsedResult2D)\nresult.render_pulsed_simulation_animation()\n</code></pre> <p>Out:</p> <pre><code>/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/types/basic.py:613: DeprecationWarning: invalid escape sequence '\\-'\n\"\"\"\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API\n  warnings.warn(\"pkg_resources is deprecated as an API\", DeprecationWarning)\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.\nImplementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n  declare_namespace(pkg)\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\nImplementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n  declare_namespace(pkg)\nWARNING: DEVITO_ARCH environment variable not set and might cause compilation errors. See NDK documentation for help.\ncreating a grid with shape: (101, 81) for extent: [0.05 0.04] m\nEstimated time to complete simulation: 2 minutes. Memory required is 28.92546936289519 GB (available 73.624408064 GB). These values are approximated.\nDefault Devito configuration:\n         * autotuning=off\n         * develop-mode=False\n         * mpi=False\n         * log-level=DEBUG\n         * language=openmp\n(ShotID 0) Preparing to run state for shot\n(ShotID 0) Estimated bandwidth for the propagated wavelet 0.257-0.724 MHz\n(ShotID 0) Spatial grid spacing (0.500 mm | 4.145 PPW) is higher than dispersion limit (0.415 mm | 5.000 PPW)\n(ShotID 0) Time grid spacing (0.083 \u03bcs | 46%) is above OT2 limit (0.080 \u03bcs) and below OT4 limit (0.145 \u03bcs)\n(ShotID 0) Selected undersampling level 4\n(ShotID 0) Selected time stepping scheme OT4\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\nOperator `acoustic_iso_state` instance configuration:\n         * subs={h_x: 0.0005, h_y: 0.0005}\n         * opt=advanced\n         * platform=None\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\nOperator `acoustic_iso_state` generated in 10.47 s\n  * lowering.Clusters: 4.96 s (47.5 %)\n     * specializing.Clusters: 3.33 s (31.9 %)\n  * lowering.Expressions: 3.03 s (29.0 %)\nFlops reduction after symbolic optimization: [3457 --&gt; 892]\nrecompiling for non-existent cache dir (/tmp/devito-codepy-uid1001/300b924/ae802b3a0a758d83087b6d6dfec378ed).\ngcc -O3 -g -fPIC -Wall -std=c99 -march=native -Wno-unused-result -Wno-unused-variable -Wno-unused-but-set-variable -ffast-math -shared -fopenmp /tmp/devito-jitcache-uid1001/300b924d7d2dce0732c3931f2d6f9c3293d56c3f.c -lm -o /tmp/devito-jitcache-uid1001/300b924d7d2dce0732c3931f2d6f9c3293d56c3f.so\nOperator `acoustic_iso_state` jit-compiled `/tmp/devito-jitcache-uid1001/300b924d7d2dce0732c3931f2d6f9c3293d56c3f.c` in 4.11 s with `GNUCompiler`\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/numpy/ctypeslib.py:137: DeprecationWarning: \n  `numpy.distutils` is deprecated since NumPy 1.23.0, as a result\n  of the deprecation of `distutils` itself. It will be removed for\n  Python &gt;= 3.12. For older Python versions it will remain present.\n  It is recommended to use `setuptools &lt; 60.0` for those Python versions.\n  For more details, see:\n    https://numpy.org/devdocs/reference/distutils_status_migration.html \n  from numpy.distutils.misc_util import get_shared_lib_extension\n/home/circleci/project/src/neurotechdevkit/rendering/_animations.py:118: UserWarning: You passed in an explicit save_count=127 which is being ignored in favor of frames=127.\n  anim = FuncAnimation(\n</code></pre> Once Loop Reflect"},{"location":"generated/gallery/plot_pulsed_simulation/#generating-a-video-file","title":"Generating a video file","text":"<p>You can also generate a video file of the simulation (which requires ffmpeg installed).</p> <p>To create and save the video as <code>animation.mp4</code> in the current folder, all you need is the execute following command:</p> <pre><code>result.create_video_file(\"animation.mp4\", fps=25, overwrite=True)\n</code></pre> <p>Out:</p> <pre><code>/home/circleci/project/src/neurotechdevkit/rendering/_animations.py:118: UserWarning: You passed in an explicit save_count=127 which is being ignored in favor of frames=127.\n  anim = FuncAnimation(\nSaved to animation.mp4 file.\n</code></pre> <p>Total running time of the script: ( 1 minutes  38.602 seconds)</p> <p> Download Python source code: plot_pulsed_simulation.py</p> <p> Download Jupyter notebook: plot_pulsed_simulation.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/plot_scenarios/","title":"Plot scenarios","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/gallery/plot_scenarios/#plot-scenarios","title":"Plot scenarios","text":"<p>This example demonstrates how to execute a steady state simulation using ndk</p> <pre><code>import neurotechdevkit as ndk\ndef plot_scenario(scenario_id):\nprint(f\"Simulating scenario: {scenario_id}\")\nscenario = ndk.make(scenario_id)\nresult = scenario.simulate_steady_state()\nresult.render_steady_state_amplitudes(show_material_outlines=False)\n</code></pre>"},{"location":"generated/gallery/plot_scenarios/#simulating-scenario-scenario-0-v0","title":"Simulating scenario: scenario-0-v0","text":"<pre><code>plot_scenario(\"scenario-0-v0\")\n</code></pre> <p>Out:</p> <pre><code>Simulating scenario: scenario-0-v0\ncreating a grid with shape: (101, 81) for extent: [0.05 0.04] m\nEstimated time to complete simulation: 44 seconds. Memory required is 8.09906664298232 GB (available 73.624408064 GB). These values are approximated.\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\ngcc -O3 -g -fPIC -Wall -std=c99 -march=native -Wno-unused-result -Wno-unused-variable -Wno-unused-but-set-variable -ffast-math -shared -fopenmp /tmp/devito-jitcache-uid1001/4f8ef5056730ae3c7fbdc107b4e51890098e4f0b.c -lm -o /tmp/devito-jitcache-uid1001/4f8ef5056730ae3c7fbdc107b4e51890098e4f0b.so\n</code></pre>"},{"location":"generated/gallery/plot_scenarios/#simulating-scenario-scenario-1-2d-v0","title":"Simulating scenario: scenario-1-2d-v0","text":"<pre><code>plot_scenario(\"scenario-1-2d-v0\")\n</code></pre> <p>Out:</p> <pre><code>Simulating scenario: scenario-1-2d-v0\ncreating a grid with shape: (241, 141) for extent: [0.12 0.07] m\nEstimated time to complete simulation: 47 seconds. Memory required is 8.110059917325207 GB (available 73.624408064 GB). These values are approximated.\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\ngcc -O3 -g -fPIC -Wall -std=c99 -march=native -Wno-unused-result -Wno-unused-variable -Wno-unused-but-set-variable -ffast-math -shared -fopenmp /tmp/devito-jitcache-uid1001/8aed0abf685aca05537adb2a263f72cdb8d7f4cf.c -lm -o /tmp/devito-jitcache-uid1001/8aed0abf685aca05537adb2a263f72cdb8d7f4cf.so\n</code></pre>"},{"location":"generated/gallery/plot_scenarios/#simulating-scenario-scenario-2-2d-v0","title":"Simulating scenario: scenario-2-2d-v0","text":"<pre><code>plot_scenario(\"scenario-2-2d-v0\")\n</code></pre> <p>Out:</p> <pre><code>Simulating scenario: scenario-2-2d-v0\ncreating a grid with shape: (451, 341) for extent: [0.225 0.17 ] m\nEstimated time to complete simulation: 1 minutes. Memory required is 8.207058332240669 GB (available 73.624408064 GB). These values are approximated.\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\ngcc -O3 -g -fPIC -Wall -std=c99 -march=native -Wno-unused-result -Wno-unused-variable -Wno-unused-but-set-variable -ffast-math -shared -fopenmp /tmp/devito-jitcache-uid1001/0ec68a19d4dc4792357f350ee80ee7e46d45a036.c -lm -o /tmp/devito-jitcache-uid1001/0ec68a19d4dc4792357f350ee80ee7e46d45a036.so\n</code></pre> <p>Total running time of the script: ( 1 minutes  2.143 seconds)</p> <p> Download Python source code: plot_scenarios.py</p> <p> Download Jupyter notebook: plot_scenarios.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/plot_store_results/","title":"Save and load results","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/gallery/plot_store_results/#save-and-load-results","title":"Save and load results","text":"<p>Note</p> <p>NDK and its examples are under constant development, more information and content will be added to this example soon!</p> <p>This example demonstrates how a simulation can be executed and stored in one computer and the results can be loaded and rendered later in the same computer or another one.</p> <p>Execute the following code in a computer with ndk installed</p> <pre><code>import neurotechdevkit as ndk\nscenario = ndk.make(\"scenario-0-v0\")\nresult = scenario.simulate_steady_state()\nresult.save_to_disk(\"scenario-0-v0-results.tar.gz\")\n</code></pre> <p>Out:</p> <pre><code>creating a grid with shape: (101, 81) for extent: [0.05 0.04] m\nEstimated time to complete simulation: 44 seconds. Memory required is 8.09906664298232 GB (available 73.624408064 GB). These values are approximated.\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\nA result artifact has been saved to scenario-0-v0-results.tar.gz.\n</code></pre> <p>The output file from the previous step could be copied to another computer with ndk installed or stored for future use. The results can be loaded running the following code:</p> <pre><code>import neurotechdevkit as ndk  # noqa: E402\nresult2 = ndk.load_result_from_disk(\"scenario-0-v0-results.tar.gz\")\nassert isinstance(result2, ndk.results.SteadyStateResult2D)\nresult2.render_steady_state_amplitudes(show_material_outlines=False)\n</code></pre> <p></p> <p>Out:</p> <pre><code>Recreating the scenario for the result from saved metadata...\ncreating a grid with shape: (101, 81) for extent: [0.05 0.04] m\n</code></pre> <p>Total running time of the script: ( 0 minutes  12.814 seconds)</p> <p> Download Python source code: plot_store_results.py</p> <p> Download Jupyter notebook: plot_store_results.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"usage/defining_sources/","title":"Sources","text":"<p>NDK provides a simple but flexible API to control the parameters of sources. Users can specify the parameters and placement of sources, and add them to their simulation.</p> <pre><code>import neurotechdevkit as ndk\nimport numpy as np\nscenario = ndk.make('scenario-2-2d-v0')\nscenario.current_target_id = 'right-inferior-frontal-gyrus'\nsource = ndk.sources.FocusedSource2D(\nposition=np.array([0.19, 0.07]),\ndirection=np.array([-0.5, -1.]),\naperture=0.06,\nfocal_length=0.08,\nnum_points=3000\n)\nscenario.add_source(source)\nscenario.render_layout()\n</code></pre> <p></p> <p>In the visualization of the source, the <code>position</code> parameter of the source corresponds to the point located at the midpoint of the dark arc on the front (concave) edge. The <code>position</code> and <code>direction</code> of the source are accurately shown in the plot, while the <code>aperture</code> and <code>focal_length</code> (radius of curvature) of the rendered source approximately visualize what is defined in the source object. The blue dotted lines indicate the ultrasound waves.</p> <p>Transducer locations are currently not constrained within the scenario or by materials, and so care needs to be taken when configuring a source so that it is not embedded inside the skull, for instance, or located outside of the simulation volume.</p> <p>In the future, we plan to implement constraints to avoid overlapping with solid materials or other sources, and to also add helper utilities to assist with placing sources along the surface of the skull using fewer degrees of freedom.</p> <p>If a source is not specified before the scenario is rendered or simulated, then a default source will be used. So you should add the source to the scenario before doing either of these operations (rendering or simulating).</p> <p>Note</p> <p>The visualization of the source in 2D plots currently has some scaling limitations, and transducers with short focal lengths can appear very small. This only affects the visualization and not the simulation, and will be improved in future versions.</p> <p>The implemented source options are:</p> <ul> <li><code>FocusedSource2D</code></li> <li><code>FocusedSource3D</code></li> <li><code>PlanarSource2D</code></li> <li><code>PlanarSource3D</code></li> <li><code>PhasedArraySource2D</code></li> <li><code>PhasedArraySource3D</code></li> </ul> <p>The 2D sources are for 2D scenarios and the 3D sources for 3D scenarios. The parameters to configure the sources are identical between focused and planar sources, except that planar sources have a pre-defined focal length of <code>np.inf</code>.</p> <pre><code>import neurotechdevkit as ndk\nimport numpy as np\nscenario = ndk.make('scenario-2-2d-v0')\nscenario.current_target_id = 'right-inferior-frontal-gyrus'\nsource_position = np.array([0.19, 0.07])\nsource = ndk.sources.PlanarSource2D(\nposition=source_position,\ndirection=scenario.target_center - source_position,\naperture=0.06,\nnum_points=3000\n)\nscenario.add_source(source)\nscenario.render_layout()\n</code></pre> <p></p>"},{"location":"usage/gpu/","title":"GPU support","text":"<p>In order to use your GPU to run NDK simulations you will have to install the NVIDIA HPC SDK.</p> <p>Warning</p> <p>Make sure the HPC SDK environment variables are exported.</p> <p>You will only have to export one environment variable to enable the GPU support for NDK:</p> <pre><code>export PLATFORM=\"nvidia-acc\"\n</code></pre> <p>Now when running NDK simulations you should be able to see <code>platform=nvidiaX</code> in the execution output:</p> <pre><code>import neurotechdevkit as ndk\nscenario = ndk.make('scenario-2-2d-v0')\nresult = scenario.simulate_steady_state()\nresult.render_steady_state_amplitudes()\n</code></pre> <p>Output: <pre><code>...\n\nOperator `acoustic_iso_state` instance configuration:\n     * subs={h_x: 0.0005, h_y: 0.0005}\n* opt=advanced\n     * compiler=pgcc\n     * language=openacc\n     * platform=nvidiaX\n\n...\n</code></pre></p> <p>Warning</p> <p>Simulations with high memory requirement (e.g. 3D simulations) may not fit in the GPU and running them with GPU acceleration might crash the simulation.</p>"},{"location":"usage/loading_scenarios/","title":"Scenarios","text":"<p>Scenarios provide a convenient structure to describe the environment, transducers, and sensors. A collection of preconfigured scenarios are provided with NDK, and can be loaded using a scenario id.</p> <p>There are currently three scenarios provided with NDK, two of which have both a 2D and 3D version. 2D versions are quick to simulate and are great for testing out ideas quickly before transferring to a 3D simulation.</p> <p>The following is all that's needed to load a pre-defined scenario:</p> <pre><code>import neurotechdevkit as ndk\nscenario = ndk.make('scenario-2-2d-v0')\n</code></pre> <p>The existing scenario ids are:</p> <ul> <li><code>scenario-0-v0</code> (2D) - a simple quickstart toy scenario that enables users to dive in and experiment with their first simulation immediately.</li> <li><code>scenario-1-3d-v0</code> (3D) - a scenario containing a flat 3-layer bone covered by skin, with water above the skin and brain below the bone. This is based on benchmark 4 of Jean-Francois Aubry, et al..</li> <li><code>scenario-2-3d-v0</code> (3D) - a scenario containing a full skull and brain mesh immersed in water. This is based on benchmark 8 of Jean-Francois Aubry, et al..</li> <li><code>scenario-1-2d-v0</code> (2D) - a 2D version of scenario 1.</li> <li><code>scenario-2-2d-v0</code> (2D) - a 2D version of scenario 2.</li> </ul> <p>All of these scenarios are immediately ready for visualization and simulation, with appropriate default parameters used where needed.</p> <pre><code>scenario.render_layout()\n</code></pre> <p></p>"},{"location":"usage/running_simulation/","title":"Simulation","text":"<p>The Neurotech Development Kit provides support for a range of simulation modes, including pulsed simulation and steady-state simulation.</p> <p>Running a simulation takes just a single function call.</p> <pre><code>import neurotechdevkit as ndk\nscenario = ndk.make('scenario-2-2d-v0')\nresult = scenario.simulate_steady_state()\nresult.render_steady_state_amplitudes()\n</code></pre> <p></p>"},{"location":"usage/troubleshooting/","title":"Troubleshooting","text":"<p>This page contains a list of known problems you might face when installing and running NDK and the actions to solve them.</p>"},{"location":"usage/troubleshooting/#error-command-x86_64-linux-gnu-gcc-failed-no-such-file-or-directory-on-linux","title":"<code>error: command 'x86_64-linux-gnu-gcc' failed: No such file or directory</code> on Linux","text":"<p>This error occurs when <code>g++</code> is not installed. You can install it with:</p> <pre><code>apt-get install g++\n</code></pre> <p>and run the installation again.</p>"},{"location":"usage/troubleshooting/#pyrevolveschedulerscrevolvecpp2510-fatal-error-pythonh-no-such-file-or-directory-on-linux","title":"<code>pyrevolve/schedulers/crevolve.cpp:25:10: fatal error: Python.h: No such file or directory</code> on Linux","text":"<p>This error occurs when the <code>python-dev</code> package was not installed. You can install it with: <pre><code>apt-get install python3.10-dev\n</code></pre> replace <code>3.10</code> with your installed python version.</p> <p>And run the installation again.</p>"},{"location":"usage/troubleshooting/#error-legacy-install-failure-on-macos","title":"<code>error: legacy-install-failure</code> on MacOS","text":"<p>This error might occur when <code>brew</code> or <code>pip</code> are outdated.</p> <p>Update brew: <pre><code>brew update\n</code></pre></p> <p>Update pip: <pre><code>pip install --upgrade pip\n</code></pre></p> <p>And run the installation again.</p>"},{"location":"usage/troubleshooting/#error-process-completed-with-exit-code-1-when-installing-stride-on-windows","title":"<code>Error: Process completed with exit code 1.</code> when installing Stride on Windows","text":"<p>Unfortunately Stride can't be installed on a Windows platform, therefore NDK is also unsupported.</p>"},{"location":"usage/troubleshooting/#error-cannot-install-under-rosetta-2-in-arm-default-prefix-opthomebrew-on-macos","title":"<code>Error: Cannot install under Rosetta 2 in ARM default prefix (/opt/homebrew)!</code> on MacOS","text":"<p>This error occurs when you are not running the native homebrew for an ARM platform. To proceed with the installation you can:</p> <ul> <li>Migrate to native homebrew</li> </ul> <p>or</p> <ul> <li>Prepend the brew install commands with <code>arch -arm64</code>: <pre><code>arch -arm64 brew install ...\n</code></pre></li> </ul>"},{"location":"usage/troubleshooting/#getting-error-codepycompileerror-module-compilation-failed","title":"Getting error <code>codepy.CompileError: module compilation failed</code>","text":"<p>This error occurs when the compiler wasn't able to perform the compilation, it can be caused by a environment configuration problem. Check the <code>DEVITO_ARCH</code> environment variable, it should be set with the compiler devito will use to compile the code.</p> <p>You can find further information in the Devito documentation.</p>"},{"location":"usage/troubleshooting/#getting-error-codepycompileerror-module-compilation-failed-with-fatal-error-omph-file-not-found","title":"Getting error <code>codepy.CompileError: module compilation failed</code> with <code>fatal error: 'omp.h' file not found</code>","text":"<p>This error occurs when the <code>libomp</code> is not installed or can not be found by the compiler.</p> <p>Make sure to install it and export the environment variable <code>CPATH</code> with the path to the folder containing libomp headers.</p>"},{"location":"usage/troubleshooting/#getting-error-modulenotfounderror-no-module-named-neurotechdevkit","title":"Getting error <code>ModuleNotFoundError: No module named 'neurotechdevkit'</code>","text":"<p>This error is shown when <code>neurotechdevkit</code> is not installed, if you installed it using a virtual environment like poetry you must run the script with <code>poetry run</code> or activate the environment.</p>"},{"location":"usage/troubleshooting/#getting-error-attributeerror-module-napari-has-no-attribute-viewer-when-calling-render_layout_3d","title":"Getting error <code>AttributeError: module 'napari' has no attribute 'Viewer'</code> when calling <code>render_layout_3d</code>","text":"<p>This error is shown when napari is not installed, make sure to run</p> <p><code>pip install \"napari[all]\"</code></p> <p>(or <code>pip install \"napari[pyqt6_experimental]\"</code> if running on a Mac M1)</p> <p>and try again.</p>"}]}