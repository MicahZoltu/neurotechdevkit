{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Neurotech Development Kit","text":"<p>The Neurotech Development Kit (NDK) is an open-source, community-driven software library designed to lower the barrier of entry to the next generation of neurotechnology for current researchers and companies. It also enables software developers without access to hardware and human subjects to solve open problems in the field. The initial release of NDK provides support for transcranial focused ultrasound stimulation, along with comprehensive documentation, API flexibility, and 2D/3D visualizations. Future areas of interest may include photoacoustic and optical whole-brain imaging.</p> <p>As a community-driven project, we encourage you to contribute code, feedback, and features to help accelerate the development of transformative neurotechnology.</p> <p></p> <p>Check out the NDK documentation page.</p>"},{"location":"#running","title":"Running","text":""},{"location":"#docker","title":"Docker","text":"<p>You can run <code>neurotechdevkit</code> inside a docker container with just a couple of steps:</p> <ol> <li> <p>Install docker</p> </li> <li> <p>Run the following command:</p> <pre><code>docker run -p 8888:8888 -it ghcr.io/agencyenterprise/neurotechdevkit:latest\n</code></pre> <p>The command above will start a Jupyter notebook server with example notebooks you can use to explore <code>neurotechdevkit</code>. Use the printed URL to open it in your browser or connect to it using your IDE.</p> <p>All changes you make to these files will be lost once you stop the docker container.</p> </li> </ol> <p>Note:</p> <p>You can have persisting Jupyter notebooks by running    <pre><code>docker run -p 8888:8888  -v $(pwd)/notebooks:/ndk/notebooks -it ghcr.io/agencyenterprise/neurotechdevkit:latest\n</code></pre>    The command above will create a folder <code>notebooks</code> in your current directory where you can put your jupyter notebooks.</p> <p>We recommend downloading the <code>.zip</code> file with example notebooks from this link, and extracting it into your local <code>notebooks</code> folder so you can access them from the docker.</p>"},{"location":"#local-installation","title":"Local installation","text":"<p>To install and run neurotechdevkit locally check the installation page.</p>"},{"location":"#usage","title":"Usage","text":"<pre><code>import neurotechdevkit as ndk\nscenario = ndk.make('scenario-0-v0')\nresult = scenario.simulate_steady_state()\nresult.render_steady_state_amplitudes(show_material_outlines=False)\n</code></pre>"},{"location":"#acknowledgements","title":"Acknowledgements","text":"<p>Thanks to Fred Ehrsam for supporting this project, Quintin Frerichs and Milan Cvitkovic for providing direction, and to Sumner Norman for his ultrasound and neuroscience expertise. Thanks to Stride for facilitating ultrasound simulations and providing an MIT license for usage within NDK, Devito for providing the backend solver, Napari for great 3D visualization, and to Jean-Francois Aubry, et al. for the basis of the simulation scenarios.</p>"},{"location":"contributing/","title":"Contributing","text":"<p>You can contribute to NDK by creating GitHub issues or by submitting pull requests.</p>"},{"location":"contributing/#reporting-issues","title":"Reporting issues","text":"<p>Feel free to open an issue if you would like to discuss a new feature request or report a bug. When creating a bug report, please include as much information as possible to help us reproduce the bug as well as what the actual and expected behavior is.</p>"},{"location":"contributing/#contributing-code","title":"Contributing code","text":""},{"location":"contributing/#standards","title":"Standards","text":"<p>To ensure efficient collaborative development, a variety of standards are utilized in this project.</p> <ul> <li>Black code formatter is used.</li> <li>Flake8 is used for linting.</li> <li>isort is used for sorting the imports.</li> <li>pyright is used for static type checking.</li> <li>Type hinting is used.<ul> <li>And checked using mypy.</li> </ul> </li> </ul>"},{"location":"contributing/#preparing-your-environment","title":"Preparing your environment","text":"<p>Start by cloning the repository:</p> <pre><code>git clone https://github.com/agencyenterprise/neurotechdevkit.git\ncd neurotechdevkit\n</code></pre>"},{"location":"contributing/#running-on-docker","title":"Running on docker","text":"<p>If you don't want to install NDK's dependencies on your machine, you can run it in a container:</p> <ul> <li> <p>Install Docker.</p> </li> <li> <p>Run the container, which will start a jupyter notebook server:    <pre><code>git clone https://github.com/agencyenterprise/neurotechdevkit.git\ncd neurotechdevkit\ndocker compose up\n</code></pre></p> </li> <li> <p>Connect to the jupyter notebook directly in your browser or with your IDE.</p> </li> </ul>"},{"location":"contributing/#running-locally","title":"Running locally","text":"<p>This project requires Python <code>&gt;=3.9</code> and <code>&lt;3.11</code> to be installed. You can find the Python version you have installed by running <code>python --version</code> in a terminal. If you don't have Python installed or are running an unsupported version, you can download a supported version from python.org.</p> <p>We use poetry to manage dependencies and virtual environments. Follow the instructions from poetry's documentation to install it if you don't have it on your system.</p> <p>Install the dependencies by running the following command in a shell within the project directory:</p> <pre><code>poetry install\n</code></pre> <p>This will resolve and install the dependencies from <code>poetry.lock</code> and will install the <code>neurotechdevkit</code> package in editable mode.</p> <p>Install stride with</p> <pre><code>$ poetry run pip install git+https://github.com/trustimaging/stride\n</code></pre> <p><code>devito</code>, a dependency of <code>neurotechdevkit</code>, requires <code>libomp</code>. On MacOS it can be installed with:</p> <pre><code>brew install libomp\n</code></pre> <p>the output of the command above will look like this:</p> <pre><code>For compilers to find libomp you may need to set:\nexport LDFLAGS=\"-L/usr/local/opt/libomp/lib\"\nexport CPPFLAGS=\"-I/usr/local/opt/libomp/include\"\n</code></pre> <p><code>devito</code> requires the directory with <code>libomp</code> headers to be accessible during the runtime compilation, you can make it accessible by exporting a new environment variable <code>CPATH</code> with the path for libomp headers, like so:</p> <pre><code>export CPATH=\"/usr/local/opt/libomp/include\"\n</code></pre> <p>You will also have to set an environment variable that defines what compiler <code>devito</code> will use, like so:</p> <pre><code>export DEVITO_ARCH=gcc\n</code></pre> <p>the supported values for <code>DEVITO_ARCH</code> are: <code>'custom', 'gnu', 'gcc', 'clang', 'aomp', 'pgcc', 'pgi', 'nvc', 'nvc++', 'nvidia', 'cuda', 'osx', 'intel', 'icpc', 'icc', 'intel-knl', 'knl', 'dpcpp', 'gcc-4.9', 'gcc-5', 'gcc-6', 'gcc-7', 'gcc-8', 'gcc-9', 'gcc-10', 'gcc-11'</code></p>"},{"location":"contributing/#using-the-environment","title":"Using the environment","text":"<p>If you are not already using a virtual environment, <code>poetry</code> will create one for you by default. You will need to use this virtual env when using or working on the package.</p> <p>Activate the environment directly via:</p> <pre><code>poetry shell\n</code></pre> <p>If you are already using your own virtual environment, you should not need to change anything.</p>"},{"location":"contributing/#code-requirements-and-conventions","title":"Code requirements and conventions","text":"<p>Note</p> <p>The following commands require <code>GNU make</code> to be installed, on Windows you can install it with Chocolatey:</p> <p><code>choco install make</code></p> <p>Before opening a pull request, please make sure that all of the following requirements are met:</p> <ol> <li>all unit and integration tests are passing:    <pre><code>make test\n</code></pre></li> <li>the code is linted and formatted:    <pre><code>make lint\n</code></pre></li> <li>type hinting is used on all function and method parameters and return values, excluding tests</li> <li>docstring usage conforms to the following:<ol> <li>all docstrings should follow PEP257 Docstring Conventions</li> <li>all public API classes, functions, methods, and properties have docstrings and follow the Google Python Style Guide</li> <li>docstrings on private objects are not required, but are encouraged where they would significantly aid understanding</li> </ol> </li> <li>testing is done using the pytest library, and test coverage should not unnecessarily decrease.</li> </ol>"},{"location":"contributing/#process","title":"Process","text":""},{"location":"contributing/#versioning","title":"Versioning","text":"<p>NDK uses semantic versioning to identify its releases.</p> <p>We use the release on push github action to generate the new version for each release. This github action generates the version based on a pull request label assigned before merge. The supported labels are:</p> <ul> <li><code>release-patch</code></li> <li><code>release-minor</code></li> <li><code>release-major</code></li> <li><code>norelease</code></li> </ul>"},{"location":"contributing/#automatic-release","title":"Automatic release","text":"<p>Merged pull requests with one of the labels <code>release-patch</code>, <code>release-minor</code> or <code>release-major</code> will trigger a release job on CI.</p> <p>The release job will:</p> <ol> <li>generate a new package version using semantic versioning provided by release on push</li> <li>update the <code>pyproject.toml</code> version using <code>poetry</code></li> <li>commit the updated <code>pyproject.toml</code> file using the git-auto-commit action</li> <li>push the package to pypi using poetry publish</li> <li>build a new docker image and tag it with the previously generated semantic version</li> </ol> <p>Pull requests merged with the tag <code>norelease</code> will not trigger any of the actions listed above.</p>"},{"location":"contributing/#gallery-of-examples","title":"Gallery of examples","text":"<p>The examples you can find in the official documentation are python scripts executed in CI.</p> <p>Running these scripts is a resource intensive and time consuming task, for this reason we are using CircleCI instead of Github Actions (as we can choose a more powerful machine to execute the job) and we are also using a cache that prevents processing all gallery files on each execution.</p> <p>The cache source for the gallery is the <code>gh-pages</code> branch from our repository. This branch is updated every time a new push to the <code>main</code> branch occurs, and the output of the execution of gallery scripts are part of it. Our CI checks out the <code>gh-pages</code> branch and moves the generated gallery output to the directory that will be read by mkdocs, you can check how it is done here.</p> <p>With the forementioned cache implemented only newly added gallery scripts are executed on a Pull Request. So there's a risk of having changes to code breaking gallery scripts that were not touched in the Pull Request, these broken scripts would pass unnoticed because of the cache. We try to mitigate this issue by triggering a full execution of all gallery scripts without cache on a weekly basis, this is achieved using a Github Action with a schedule that starts a CicleCI workflow.</p>"},{"location":"contributing/#checking-ndk-documentation-on-ci","title":"Checking NDK documentation on CI","text":"<p>All pull requests trigger a CI job that builds the documentation and makes the built files available.</p> <p>To check the generated documentation in a pull request:</p> <ol> <li>Scroll to the bottom of the page and click on the <code>Show all checks</code> link.</li> <li>Click on the details link of the <code>Check the rendered docs here!</code> job.        </li> </ol> <p>Note</p> <p>The <code>Examples</code> section is not properly rendered when the documentation is built   on CI. The links of the thumbnails in <code>gallery/index.html</code> point to broken paths,   in order to check one of the examples you will have to click on the left panel,   as shown in the image below:       Within each example, the outputs of cells are also not properly displayed.</p>"},{"location":"conventions/","title":"Conventions","text":"<p>Below are some of the conventions that we are or would like to follow in NDK. This page should be considered incomplete as there are conventions being followed in the codebase which are not described here. We should add to this doc incrementally as part of relevant PRs.</p>"},{"location":"conventions/#units-of-measurement","title":"Units of Measurement","text":"<p>Unit of measurement (uom) labels should be used wherever relevant throughout docstrings, documentation, plots, and textual output.</p> <p>For internal methods and computation steps, always express values using uom without scale prefixes (eg. m rather than mm or km). When values are provided by the user (via parameters) or shown directly to the user (via plots or textual output) scaling prefixes can be used if there is a clear convention in the ultrasound community for which prefix should be used.</p>"},{"location":"conventions/#in-docstrings","title":"In docstrings","text":"<ul> <li>include units for all parameters and return values that have meaningful units<ul> <li>put the uom in parentheses after \"in\". Eg: \"distance (in meters)\"</li> </ul> </li> <li>when the uom has an SI name, write out the name fully with the correct capitalization (eg. seconds, meters, pascals)</li> <li>when the uom does not have an SI name, use the equation specifying the uom (eg. m/s, W/cm\u00b2)</li> </ul>"},{"location":"conventions/#in-plots","title":"In plots","text":"<ul> <li>for axis labels, use the uom abbreviation in parentheses. eg: \"Pressure (Pa)\"</li> </ul>"},{"location":"conventions/#for-metrics","title":"For metrics","text":"<ul> <li>include a specific uom in the output for each metric</li> </ul>"},{"location":"conventions/#adding-to-conventions","title":"Adding to Conventions","text":"<p>Whenever new conventions are used, they should be added to this document within the PR where the conventions were first added.</p> <p>Whenever existing conventions are discovered or refined (such as through PR review discussion), the conventions should be added or updated in this document as part of that PR.</p>"},{"location":"installation/","title":"Installation","text":"<p>You can run NDK without installing the package using docker, as shown here. However, if you'd like to install it, please follow the instructions below.</p> Before installing on Windows <ol> <li> <p>Install Ubuntu on WSL.</p> </li> <li> <p>Follow the the <code>Linux</code> steps described in this page inside your Ubuntu shell.</p> </li> </ol> <p><code>neurotechdevkit</code> requires Python <code>&gt;=3.9</code> and <code>&lt;3.11</code> to be installed. You can find which Python version you have installed by running <code>python --version</code> in a terminal.</p> <p>If you don't have Python installed, or you are running an unsupported version, you can download it from python.org. Python environment managers like pyenv, conda, and poetry are all perfectly suitable as well.</p> Before installing on Linux <ol> <li> <p>In order to install <code>neurotechdevkit</code> you must first install <code>g++</code> and the <code>python-dev</code> package for your python version.</p> <p>Both packages can be installed with: <pre><code>apt-get install -y g++ python3.10-dev\n</code></pre></p> <p>Important: You must replace <code>3.10</code> with your python version when running the command above.</p> </li> </ol> <p>You can install the <code>neurotechdevkit</code> package using:</p> <pre><code>pip install neurotechdevkit\n</code></pre> <p>You also have to install stride, it can be done running:</p> <pre><code>pip install git+https://github.com/trustimaging/stride\n</code></pre>"},{"location":"installation/#setting-up-a-compiler","title":"Setting up a compiler","text":"<p>NDK uses devito to perform the heavy computational operations. Devito generates, compiles and runs C code to achieve better performance. The compiler used by Devito has to be selected, and paths for the linker might also be added as environment variables.</p> <p>As a last step before running NDK, follow the instructions below depending on your OS.</p> Before running on MacOS <p>The two main compiler options for MacOS are clang and gcc.</p> Before running on Linux <ol> <li> <p>Export the <code>DEVITO_ARCH</code> environment variable, or add it to your shell profile:</p> <pre><code>export DEVITO_ARCH=\"gcc\"\n</code></pre> <p>The supported values for <code>DEVITO_ARCH</code> are: <code>'custom', 'gnu', 'gcc', 'clang', 'aomp', 'pgcc', 'pgi', 'nvc', 'nvc++', 'nvidia', 'cuda', 'osx', 'intel', 'icpc', 'icc', 'intel-knl', 'knl', 'dpcpp', 'gcc-4.9', 'gcc-5', 'gcc-6', 'gcc-7', 'gcc-8', 'gcc-9', 'gcc-10', 'gcc-11'</code>.</p> </li> </ol> <p>Note</p> <p>After installing <code>neurotechdevkit</code> you can use Jupyter to explore the package.</p> <p>To get started, we recommend downloading the example notebooks from this link.</p> <p>On Linux you can download and extract the notebooks running the following commands:</p> <ol> <li><code>sudo apt-get update &amp;&amp; sudo apt-get install -y unzip wget</code></li> <li><code>wget \"https://agencyenterprise.github.io/neurotechdevkit/generated/gallery/gallery_jupyter.zip\" -O temp.zip &amp;&amp; unzip temp.zip &amp;&amp; rm temp.zip</code></li> </ol>"},{"location":"installation/#clang","title":"clang","text":"<p>If you prefer to use clang you will have to install <code>libomp</code> and <code>llvm</code>, you will also have to export a few environment variables needed by the compiler.</p> <ol> <li> <p>Install libomp</p> <pre><code>brew install libomp\n</code></pre> <p>the output of the command above will look like this:</p> <pre><code>For compilers to find libomp you may need to set:\nexport LDFLAGS=\"-L/usr/local/opt/libomp/lib\"\nexport CPPFLAGS=\"-I/usr/local/opt/libomp/include\"\n</code></pre> </li> <li> <p>Run the following command to export a new environment variable <code>CPATH</code> with the path for <code>libomp</code> headers:</p> <pre><code>echo 'export CPATH=\"/usr/local/opt/libomp/include\"' &gt;&gt; ~/.zshrc\n</code></pre> </li> <li> <p>Install <code>llvm</code>:</p> <pre><code>brew install llvm\n</code></pre> </li> <li> <p>Run the following commands to export the <code>llvm</code> environment variables:</p> <pre><code>echo 'export PATH=\"/usr/local/opt/llvm/bin:$PATH\"' &gt;&gt; ~/.zshrc\necho 'export LDFLAGS=\"-L/usr/local/opt/llvm/lib\"' &gt;&gt; ~/.zshrc\necho 'export CPPFLAGS=\"-I/usr/local/opt/llvm/include\"' &gt;&gt; ~/.zshrc\n</code></pre> </li> <li> <p>The following command will export the <code>DEVITO_ARCH</code> environment variable:</p> <pre><code>echo 'export DEVITO_ARCH=\"clang\"' &gt;&gt; ~/.zshrc\n</code></pre> </li> <li> <p>Load the modified zsh configuration file:</p> <pre><code>source ~/.zshrc\n</code></pre> </li> </ol>"},{"location":"installation/#gcc","title":"gcc","text":"<p>On MacOS the <code>gcc</code> executable is a symbolic link to <code>clang</code>, so by defining DEVITO_ARCH=gcc devito will try to add <code>gcc</code> flags to the <code>clang</code> compiler, and the compilation will most probably fail.</p> <p>You can tell devito to use the correct <code>gcc</code> compiler doing the following:</p> <ol> <li> <p>Install gcc-11</p> <pre><code>brew install gcc@11\n</code></pre> </li> <li> <p>Run the command that exports the <code>DEVITO_ARCH</code> environment variable:</p> <pre><code>echo 'export DEVITO_ARCH=\"gcc-11\"' &gt;&gt; ~/.zshrc\n</code></pre> </li> <li> <p>Load the modified zsh configuration file:</p> <pre><code>source ~/.zshrc\n</code></pre> </li> </ol>"},{"location":"api/make/","title":"NDK Interface","text":""},{"location":"api/make/#neurotechdevkit.make","title":"<code>neurotechdevkit.make(scenario_id, complexity='fast')</code>","text":"<p>Initialize a scenario and return an object which represents the simulation.</p> <p>Parameters:</p> Name Type Description Default <code>scenario_id</code> <code>str</code> <p>the id of the scenario to load. Supported scenarios are:</p> <ul> <li>Scenario 0</li> <li>Scenario 1 2D</li> <li>Scenario 1 3D</li> <li>Scenario 2 2D</li> <li>Scenario 2 3D</li> </ul> required <code>complexity</code> <code>str</code> <p>allow the user to choose from a few pre-selected options for parameters such as PPP and PPW that determine the compute, memory, and time requirements of a simulation as well as the accuracy of the simulation results. Defaults to \"fast\".</p> <code>'fast'</code> <p>Raises:</p> Type Description <code>ScenarioNotFoundError</code> <p>Raised when the scenario id is not found.</p> <p>Returns:</p> Type Description <code>scenarios.Scenario</code> <p>An object representing the simulation.</p>"},{"location":"api/results/","title":"Results","text":""},{"location":"api/results/#neurotechdevkit.results.PulsedResult","title":"<code>PulsedResult</code>  <code>dataclass</code>","text":"<p>         Bases: <code>Result</code></p> <p>A base container for holding the results of a pulsed simulation.</p> <p>This class should not be instantiated, use PulsedResult2D or PulsedResult3D.</p> <p>Parameters:</p> Name Type Description Default <code>scenario</code> <code>scenario.Scenario</code> <p>the scenario from which this result came.</p> required <code>center_frequency</code> <code>float</code> <p>the center frequency (in hertz) of the sources.</p> required <code>effective_dt</code> <code>float</code> <p>the effective time step (in seconds) along the time axis of the wavefield. This can differ from the simulation dt if the recording undersampling factor is larger than 1.</p> required <code>pde</code> <code>stride.Operator</code> <p>the stride Operator that was executed to run the simulation.</p> required <code>shot</code> <code>stride.Shot</code> <p>the stride Shot which was used for the simulation.</p> required <code>wavefield</code> <code>npt.NDArray[np.float_]</code> <p>an array containing the resulting simulation data.</p> required <code>traces</code> <code>stride.Traces</code> <p>the stride Traces object returned from executing the pde.</p> required"},{"location":"api/results/#neurotechdevkit.results.PulsedResult2D","title":"<code>PulsedResult2D</code>","text":"<p>         Bases: <code>PulsedResult</code></p> <p>A container for holding the results of a 2D pulsed simulation.</p> <p>Parameters:</p> Name Type Description Default <code>scenario</code> <code>scenarios.Scenario2D</code> <p>the 2D scenario from which this result came.</p> required <code>center_frequency</code> <code>float</code> <p>the center frequency (in hertz) of the sources.</p> required <code>effective_dt</code> <code>float</code> <p>the effective time step (in seconds) along the time axis of the wavefield. This can differ from the simulation dt if the recording downsampling factor is larger than 1.</p> required <code>pde</code> <code>stride.Operator</code> <p>the stride Operator that was executed to run the simulation.</p> required <code>shot</code> <code>stride.Shot</code> <p>the stride Shot which was used for the simulation.</p> required <code>wavefield</code> <code>npt.NDArray[np.float_]</code> <p>a 3 dimensional array (two axes for space and one for time) containing the resulting simulation data.</p> required <code>traces</code> <code>stride.Traces</code> <p>the stride Traces object returned from executing the pde.</p> required"},{"location":"api/results/#neurotechdevkit.results._results.PulsedResult2D.create_video_file","title":"<code>create_video_file(file_name, show_sources=True, show_target=True, show_material_outlines=True, n_frames_undersampling=1, time_lim=None, norm='linear', fps=25, dpi=100, bitrate=2500, overwrite=False)</code>","text":"<p>Save a <code>mp4</code> animation file to disk with the results of the simulation.</p> <p>Currently only mp4 format supported. <code>ffmpeg</code> command line tools needs to be installed.</p> <p>Parameters:</p> Name Type Description Default <code>file_name</code> <code>str</code> <p>the file with path an extension where the animation would be saved. Currently only supports mp4 extension.</p> required <code>show_sources</code> <code>bool</code> <p>whether or not to show the source transducer layer.</p> <code>True</code> <code>show_target</code> <code>bool</code> <p>whether or not to show the target layer.</p> <code>True</code> <code>show_material_outlines</code> <code>bool</code> <p>whether or not to display a thin white outline of the transition between different materials.</p> <code>True</code> <code>n_frames_undersampling</code> <code>int</code> <p>the number of time steps to be skipped when creating the animation.</p> <code>1</code> <code>time_lim</code> <code>tuple[np.float_, np.float_] | None</code> <p>the input time limit tuple to validate. The expected format is (minimum_time, maximum_time).</p> <code>None</code> <code>norm</code> <code>str</code> <p>the normalization method used to scale scalar data to the [0, 1] range before mapping to colors using cmap. For a list of available scales, call <code>matplotlib.scale.get_scale_names()</code>.</p> <code>'linear'</code> <code>fps</code> <code>int</code> <p>the frames per second in the animation.</p> <code>25</code> <code>dpi</code> <code>int</code> <p>the number of dots per inch in the frames of the animation.</p> <code>100</code> <code>bitrate</code> <code>int</code> <p>the bitrate for the saved movie file, which is one way to control the output file size and quality.</p> <code>2500</code> <code>overwrite</code> <code>bool</code> <p>a boolean that allows the animation to be saved with the same file name that is already exists.</p> <code>False</code>"},{"location":"api/results/#neurotechdevkit.results._results.PulsedResult2D.render_pulsed_simulation_animation","title":"<code>render_pulsed_simulation_animation(show_sources=True, show_target=True, show_material_outlines=True, n_frames_undersampling=1, time_lim=None, norm='linear')</code>","text":"<p>Create a matplotlib animation with the time evolution of the wavefield.</p> <p>The created animation will be displayed as an interactive widget in a IPython or Jupyter Notebook environment. In a non-interactive environment (script) the result of this animation would be lost. Use <code>create_video_file</code> method instead.</p> <p>Parameters:</p> Name Type Description Default <code>show_sources</code> <code>bool</code> <p>whether or not to show the source transducer layer.</p> <code>True</code> <code>show_target</code> <code>bool</code> <p>whether or not to show the target layer.</p> <code>True</code> <code>show_material_outlines</code> <code>bool</code> <p>whether or not to display a thin white outline of the transition between different materials.</p> <code>True</code> <code>n_frames_undersampling</code> <code>int</code> <p>the number of time steps to be skipped when creating the animation.</p> <code>1</code> <code>time_lim</code> <code>tuple[np.float_, np.float_] | None</code> <p>the input time limit tuple to validate. The expected format is (minimum_time, maximum_time).</p> <code>None</code> <code>norm</code> <code>str</code> <p>the normalization method used to scale scalar data to the [0, 1] range before mapping to colors using cmap. For a list of available scales, call <code>matplotlib.scale.get_scale_names()</code>.</p> <code>'linear'</code> <p>Returns:</p> Type Description <code>FuncAnimation</code> <p>An matplotlib animation object.</p>"},{"location":"api/results/#neurotechdevkit.results.PulsedResult3D","title":"<code>PulsedResult3D</code>","text":"<p>         Bases: <code>PulsedResult</code></p> <p>A container for holding the results of a 3D pulsed simulation.</p> <p>Parameters:</p> Name Type Description Default <code>scenario</code> <code>scenarios.Scenario3D</code> <p>the 3D scenario from which this result came.</p> required <code>center_frequency</code> <code>float</code> <p>the center frequency (in hertz) of the sources.</p> required <code>effective_dt</code> <code>float</code> <p>the effective time step (in seconds) along the time axis of the wavefield. This can differ from the simulation dt if the recording downsampling factor is larger than 1.</p> required <code>pde</code> <code>stride.Operator</code> <p>the stride Operator that was executed to run the simulation.</p> required <code>shot</code> <code>stride.Shot</code> <p>the stride Shot which was used for the simulation.</p> required <code>wavefield</code> <code>npt.NDArray[np.float_]</code> <p>a 4 dimensional array (three axes for space and one for time) containing the resulting simulation data.</p> required <code>traces</code> <code>stride.Traces</code> <p>the stride Traces object returned from executing the pde.</p> required"},{"location":"api/results/#neurotechdevkit.results._results.PulsedResult3D.create_video_file","title":"<code>create_video_file(file_name, show_sources=True, show_target=True, show_material_outlines=True, n_frames_undersampling=1, slice_axis=None, slice_position=None, time_lim=None, norm='linear', fps=25, dpi=100, bitrate=2500, overwrite=False)</code>","text":"<p>Save a <code>mp4</code> animation file to disk with the results of the simulation.</p> <p>Currently only mp4 format supported. <code>ffmpeg</code> command line tools needs to be installed.</p> <p>Parameters:</p> Name Type Description Default <code>file_name</code> <code>str</code> <p>the file with path an extension where the animation would be saved. Currently only supports mp4 extension.</p> required <code>show_sources</code> <code>bool</code> <p>whether or not to show the source transducer layer.</p> <code>True</code> <code>show_target</code> <code>bool</code> <p>whether or not to show the target layer.</p> <code>True</code> <code>show_material_outlines</code> <code>bool</code> <p>whether or not to display a thin white outline of the transition between different materials.</p> <code>True</code> <code>n_frames_undersampling</code> <code>int</code> <p>the number of time steps to be skipped when creating the animation.</p> <code>1</code> <code>slice_axis</code> <code>int | None</code> <p>the axis along which to slice. If None, then the value returned by <code>scenario.get_default_slice_axis()</code> is used.</p> <code>None</code> <code>slice_position</code> <code>float | None</code> <p>the position (in meters) along the slice axis at which the slice should be made. If None, then the value returned by <code>scenario.get_default_slice_position()</code> is used.</p> <code>None</code> <code>time_lim</code> <code>tuple[np.float_, np.float_] | None</code> <p>the input time limit tuple to validate. The expected format is (minimum_time, maximum_time).</p> <code>None</code> <code>norm</code> <code>str</code> <p>the normalization method used to scale scalar data to the [0, 1] range before mapping to colors using cmap. For a list of available scales, call <code>matplotlib.scale.get_scale_names()</code>.</p> <code>'linear'</code> <code>fps</code> <code>int</code> <p>the frames per second in the animation.</p> <code>25</code> <code>dpi</code> <code>int</code> <p>the number of dots per inch in the frames of the animation.</p> <code>100</code> <code>bitrate</code> <code>int</code> <p>the bitrate for the saved movie file, which is one way to control the output file size and quality.</p> <code>2500</code> <code>overwrite</code> <code>bool</code> <p>a boolean that allows the animation to be saved with the same file name that is already exists.</p> <code>False</code>"},{"location":"api/results/#neurotechdevkit.results._results.PulsedResult3D.render_pulsed_simulation_animation","title":"<code>render_pulsed_simulation_animation(show_sources=True, show_target=True, show_material_outlines=True, n_frames_undersampling=1, slice_axis=None, slice_position=None, time_lim=None, norm='linear')</code>","text":"<p>Create a matplotlib animation with the time evolution of the wavefield.</p> <p>The created animation will be displayed as an interactive widget in a IPython or Jupyter Notebook environment. In a non-interactive environment (script) the result of this animation would be lost. Use <code>create_video_file</code> method instead.</p> <p>Parameters:</p> Name Type Description Default <code>show_sources</code> <code>bool</code> <p>whether or not to show the source transducer layer.</p> <code>True</code> <code>show_target</code> <code>bool</code> <p>whether or not to show the target layer.</p> <code>True</code> <code>show_material_outlines</code> <code>bool</code> <p>whether or not to display a thin white outline of the transition between different materials.</p> <code>True</code> <code>n_frames_undersampling</code> <code>int</code> <p>the number of time steps to be skipped when creating the animation.</p> <code>1</code> <code>slice_axis</code> <code>int | None</code> <p>the axis along which to slice. If None, then the value returned by <code>scenario.get_default_slice_axis()</code> is used.</p> <code>None</code> <code>slice_position</code> <code>float | None</code> <p>the position (in meters) along the slice axis at which the slice should be made. If None, then the value returned by <code>scenario.get_default_slice_position()</code> is used.</p> <code>None</code> <code>time_lim</code> <code>tuple[np.float_, np.float_] | None</code> <p>the input time limit tuple to validate. The expected format is (minimum_time, maximum_time).</p> <code>None</code> <code>norm</code> <code>str</code> <p>the normalization method used to scale scalar data to the [0, 1] range before mapping to colors using cmap. For a list of available scales, call <code>matplotlib.scale.get_scale_names()</code>.</p> <code>'linear'</code> <p>Returns:</p> Type Description <code>FuncAnimation</code> <p>An matplotlib animation object.</p>"},{"location":"api/results/#neurotechdevkit.results.Result","title":"<code>Result</code>  <code>dataclass</code>","text":"<p>         Bases: <code>abc.ABC</code></p> <p>A base container for holding the results of a simulation.</p> <p>This class should not be instantiated, use SteadyStateResult2D, SteadyStateResult3D, PulsedResult2D, or PulsedResult3D.</p> <p>Parameters:</p> Name Type Description Default <code>scenario</code> <code>scenarios.Scenario</code> <p>the scenario from which this result came.</p> required <code>center_frequency</code> <code>float</code> <p>the center frequency (in hertz) of the sources.</p> required <code>effective_dt</code> <code>float</code> <p>the effective time step (in seconds) along the time axis of the wavefield. This can differ from the simulation dt if the recording undersampling factor is larger than 1.</p> required <code>pde</code> <code>stride.Operator</code> <p>the stride Operator that was executed to run the simulation.</p> required <code>shot</code> <code>stride.Shot</code> <p>the stride Shot which was used for the simulation.</p> required <code>wavefield</code> <code>npt.NDArray[np.float_]</code> <p>an array containing the resulting simulation data.</p> required <code>traces</code> <code>stride.Traces</code> <p>the stride Traces object returned from executing the pde.</p> required"},{"location":"api/results/#neurotechdevkit.results._results.Result.save_to_disk","title":"<code>save_to_disk(filepath)</code>","text":"<p>Save the result to a tarball containing the data as a gzip compressed file.</p> <p>The resulting tarball will contain two files:</p> <ul> <li><code>data.gz</code>: gzip compressed file which is a pickle object.</li> <li><code>VERSION</code>: a text file containing the <code>neurotechdevkit</code> version.</li> </ul> <p>Warning</p> <p>This functionality is experimental, so do do not be surprised if you encounter issues calling this function.</p> <p>This function is particularly useful if simulation is performed in the cloud but the user would like to download the results in order to visualize them locally in 3D.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str | pathlib.Path</code> <p>the path to the file where the results should be exported. Usually a .tar.gz file.</p> required"},{"location":"api/results/#neurotechdevkit.results.SteadyStateResult","title":"<code>SteadyStateResult</code>  <code>dataclass</code>","text":"<p>         Bases: <code>Result</code></p> <p>A base container for holding the results of a steady-state simulation.</p> <p>This class should not be instantiated, use SteadyStateResult2D or SteadyStateResult3D.</p> <p>Parameters:</p> Name Type Description Default <code>scenario</code> <code>scenario.Scenario</code> <p>the scenario from which this result came.</p> required <code>center_frequency</code> <code>float</code> <p>the center frequency (in hertz) of the sources.</p> required <code>effective_dt</code> <code>float</code> <p>the effective time step (in seconds) along the time axis of the wavefield. This can differ from the simulation dt if the recording undersampling factor is larger than 1.</p> required <code>pde</code> <code>stride.Operator</code> <p>the stride Operator that was executed to run the simulation.</p> required <code>shot</code> <code>stride.Shot</code> <p>the stride Shot which was used for the simulation.</p> required <code>wavefield</code> <code>npt.NDArray[np.float_]</code> <p>an array containing the resulting simulation data.</p> required <code>traces</code> <code>stride.Traces</code> <p>the stride Traces object returned from executing the pde.</p> required"},{"location":"api/results/#neurotechdevkit.results._results.SteadyStateResult.metrics","title":"<code>metrics: dict[str, dict[str, str | float]]</code>  <code>property</code>","text":"<p>A dictionary containing metrics and their descriptions.</p> <p>The keys for the dictionary are the names of the metrics. The value for each metric is another dictionary containing the following:</p> <ul> <li>value: the value of the metric.</li> <li>unit-of-measurement: the unit of measurement for the metric.</li> <li>description: A text description of the metric.</li> </ul>"},{"location":"api/results/#neurotechdevkit.results._results.SteadyStateResult.get_steady_state","title":"<code>get_steady_state()</code>","text":"<p>Return the steady-state array and while computing it if necessary.</p> <p>Returns:</p> Type Description <code>npt.NDArray[np.float_]</code> <p>An array containing steady-state pressure wave amplitudes (in pascals).</p>"},{"location":"api/results/#neurotechdevkit.results.SteadyStateResult2D","title":"<code>SteadyStateResult2D</code>","text":"<p>         Bases: <code>SteadyStateResult</code></p> <p>A container for holding the results of a 2D steady-state simulation.</p> <p>Parameters:</p> Name Type Description Default <code>scenario</code> <code>scenarios.Scenario2D</code> <p>the 2D scenario from which this result came.</p> required <code>center_frequency</code> <code>float</code> <p>the center frequency (in hertz) of the sources.</p> required <code>effective_dt</code> <code>float</code> <p>the effective time step (in seconds) along the time axis of the wavefield. This can differ from the simulation dt if the recording downsampling factor is larger than 1.</p> required <code>pde</code> <code>stride.Operator</code> <p>the stride Operator that was executed to run the simulation.</p> required <code>shot</code> <code>stride.Shot</code> <p>the stride Shot which was used for the simulation.</p> required <code>wavefield</code> <code>npt.NDArray[np.float_]</code> <p>a 3 dimensional array (two axes for space and one for time) containing the resulting simulation data.</p> required <code>traces</code> <code>stride.Traces</code> <p>the stride Traces object returned from executing the pde.</p> required"},{"location":"api/results/#neurotechdevkit.results._results.SteadyStateResult2D.render_steady_state_amplitudes","title":"<code>render_steady_state_amplitudes(show_sources=True, show_target=True, show_material_outlines=True)</code>","text":"<p>Create a matplotlib figure with the steady-state pressure wave amplitude.</p> <p>The grid can be turned on via: <code>plt.grid(True)</code></p> <p>Parameters:</p> Name Type Description Default <code>show_sources</code> <code>bool</code> <p>whether or not to show the source transducer layer.</p> <code>True</code> <code>show_target</code> <code>bool</code> <p>whether or not to show the target layer.</p> <code>True</code> <code>show_material_outlines</code> <code>bool</code> <p>whether or not to display a thin white outline of the transition between different materials.</p> <code>True</code>"},{"location":"api/results/#neurotechdevkit.results.SteadyStateResult3D","title":"<code>SteadyStateResult3D</code>","text":"<p>         Bases: <code>SteadyStateResult</code></p> <p>A container for holding the results of a 3D steady-state simulation.</p> <p>Parameters:</p> Name Type Description Default <code>scenario</code> <code>scenarios.Scenario3D</code> <p>the 3D scenario from which this result came.</p> required <code>center_frequency</code> <code>float</code> <p>the center frequency (in hertz) of the sources.</p> required <code>effective_dt</code> <code>float</code> <p>the effective time step (in seconds) along the time axis of the wavefield. This can differ from the simulation dt if the recording downsampling factor is larger than 1.</p> required <code>pde</code> <code>stride.Operator</code> <p>the stride Operator that was executed to run the simulation.</p> required <code>shot</code> <code>stride.Shot</code> <p>the stride Shot which was used for the simulation.</p> required <code>wavefield</code> <code>npt.NDArray[np.float_]</code> <p>a 4 dimensional array (three axes for space and one for time) containing the resulting simulation data.</p> required <code>traces</code> <code>stride.Traces</code> <p>the stride Traces object returned from executing the pde.</p> required"},{"location":"api/results/#neurotechdevkit.results._results.SteadyStateResult3D.render_steady_state_amplitudes","title":"<code>render_steady_state_amplitudes(slice_axis=None, slice_position=None, show_sources=True, show_target=True, show_material_outlines=True)</code>","text":"<p>Create a matplotlib figure with the steady-state pressure wave amplitude.</p> <p>In order to visualize the 3D scenario in a 2D plot, a slice through the scenario needs to be specified via <code>slice_axis</code> and <code>slice_position</code>. Eg. to take a slice at z=0.01 m, use <code>slice_axis=2</code> and <code>slice_position=0.01</code>.</p> <p>The grid can be turned on via: <code>plt.grid(True)</code></p> <p>Parameters:</p> Name Type Description Default <code>slice_axis</code> <code>int | None</code> <p>the axis along which to slice. If None, then the value returned by <code>scenario.get_default_slice_axis()</code> is used.</p> <code>None</code> <code>slice_position</code> <code>float | None</code> <p>the position (in meters) along the slice axis at which the slice should be made. If None, then the value returned by <code>scenario.get_default_slice_position()</code> is used.</p> <code>None</code> <code>show_sources</code> <code>bool</code> <p>whether or not to show the source transducer layer.</p> <code>True</code> <code>show_target</code> <code>bool</code> <p>whether or not to show the target layer.</p> <code>True</code> <code>show_material_outlines</code> <code>bool</code> <p>whether or not to display a thin white outline of the transition between different materials.</p> <code>True</code>"},{"location":"api/results/#neurotechdevkit.results._results.SteadyStateResult3D.render_steady_state_amplitudes_3d","title":"<code>render_steady_state_amplitudes_3d()</code>","text":"<p>Render the steady-state simulation results in 3D using napari.</p> <p>This function requires the napari package to be installed.</p> <p>Warning</p> <p>Integration with napari is experimental, and do not be surprised if you encounter issues calling this function.</p> <p>This will open up the napari interactive GUI in a separate window. The GUI contains many different controls for controlling the view of the data as well as the rendering of the layers. Among these, you can drag the scenario to view it from different angles, zoom in our out, and turn layers on or off.</p> <p>See the napari documentation for more information on the GUI.</p>"},{"location":"api/results/#neurotechdevkit.results.create_pulsed_result","title":"<code>create_pulsed_result(scenario, center_frequency, effective_dt, pde, shot, wavefield, traces, recorded_slice=None)</code>","text":"<p>Create results from pulsed simulations.</p> <p>Creates a PulsedResult2D or PulsedResult3D depending on the number of wavefield spatial dimensions. If the ndim of the wavefield is N, then the wavefield has N-1 spatial dimensions and 1 time dimension.</p> <p>Parameters:</p> Name Type Description Default <code>scenario</code> <code>scenarios.Scenario</code> <p>the scenario from which this result came.</p> required <code>center_frequency</code> <code>float</code> <p>the center frequency (in hertz) of the sources.</p> required <code>effective_dt</code> <code>float</code> <p>the effective time step (in seconds) along the time axis of the wavefield. This can differ from the simulation dt if the recording downsampling factor is larger than 1.</p> required <code>pde</code> <code>stride.Operator</code> <p>the stride Operator that was executed to run the simulation.</p> required <code>shot</code> <code>stride.Shot</code> <p>the stride Shot which was used for the simulation.</p> required <code>wavefield</code> <code>npt.NDArray[np.float_]</code> <p>an array containing the resulting simulation data.</p> required <code>traces</code> <code>stride.Traces</code> <p>the stride Traces object returned from executing the pde.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if the ndim of the wavefield is less than 3 or more than 4.</p> <p>Returns:</p> Name Type Description <code>Result</code> <code>PulsedResult</code> <p>a PulsedResult2D or PulsedResult3D, depending on the wavefield shape.</p>"},{"location":"api/results/#neurotechdevkit.results.create_steady_state_result","title":"<code>create_steady_state_result(scenario, center_frequency, effective_dt, pde, shot, wavefield, traces)</code>","text":"<p>Create a steady state result.</p> <p>Creates a SteadyStateResult2D or SteadyStateResult3D depending on the number of wavefield spatial dimensions. If the ndim of the wavefield is N, then the wavefield has N-1 spatial dimensions and 1 time dimension.</p> <p>Parameters:</p> Name Type Description Default <code>scenario</code> <code>scenarios.Scenario</code> <p>the scenario from which this result came.</p> required <code>center_frequency</code> <code>float</code> <p>the center frequency (in hertz) of the sources.</p> required <code>effective_dt</code> <code>float</code> <p>the effective time step (in seconds) along the time axis of the wavefield. This can differ from the simulation dt if the recording downsampling factor is larger than 1.</p> required <code>pde</code> <code>stride.Operator</code> <p>the stride Operator that was executed to run the simulation.</p> required <code>shot</code> <code>stride.Shot</code> <p>the stride Shot which was used for the simulation.</p> required <code>wavefield</code> <code>npt.NDArray[np.float_]</code> <p>an array containing the resulting simulation data.</p> required <code>traces</code> <code>stride.Traces</code> <p>the stride Traces object returned from executing the pde.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if the ndim of the wavefield is less than 3 or more than 4.</p> <p>Returns:</p> Name Type Description <code>Result</code> <code>SteadyStateResult</code> <p>a SteadyStateResult2D or SteadyStateResult3D, depending on the wavefield shape.</p>"},{"location":"api/results/#neurotechdevkit.results.load_result_from_disk","title":"<code>load_result_from_disk(filepath)</code>","text":"<p>Load a result from the tarball file stored on disk.</p> <p>Warning</p> <p>This functionality is experimental, so do do not be surprised if you encounter issues calling this function.</p> <p>Load a file that was saved to disk via <code>Result.save_to_disk</code>.</p> <p>If the object saved in <code>filepath</code> is the result from a steady-state simulation the results will contain only the steady-state amplitudes. Instead, for pulsed simulations the result object will contain the original wavefield.</p> <p>This function is particularly useful if simulation is performed in the cloud but the user would like to download the results in order to visualize them locally in 3D.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str | pathlib.Path</code> <p>the path to an existing result file previously saved via Result.save_to_disk.</p> required <p>Returns:</p> Type Description <code>Result</code> <p>A Results object (SteadyStateResult or PulsedResult)</p>"},{"location":"api/scenarios/","title":"Scenarios","text":""},{"location":"api/scenarios/#neurotechdevkit.scenarios.Scenario","title":"<code>neurotechdevkit.scenarios.Scenario(origin, complexity='fast')</code>","text":"<p>         Bases: <code>abc.ABC</code></p> <p>The base scenario.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.complexity","title":"<code>complexity: str</code>  <code>property</code>","text":"<p>The complexity level to use when simulating this scenario.</p> <p>Note</p> <p>The only currently supported complexity is <code>fast</code>.</p> <p>Options are:</p> <ul> <li><code>fast</code>: uses a small grid size (large grid spacing) so that simulations are fast.</li> <li><code>accurate</code>: uses a large grid size (small grid spacing) so that simulation results are accurate.</li> <li><code>balanced</code>: a grid size and grid spacing balanced between <code>fast</code> and <code>accurate</code>.</li> </ul>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.current_target_id","title":"<code>current_target_id: str</code>  <code>property</code> <code>writable</code>","text":"<p>Get or set the id of the currently selected target.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.dt","title":"<code>dt: float</code>  <code>property</code>","text":"<p>The spacing (in seconds) between consecutive timesteps of the simulation.</p> <p>Only available once a simulation has been completed.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.dx","title":"<code>dx: float</code>  <code>property</code>","text":"<p>The spacing (in meters) between spatial grid points.</p> <p>Spacing is the same in each spatial direction.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.extent","title":"<code>extent: npt.NDArray[np.float_]</code>  <code>property</code>","text":"<p>The extent of the spatial grid (in meters).</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.layer_ids","title":"<code>layer_ids: Mapping[str, int]</code>  <code>property</code>","text":"<p>A map between material names and their layer id.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.materials","title":"<code>materials: Mapping[str, Struct]</code>  <code>property</code>","text":"<p>A map between material name and material properties.</p> <ul> <li>vp: the speed of sound (in m/s).</li> <li>rho: the mass density (in kg/m\u00b3).</li> <li>alpha: the absorption (in dB/cm).</li> <li>render_color: the color used when rendering this material in the scenario layout plot.</li> </ul>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.ordered_layers","title":"<code>ordered_layers: list[str]</code>  <code>property</code>","text":"<p>A list of material names in order of their layer id.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.origin","title":"<code>origin: npt.NDArray[np.float_]</code>  <code>property</code>","text":"<p>The spatial coordinates of grid position (0, 0, 0).</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.ppp","title":"<code>ppp: float</code>  <code>property</code>","text":"<p>The number of points per period.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.ppw","title":"<code>ppw: float</code>  <code>property</code>","text":"<p>The number of points per wavelength.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.problem","title":"<code>problem: stride.Problem</code>  <code>property</code>","text":"<p>The stride Problem object.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.scenario_id","title":"<code>scenario_id: str</code>  <code>property</code>","text":"<p>The ID for this scenario.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.shape","title":"<code>shape: npt.NDArray[np.int_]</code>  <code>property</code>","text":"<p>The shape of the spatial grid (in number of grid points).</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.sources","title":"<code>sources: FrozenList[Source]</code>  <code>property</code>","text":"<p>The list of sources currently defined.</p> <p>The source list can be edited only before a simulation is run. Once a simulation is run, the source list will be frozen and can no longer be modified.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.t_max","title":"<code>t_max: float</code>  <code>property</code>","text":"<p>The maximum time (in seconds) of the simulation.</p> <p>Only available once a simulation has been completed.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.t_min","title":"<code>t_min: float</code>  <code>property</code>","text":"<p>The starting time (in seconds) of the simulation.</p> <p>Only available once a simulation has been completed.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.target","title":"<code>target: Target</code>  <code>property</code>","text":"<p>Details about the current target.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.target_center","title":"<code>target_center: npt.NDArray[np.float_]</code>  <code>property</code>","text":"<p>The coordinates of the center of the target region (in meters).</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.target_options","title":"<code>target_options: dict[str, str]</code>  <code>property</code>","text":"<p>Information about each of the available targets for the scenario.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.target_radius","title":"<code>target_radius: float</code>  <code>property</code>","text":"<p>The radius of the target region (in meters).</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.add_source","title":"<code>add_source(source)</code>","text":"<p>Add the specified source to the scenario.</p> <p>Sources can also be added or removed by modifying the Scenario.sources list.</p> <p>Changes can only be made to sources before a simulation has started.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>Source</code> <p>the source to add to the scenario.</p> required"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.get_default_source","title":"<code>get_default_source()</code>  <code>abstractmethod</code>","text":"<p>Create and returns a default source for this scenario.</p> <p>Returns:</p> Type Description <code>Source</code> <p>The default source.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.get_field_data","title":"<code>get_field_data(field)</code>","text":"<p>Return the array of field values across the scenario for a particular field.</p> <p>Common fields include:</p> <ul> <li>vp: the speed of sound (in m/s)</li> <li>rho: the density (in kg/m\u00b3)</li> <li>alpha: absorption (in dB/cm)</li> <li>layer: the layer id at each point over the grid</li> </ul> <p>Parameters:</p> Name Type Description Default <code>field</code> <code>str</code> <p>the name of the field to return.</p> required <p>Returns:</p> Type Description <code>npt.NDArray[np.float_]</code> <p>An array containing the field data.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.get_layer_mask","title":"<code>get_layer_mask(layer_name)</code>","text":"<p>Return the mask for the desired layer.</p> <p>The mask is <code>True</code> at each gridpoint where the requested layer exists, and <code>False</code> elsewhere.</p> <p>Parameters:</p> Name Type Description Default <code>layer_name</code> <code>str</code> <p>the name of the desired layer.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>layer_name</code> does not match the name of one of the existing layers.</p> <p>Returns:</p> Type Description <code>npt.NDArray[np.bool_]</code> <p>A boolean array indicating which gridpoints correspond to the desired layer.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.get_target_mask","title":"<code>get_target_mask()</code>  <code>abstractmethod</code>","text":"<p>Return the mask for the target region.</p> <p>Returns:</p> Type Description <code>npt.NDArray[np.bool_]</code> <p>A boolean array indicating which gridpoints correspond to the target region.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.reset","title":"<code>reset()</code>","text":"<p>Reset the scenario to initial state.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.simulate_pulse","title":"<code>simulate_pulse(center_frequency=500000.0, points_per_period=24, simulation_time=None, recording_time_undersampling=4, n_jobs=None)</code>","text":"<p>Execute a pulsed simulation in 2D.</p> <p>In this simulation, the sources will emit a pulse containing a few cycles of oscillation and then let the pulse propagate out to all edges of the scenario.</p> <p>Note</p> <p>The only supported frequency currently supported is 500kHz. Any other value will raise a NotImplementedError.</p> <p>Warning</p> <p>A poor choice of arguments to this function can lead to a failed simulation. Make sure you understand the impact of supplying parameter values other than the default if you chose to do so.</p> <p>Parameters:</p> Name Type Description Default <code>center_frequency</code> <code>float</code> <p>the center frequency (in hertz) to use for the continuous-wave source output. No other value besides 500kHz (the default) is currently supported.</p> <code>500000.0</code> <code>points_per_period</code> <code>int</code> <p>the number of points in time to simulate for each cycle of the wave.</p> <code>24</code> <code>simulation_time</code> <code>float | None</code> <p>the amount of time (in seconds) the simulation should run. If the value is None, this time will automatically be set to the amount of time it would take to propagate from one corner to the opposite in the medium with the slowest speed of sound in the scenario.</p> <code>None</code> <code>recording_time_undersampling</code> <code>int</code> <p>the undersampling factor to apply to the time axis when recording simulation results. One out of every this many consecutive time points will be recorded and all others will be dropped.</p> <code>4</code> <code>n_jobs</code> <code>int | None</code> <p>the number of threads to be used for the computation. Use None to leverage Devito automatic tuning.</p> <code>None</code> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>if a <code>center_frequency</code> other than 500kHz is provided.</p> <p>Returns:</p> Type Description <code>results.PulsedResult</code> <p>An object containing the result of the 2D pulsed simulation.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.simulate_steady_state","title":"<code>simulate_steady_state(center_frequency=500000.0, points_per_period=24, n_cycles_steady_state=10, time_to_steady_state=None, recording_time_undersampling=4, n_jobs=None)</code>","text":"<p>Execute a steady-state simulation.</p> <p>In this simulation, the sources will emit pressure waves with a continuous waveform until steady-state has been reached. The steady-state wave amplitude is found by taking the Fourier transform of the last <code>n_cycles_steady_state</code> cycles of data and taking the amplitude of the component at the <code>center_frequency</code>.</p> <p>Note</p> <p>The only supported frequency currently supported is 500kHz. Any other value will raise a NotImplementedError.</p> <p>Warning</p> <p>A poor choice of arguments to this function can lead to a failed simulation. Make sure you understand the impact of supplying parameter values other than the default if you chose to do so.</p> <p>Parameters:</p> Name Type Description Default <code>center_frequency</code> <code>float</code> <p>the center frequency (in hertz) to use for the continuous-wave source output. No other value besides 500kHz (the default) is currently supported.</p> <code>500000.0</code> <code>points_per_period</code> <code>int</code> <p>the number of points in time to simulate for each cycle of the wave.</p> <code>24</code> <code>n_cycles_steady_state</code> <code>int</code> <p>the number of complete cycles to use when calculating the steady-state wave amplitudes.</p> <code>10</code> <code>time_to_steady_state</code> <code>float | None</code> <p>the amount of time (in seconds) the simulation should run before measuring the steady-state amplitude. If the value is None, this time will automatically be set to the amount of time it would take to propagate from one corner to the opposite and back in the medium with the slowest speed of sound in the scenario.</p> <code>None</code> <code>recording_time_undersampling</code> <code>int</code> <p>the undersampling factor to apply to the time axis when recording simulation results. One out of every this many consecutive time points will be recorded and all others will be dropped.</p> <code>4</code> <code>n_jobs</code> <code>int | None</code> <p>the number of threads to be used for the computation. Use None to leverage Devito automatic tuning.</p> <code>None</code> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>if a <code>center_frequency</code> other than 500kHz is provided.</p> <p>Returns:</p> Type Description <code>results.SteadyStateResult</code> <p>An object containing the result of the steady-state simulation.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios.Scenario2D","title":"<code>neurotechdevkit.scenarios.Scenario2D</code>","text":"<p>         Bases: <code>Scenario</code></p> <p>A 2D scenario.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario2D.get_target_mask","title":"<code>get_target_mask()</code>","text":"<p>Return the mask for the target region.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario2D.render_layout","title":"<code>render_layout(show_sources=True, show_target=True, show_material_outlines=False)</code>","text":"<p>Create a matplotlib figure showing the 2D scenario layout.</p> <p>The grid can be turned on via: <code>plt.grid(True)</code></p> <p>Parameters:</p> Name Type Description Default <code>show_sources</code> <code>bool</code> <p>whether or not to show the source transducer layer.</p> <code>True</code> <code>show_target</code> <code>bool</code> <p>whether or not to show the target layer.</p> <code>True</code> <code>show_material_outlines</code> <code>bool</code> <p>whether or not to display a thin white outline of the transition between different materials.</p> <code>False</code>"},{"location":"api/scenarios/#neurotechdevkit.scenarios.Scenario3D","title":"<code>neurotechdevkit.scenarios.Scenario3D</code>","text":"<p>         Bases: <code>Scenario</code></p> <p>A 3D scenario.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario3D.viewer_config_3d","title":"<code>viewer_config_3d: rendering.ViewerConfig3D</code>  <code>property</code> <code>abstractmethod</code>","text":"<p>Configuration parameters for 3D visualization of this scenario.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario3D.get_default_slice_axis","title":"<code>get_default_slice_axis()</code>  <code>abstractmethod</code>","text":"<p>Return the default slice_axis for this scenario.</p> <p>This field is used if the slice_axis is not specified when plotting 3D data in 2D.</p> <p>Returns:</p> Type Description <code>int</code> <p>The default slice_axis for this scenario.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario3D.get_default_slice_position","title":"<code>get_default_slice_position(axis)</code>  <code>abstractmethod</code>","text":"<p>Return the default slice_position (in meters) for this scenario.</p> <p>This field is used if the slice_position is not specified when plotting 3D data in 2D.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>int</code> <p>the slice axis.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The default slice_position for this scenario along the given axis.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario3D.get_target_mask","title":"<code>get_target_mask()</code>","text":"<p>Return the mask for the target region.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario3D.render_layout","title":"<code>render_layout(slice_axis=None, slice_position=None, show_sources=True, show_target=True, show_material_outlines=False)</code>","text":"<p>Create a matplotlib figure showing a 2D slice of the scenario layout.</p> <p>In order to visualize the 3D scenario in a 2D plot, a slice through the scenario needs to be specified via <code>slice_axis</code> and <code>slice_position</code>. Eg. to take a slice at z=0.01 m, use <code>slice_axis=2</code> and <code>slice_position=0.01</code>.</p> <p>The grid can be turned on via: <code>plt.grid(True)</code></p> <p>Parameters:</p> Name Type Description Default <code>slice_axis</code> <code>int | None</code> <p>the axis along which to slice. If None, then the value returned by <code>scenario.get_default_slice_axis()</code> is used.</p> <code>None</code> <code>slice_position</code> <code>float | None</code> <p>the position (in meters) along the slice axis at which the slice should be made. If None, then the value returned by <code>scenario.get_default_slice_position()</code> is used.</p> <code>None</code> <code>show_sources</code> <code>bool</code> <p>whether or not to show the source transducer layer.</p> <code>True</code> <code>show_target</code> <code>bool</code> <p>whether or not to show the target layer.</p> <code>True</code> <code>show_material_outlines</code> <code>bool</code> <p>whether or not to display a thin white outline of the transition between different materials.</p> <code>False</code>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario3D.render_layout_3d","title":"<code>render_layout_3d()</code>","text":"<p>Render the scenario layout in 3D using napari.</p> <p>This function requires the napari package to be installed.</p> <p>Warning</p> <p>Integration with napari is experimental, so do not be surprised if you encounter issues calling this function.</p> <p>This will open up the napari interactive GUI in a separate window. The GUI contains many different controls for controlling the view of the data as well as the rendering of the layers. Among these, you can drag the scenario to view it from different angles, zoom in our out, and turn layers on or off.</p> <p>See napari documentation for more information on the GUI: documentation</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario3D.simulate_pulse","title":"<code>simulate_pulse(center_frequency=500000.0, points_per_period=24, simulation_time=None, recording_time_undersampling=4, n_jobs=None, slice_axis=None, slice_position=None)</code>","text":"<p>Execute a pulsed simulation in 3D.</p> <p>In this simulation, the sources will emit a pulse containing a few cycles of oscillation and then let the pulse propagate out to all edges of the scenario.</p> <p>Note</p> <p>The only supported frequency currently supported is 500kHz. Any other value will raise a NotImplementedError.</p> <p>Warning</p> <p>A poor choice of arguments to this function can lead to a failed simulation. Make sure you understand the impact of supplying parameter values other than the default if you chose to do so.</p> <p>Parameters:</p> Name Type Description Default <code>center_frequency</code> <code>float</code> <p>the center frequency (in hertz) to use for the continuous-wave source output. No other value besides 500kHz (the default) is currently supported.</p> <code>500000.0</code> <code>points_per_period</code> <code>int</code> <p>the number of points in time to simulate for each cycle of the wave.</p> <code>24</code> <code>simulation_time</code> <code>float | None</code> <p>the amount of time (in seconds) the simulation should run. If the value is None, this time will automatically be set to the amount of time it would take to propagate from one corner to the opposite in the medium with the slowest speed of sound in the scenario.</p> <code>None</code> <code>recording_time_undersampling</code> <code>int</code> <p>the undersampling factor to apply to the time axis when recording simulation results. One out of every this many consecutive time points will be recorded and all others will be dropped.</p> <code>4</code> <code>n_jobs</code> <code>int | None</code> <p>the number of threads to be used for the computation. Use None to leverage Devito automatic tuning.</p> <code>None</code> <code>slice_axis</code> <code>int | None</code> <p>the axis along which to slice the 3D field to be recorded. If None, then the complete field will be recorded. Use 0 for X axis, 1 for Y axis and 2 for Z axis. Only valid if <code>slice_position</code> is not None.</p> <code>None</code> <code>slice_position</code> <code>float | None</code> <p>the position (in meters) along the slice axis at which the slice of the 3D field should be made. Only valid if <code>slice_axis</code> is not None.</p> <code>None</code> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>if a <code>center_frequency</code> other than 500kHz is provided.</p> <p>Returns:</p> Type Description <code>results.PulsedResult</code> <p>An object containing the result of the 3D pulsed simulation.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios.Scenario0","title":"<code>neurotechdevkit.scenarios.Scenario0(complexity='fast')</code>","text":"<p>         Bases: <code>Scenario2D</code></p> <p>Scenario 0.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._scenario_0.Scenario0._SCENARIO_ID","title":"<code>_SCENARIO_ID = 'scenario-0-v0'</code>  <code>class-attribute</code>","text":""},{"location":"api/scenarios/#neurotechdevkit.scenarios.Scenario1_2D","title":"<code>neurotechdevkit.scenarios.Scenario1_2D(complexity='fast')</code>","text":"<p>         Bases: <code>_Scenario1Mixin</code>, <code>Scenario2D</code></p> <p>A 2D implementation of scenario 1.</p> Scenario 1 is based on benchmark 4 of the following paper <p>Jean-Francois Aubry, Oscar Bates, Christian Boehm, et al., \"Benchmark problems for transcranial ultrasound simulation: Intercomparison of compressional wave models\", The Journal of the Acoustical Society of America 152, 1003 (2022); doi: 10.1121/10.0013426 https://asa.scitation.org/doi/pdf/10.1121/10.0013426</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._scenario_1.Scenario1_2D._SCENARIO_ID","title":"<code>_SCENARIO_ID = 'scenario-1-2d-v0'</code>  <code>class-attribute</code>","text":""},{"location":"api/scenarios/#neurotechdevkit.scenarios.Scenario1_3D","title":"<code>neurotechdevkit.scenarios.Scenario1_3D(complexity='fast')</code>","text":"<p>         Bases: <code>_Scenario1Mixin</code>, <code>Scenario3D</code></p> <p>A 3D implementation of scenario 1.</p> Scenario 1 is based on benchmark 4 of the following paper <p>Jean-Francois Aubry, Oscar Bates, Christian Boehm, et al., \"Benchmark problems for transcranial ultrasound simulation: Intercomparison of compressional wave models\", The Journal of the Acoustical Society of America 152, 1003 (2022); doi: 10.1121/10.0013426 https://asa.scitation.org/doi/pdf/10.1121/10.0013426</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._scenario_1.Scenario1_3D._SCENARIO_ID","title":"<code>_SCENARIO_ID = 'scenario-1-3d-v0'</code>  <code>class-attribute</code>","text":""},{"location":"api/scenarios/#neurotechdevkit.scenarios.Scenario2_2D","title":"<code>neurotechdevkit.scenarios.Scenario2_2D(complexity='fast')</code>","text":"<p>         Bases: <code>_Scenario2Mixin</code>, <code>Scenario2D</code></p> <p>A 2D implementation of scenario 2.</p> Scenario 2 is based on benchmark 8 of the following paper <p>Jean-Francois Aubry, Oscar Bates, Christian Boehm, et al., \"Benchmark problems for transcranial ultrasound simulation: Intercomparison of compressional wave models\", The Journal of the Acoustical Society of America 152, 1003 (2022); doi: 10.1121/10.0013426 https://asa.scitation.org/doi/pdf/10.1121/10.0013426</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._scenario_2.Scenario2_2D._SCENARIO_ID","title":"<code>_SCENARIO_ID = 'scenario-2-2d-v0'</code>  <code>class-attribute</code>","text":""},{"location":"api/scenarios/#neurotechdevkit.scenarios.Scenario2_3D","title":"<code>neurotechdevkit.scenarios.Scenario2_3D(complexity='fast')</code>","text":"<p>         Bases: <code>_Scenario2Mixin</code>, <code>Scenario3D</code></p> <p>A 3D implementation of scenario 2.</p> Scenario 2 is based on benchmark 8 of the following paper <p>Jean-Francois Aubry, Oscar Bates, Christian Boehm, et al., \"Benchmark problems for transcranial ultrasound simulation: Intercomparison of compressional wave models\", The Journal of the Acoustical Society of America 152, 1003 (2022); doi: 10.1121/10.0013426 https://asa.scitation.org/doi/pdf/10.1121/10.0013426</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._scenario_2.Scenario2_3D._SCENARIO_ID","title":"<code>_SCENARIO_ID = 'scenario-2-3d-v0'</code>  <code>class-attribute</code>","text":""},{"location":"api/scenarios/#neurotechdevkit.scenarios.Target","title":"<code>neurotechdevkit.scenarios.Target</code>  <code>dataclass</code>","text":"<p>A class for containing metadata for a target.</p> <p>Attributes:</p> Name Type Description <code>target_id</code> <code>str</code> <p>the string id of the target.</p> <code>center</code> <code>npt.NDArray[np.float_]</code> <p>the location of the center of the target (in meters).</p> <code>radius</code> <code>float</code> <p>the radius of the target (in meters).</p> <code>description</code> <code>str</code> <p>a text describing the target.</p>"},{"location":"api/sources/","title":"Sources","text":""},{"location":"api/sources/#neurotechdevkit.sources.FocusedSource2D","title":"<code>FocusedSource2D</code>","text":"<p>         Bases: <code>Source</code></p> <p>A focused source in 2D.</p> <p>This source is shaped like an arc and has a circular focus. It is created by taking an arc of a circle and distributing point sources evenly along that arc.</p> <p>See Circular arc for relevant geometrical calculations.</p>"},{"location":"api/sources/#neurotechdevkit.sources.FocusedSource2D.calculate_waveform_scale","title":"<code>calculate_waveform_scale(dx)</code>","text":"<p>Calculate the scale factor to apply to waveforms from this source.</p> <p>The scale is equal to the ratio between the density of grid points along a line and the density of source points along the arc.</p> <p>Parameters:</p> Name Type Description Default <code>dx</code> <code>float</code> <p>the separation between gridpoints (in meters). Assumed to be the same in both directions.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The scale factor to apply to the waveform.</p>"},{"location":"api/sources/#neurotechdevkit.sources.FocusedSource3D","title":"<code>FocusedSource3D</code>","text":"<p>         Bases: <code>Source</code></p> <p>A focused source in 3D.</p> <p>This source is shaped like a bowl and has a spherical focus. It is created by taking a section of a spherical shell and distributing source points over the surface. Points are distributed according to Fibonacci spirals.</p> <p>See Spherical cap for relevant geometrical calculations.</p>"},{"location":"api/sources/#neurotechdevkit.sources.FocusedSource3D.calculate_waveform_scale","title":"<code>calculate_waveform_scale(dx)</code>","text":"<p>Calculate the scale factor to apply to waveforms from this source.</p> <p>The scale is equal to the ratio between the density of grid points in a plane and the density of source points along the bowl surface.</p> <p>Parameters:</p> Name Type Description Default <code>dx</code> <code>float</code> <p>the separation between gridpoints (in meters). Assumed to be the same in all 3 directions.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The scale factor to apply to the waveform.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource","title":"<code>PhasedArraySource(*, position, direction, num_points, num_elements, pitch, element_width, tilt_angle=0.0, focal_length=np.inf, delay=0.0, element_delays=None)</code>","text":"<p>         Bases: <code>Source</code></p> <p>A base class for phased array sources.</p> <p>Parameters:</p> Name Type Description Default <code>position</code> <code>npt.NDArray[np.float_]</code> <p>a numpy float array indicating the coordinates (in meters) of the point at the center of the source, which is the point that bisects the line segment source.</p> required <code>direction</code> <code>npt.NDArray[np.float_]</code> <p>a numpy float array representing a vector located at position that is perpendicular to the plane of the source. Only the orientation of <code>direction</code> affects the source, the length of the vector has no affect. See the <code>unit_direction</code> property.</p> required <code>num_points</code> <code>int</code> <p>the number of point sources to use when simulating the source.</p> required <code>num_elements</code> <code>int</code> <p>the number of elements of the phased array.</p> required <code>pitch</code> <code>float</code> <p>the distance (in meters) between the centers of neighboring elements in the phased array.</p> required <code>element_width</code> <code>float</code> <p>the width (in meters) of each individual element of the array.</p> required <code>tilt_angle</code> <code>float</code> <p>the desired tilt angle (in degrees) of the wavefront. The angle is measured between the direction the wavefront travels and the normal to the surface of the transducer, with positive angles resulting in a counter-clockwise tilt away from the normal.</p> <code>0.0</code> <code>focal_length</code> <code>float</code> <p>the distance (in meters) from <code>position</code> to the focal point.</p> <code>np.inf</code> <code>delay</code> <code>float</code> <p>the delay (in seconds) that the source will wait before emitting.</p> <code>0.0</code> <code>element_delays</code> <code>npt.NDArray[np.float_] | None</code> <p>an 1D array with the delays (in seconds) for each element of the phased array. Delays from <code>element_delays</code> take precedence; No other argument affected the delays (<code>tilt_angle</code>, <code>focal_length</code> or <code>delay</code>) would be considered. ValueError will be raised if provided values for either <code>tilt_angle</code>, <code>focal_length</code> or <code>delay</code> are non-default.</p> <code>None</code>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource.aperture","title":"<code>aperture: float</code>  <code>property</code>","text":"<p>The width (in meters) of the source.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource.element_delays","title":"<code>element_delays: npt.NDArray[np.float_]</code>  <code>property</code>","text":"<p>The delay (in seconds) that each element should wait before emitting.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource.element_positions","title":"<code>element_positions: npt.NDArray[np.float_]</code>  <code>property</code>","text":"<p>An array with the position of the center of each element of the array.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource.element_width","title":"<code>element_width: float</code>  <code>property</code>","text":"<p>The width (in meters) of each element of the array.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource.num_elements","title":"<code>num_elements: int</code>  <code>property</code>","text":"<p>The number of elements in the source array.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource.pitch","title":"<code>pitch: float</code>  <code>property</code>","text":"<p>The <code>pitch</code> (in meters) of the source.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource.point_mapping","title":"<code>point_mapping: tuple[slice, ...]</code>  <code>property</code>","text":"<p>A tuple with the slices of source point indexes comprising each element.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource.point_source_delays","title":"<code>point_source_delays: npt.NDArray[np.float_]</code>  <code>property</code>","text":"<p>The delay before emitting (in seconds) for each point source.</p> <p>The delays are computed at the element level. All source points within an element will have the same delay.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource.spacing","title":"<code>spacing: float</code>  <code>property</code>","text":"<p>The separation (in meters) between elements of the array.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource.tilt_angle","title":"<code>tilt_angle: float</code>  <code>property</code>","text":"<p>The angle (in degrees) that the wave front is tilted.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource.focal_point","title":"<code>focal_point()</code>","text":"<p>Get or set the coordinates (in meters) of the focal point of the source.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource.txdelay","title":"<code>txdelay(tilt_angle, pitch, speed=1500)</code>  <code>staticmethod</code>","text":"<p>Compute the delay (in seconds) required to tilt the wavefront.</p> <p>The delays from element n to element n+1 to achieve a wavefront with <code>tilt_angle</code> respect to the normal. Positive angles lead to counter-clockwise rotations.</p> <p>Parameters:</p> Name Type Description Default <code>tilt_angle</code> <code>float</code> <p>angle (in degrees) between the vector normal to the source         and the wavefront.</p> required <code>pitch</code> <code>float</code> <p>the pitch (in meters) of the source.</p> required <code>speed</code> <code>float</code> <p>the speed of sound (in meters/second) of the material where    the source is placed.</p> <code>1500</code> <p>Returns:</p> Type Description <code>float</code> <p>The delay (in seconds) between two consecutive elements.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource2D","title":"<code>PhasedArraySource2D</code>","text":"<p>         Bases: <code>PhasedArraySource</code></p> <p>A phased array source in 2D.</p> <p>This source is shaped like multiple segments in a line. Each segment can emit waves independently. It has no focus currently. A focused implementation will be supported in the future. This source is composed of <code>num_points</code> point sources. Distributed evenly in <code>num_elements</code>.</p> <p>If the number of points can not be evenly distributed in the number of elements, the remainder number of points from the even division will be discarded.</p> <p>See Phased array ultras... for detailed explanation.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource2D.focal_point","title":"<code>focal_point: npt.NDArray[np.float_]</code>  <code>property</code>","text":"<p>The coordinates (in meters) of the point where the array focuses.</p> <p>If the array is unfocused it will return the focal point (inf, inf).</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource2D.calculate_waveform_scale","title":"<code>calculate_waveform_scale(dx)</code>","text":"<p>Calculate the scale factor to apply to waveforms from this source.</p> <p>The scale is equal to the ratio between the density of grid points along a line and the density of source points along the line segment source.</p> <p>Parameters:</p> Name Type Description Default <code>dx</code> <code>float</code> <p>the separation between gridpoints (in meters). Assumed to be the same in both directions.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The scale factor to apply to the waveform.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource3D","title":"<code>PhasedArraySource3D(*, position, direction, center_line, num_points, num_elements, pitch, height, element_width, tilt_angle=0.0, focal_length=np.inf, delay=0.0, element_delays=None)</code>","text":"<p>         Bases: <code>PhasedArraySource</code></p> <p>A linear phased array source in 3D.</p> <p>This source is shaped like multiple rectangular segments in a line. Each segment can emit waves independently. It has no focus currently. A focused implementation will be supported in the future. This source is composed of <code>num_points</code> point sources distributed evenly in <code>num_elements</code>.</p> <p>If the number of points can not be evenly distributed in the number of elements, the remainder number of points from the even division will be discarded.</p> <p>See Phased array ultras... for detailed explanation.</p> <p>Parameters:</p> Name Type Description Default <code>position</code> <code>npt.NDArray[np.float_]</code> <p>a numpy float array in 3D indicating the coordinates (in meters) of the point at the center of the source, which is the point that bisects both the height and the aperture of the source.</p> required <code>direction</code> <code>npt.NDArray[np.float_]</code> <p>a numpy float array in 3D representing a vector located at position that is perpendicular to the plane of the source. Only the orientation of <code>direction</code> affects the source, the length of the vector has no affect. See the <code>unit_direction</code> property.</p> required <code>center_line</code> <code>npt.NDArray[np.float_]</code> <p>A 3D vector which is parallel to the line through the centers of the elements in the linear array. This vector must be perpendicular to <code>direction</code>. If the vector is not perpendicular, only the perpendicular component will be considered. Only the orientation affects the source, the length of the vector has no effect. See <code>unit_center_line</code> property.</p> required <code>num_points</code> <code>int</code> <p>the number of point sources to use when simulating the source. If the number of points is not divisible evenly by the number of elements, the number of points would be truncated to a multiple of the maximum even divisor.</p> required <code>num_elements</code> <code>int</code> <p>the number of elements of the phased array.</p> required <code>pitch</code> <code>float</code> <p>the distance (in meters) between the centers of neighboring elements in the phased array.</p> required <code>height</code> <code>float</code> <p>the height (in meters) of the elements of the array. <code>height</code> is measured along the direction in the plane of the element that is perpendicular to <code>center_line</code>.</p> required <code>element_width</code> <code>float</code> <p>the width (in meters) of each individual element of the array.</p> required <code>tilt_angle</code> <code>float</code> <p>the desired tilt angle (in degrees) of the wavefront. The angle is measured between the direction the wavefront travels and the normal to the surface of the transducer, with positive angles resulting in a counter-clockwise tilt away from the normal.</p> <code>0.0</code> <code>focal_length</code> <code>float</code> <p>the distance (in meters) from <code>position</code> to the focal point.</p> <code>np.inf</code> <code>delay</code> <code>float</code> <p>the delay (in seconds) that the source will wait before emitting.</p> <code>0.0</code> <code>element_delays</code> <code>npt.NDArray[np.float_] | None</code> <p>an 1D array with the delays (in seconds) for each element of the phased array. Delays from <code>element_delays</code> take precedence; No other argument affected the delays (<code>tilt_angle</code>, <code>focal_length</code> or <code>delay</code>) would be considered. ValueError will be raised if provided values for either <code>tilt_angle</code>, <code>focal_length</code> or <code>delay</code> are non-default.</p> <code>None</code>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource3D.focal_point","title":"<code>focal_point: npt.NDArray[np.float_]</code>  <code>property</code>","text":"<p>The coordinates (in meters) of the point where the array focuses.</p> <p>If the array is unfocused it will return the focal point (inf, inf, inf).</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource3D.height","title":"<code>height: float</code>  <code>property</code>","text":"<p>The <code>height</code> (in meters) of the elements of the source.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource3D.unit_center_line","title":"<code>unit_center_line: npt.NDArray[np.float_]</code>  <code>property</code>","text":"<p>The unit direction of the line crossing the center of the array elements.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource3D.calculate_waveform_scale","title":"<code>calculate_waveform_scale(dx)</code>","text":"<p>Calculate the scale factor to apply to waveforms from this source.</p> <p>The scale is equal to the ratio between the density of grid points along a plane and the density of source points along the planar source.</p> <p>Parameters:</p> Name Type Description Default <code>dx</code> <code>float</code> <p>the separation between gridpoints (in meters). Assumed to be the same in both directions.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The scale factor to apply to the waveform.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PlanarSource2D","title":"<code>PlanarSource2D</code>","text":"<p>         Bases: <code>UnfocusedSource</code></p> <p>A planar source in 2D.</p> <p>This source is shaped like a line segment and has no focus. The source is composed of <code>num_points</code> point sources evenly distributed along the line segment.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PlanarSource2D.calculate_waveform_scale","title":"<code>calculate_waveform_scale(dx)</code>","text":"<p>Calculate the scale factor to apply to waveforms from this source.</p> <p>The scale is equal to the ratio between the density of grid points along a line and the density of source points along the line segment source.</p> <p>Parameters:</p> Name Type Description Default <code>dx</code> <code>float</code> <p>the separation between gridpoints (in meters). Assumed to be the same in both directions.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The scale factor to apply to the waveform.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PlanarSource3D","title":"<code>PlanarSource3D</code>","text":"<p>         Bases: <code>UnfocusedSource</code></p> <p>A planar source in 3D.</p> <p>This source is shaped like a disk and has no focus. It is created by defining a disk and distributing <code>num_points</code> point sources according to Fibonacci spirals.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PlanarSource3D.calculate_waveform_scale","title":"<code>calculate_waveform_scale(dx)</code>","text":"<p>Calculate the scale factor to apply to waveforms from this source.</p> <p>The scale is equal to the ratio between the density of grid points along a plane and the density of source points along the disk source.</p> <p>Parameters:</p> Name Type Description Default <code>dx</code> <code>float</code> <p>the separation between gridpoints (in meters). Assumed to be the same in both directions.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The scale factor to apply to the waveform.</p>"},{"location":"api/sources/#neurotechdevkit.sources.Source","title":"<code>Source(*, position, direction, aperture, focal_length, num_points, delay=0.0)</code>","text":"<p>         Bases: <code>abc.ABC</code></p> <p>An abstract class that represents a generic Source object.</p> <p>Sources can be 2D or 3D, which affects the shape of arrays representing coordinates or vectors. Sources are composed of point sources evenly distributed over the appropriate source geometry.</p> <p>Parameters:</p> Name Type Description Default <code>position</code> <code>npt.NDArray[np.float_]</code> <p>a numpy float array indicating the coordinates (in meters) of the point at the center of the source.</p> required <code>direction</code> <code>npt.NDArray[np.float_]</code> <p>a numpy float array representing a vector located at position and pointing towards the focal point. Only the orientation of <code>direction</code> affects the source, the length of the vector has no affect. See the <code>unit_direction</code> property.</p> required <code>aperture</code> <code>float</code> <p>the width (in meters) of the source.</p> required <code>focal_length</code> <code>float</code> <p>the distance (in meters) from <code>position</code> to the focal point.</p> required <code>num_points</code> <code>int</code> <p>the number of point sources to use when simulating the source.</p> required <code>delay</code> <code>float</code> <p>the delay (in seconds) that the source will wait before emitting. Defaults to 0.0.</p> <code>0.0</code>"},{"location":"api/sources/#neurotechdevkit.sources.Source.aperture","title":"<code>aperture: float</code>  <code>property</code>","text":"<p>The width (in meters) of the source.</p>"},{"location":"api/sources/#neurotechdevkit.sources.Source.coordinates","title":"<code>coordinates: npt.NDArray[np.float_]</code>  <code>property</code>","text":"<p>A 2D array containing the <code>coordinates</code> (in meters) of the source points.</p> <p>The length of this array along the first dimension is equal to <code>num_points</code>.</p>"},{"location":"api/sources/#neurotechdevkit.sources.Source.delay","title":"<code>delay: float</code>  <code>property</code>","text":"<p>The <code>delay</code> (in seconds) for the source as a whole.</p> <p><code>delay</code> should be non-negative.</p>"},{"location":"api/sources/#neurotechdevkit.sources.Source.focal_length","title":"<code>focal_length: float</code>  <code>property</code>","text":"<p>The distance (in meters) from <code>position</code> to the focal point.</p>"},{"location":"api/sources/#neurotechdevkit.sources.Source.num_points","title":"<code>num_points: int</code>  <code>property</code>","text":"<p>The number of point sources used to simulate the source.</p>"},{"location":"api/sources/#neurotechdevkit.sources.Source.point_source_delays","title":"<code>point_source_delays: npt.NDArray[np.float_]</code>  <code>property</code>","text":"<p>The delay before emitting (in seconds) for each point source.</p>"},{"location":"api/sources/#neurotechdevkit.sources.Source.position","title":"<code>position: npt.NDArray[np.float_]</code>  <code>property</code>","text":"<p>A numpy float array indicating the <code>position</code> (in meters) of the source.</p> <p>The position of the source is defined as the coordinates of the point at the center of symmetry of the source.</p>"},{"location":"api/sources/#neurotechdevkit.sources.Source.unit_direction","title":"<code>unit_direction: npt.NDArray[np.float_]</code>  <code>property</code>","text":"<p>A normalized vector indicating the orientation of the source.</p> <p>The vector is located at <code>position</code>, points towards the focal point, and has unit length. It points in the same direction as the <code>direction</code> parameter in <code>__init__</code>, except it is normalized.</p>"},{"location":"api/sources/#neurotechdevkit.sources.Source.calculate_waveform_scale","title":"<code>calculate_waveform_scale(dx)</code>  <code>abstractmethod</code>","text":"<p>Calculate the scale factor to apply to waveforms from this source.</p> <p>The scale depends on the relative density of source points vs grid points.</p> <p>This method must be implemented by all concrete Source classes.</p> <p>Parameters:</p> Name Type Description Default <code>dx</code> <code>float</code> <p>the separation (in meters) between gridpoints. Assumed to be the same in all directions.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The scale factor to apply to the waveform.</p>"},{"location":"api/sources/#neurotechdevkit.sources.UnfocusedSource","title":"<code>UnfocusedSource(*, position, direction, aperture, num_points, delay=0.0)</code>","text":"<p>         Bases: <code>Source</code></p> <p>A base class for unfocused sources.</p> <p>Automatically sets <code>focal_length</code> to <code>np.inf</code></p>"},{"location":"api/utils/","title":"Utils","text":""},{"location":"api/utils/#neurotechdevkit.scenarios.add_material_fields_to_problem","title":"<code>neurotechdevkit.scenarios.add_material_fields_to_problem(problem, materials, layer_ids, masks)</code>","text":"<p>Add material fields as media to the problem.</p> <p>Included fields are:</p> <ul> <li>the speed of sound (in m/s)</li> <li>density (in kg/m^3)</li> <li>absorption (in dB/cm)</li> </ul> <p>Parameters:</p> Name Type Description Default <code>problem</code> <code>stride.Problem</code> <p>the stride Problem object to which the media should be added.</p> required <code>materials</code> <code>Mapping[str, Struct]</code> <p>a mapping from material names to Structs containing the material properties.</p> required <code>layer_ids</code> <code>Mapping[str, int]</code> <p>a mapping from material names to integers representing the layer number for each material.</p> required <code>masks</code> <code>Mapping[str, npt.NDArray[np.bool_]]</code> <p>a mapping from material names to boolean masks indicating the gridpoints.</p> required"},{"location":"api/utils/#neurotechdevkit.scenarios.create_grid_circular_mask","title":"<code>neurotechdevkit.scenarios.create_grid_circular_mask(grid, origin, center, radius)</code>","text":"<p>Return a 2D mask array for a circle with the specified parameters.</p> <p>Array elements are True for the gridpoints within the circle and False otherwise.</p> <p>Parameters:</p> Name Type Description Default <code>grid</code> <code>stride.Grid</code> <p>the simulation grid.</p> required <code>origin</code> <code>npt.NDArray[np.float_]</code> <p>the coordinates (in meters) of the grid element (0, 0).</p> required <code>center</code> <code>npt.NDArray[np.float_]</code> <p>the coordinates (in meters) of the center of the circle.</p> required <code>a</code> <p>the radius (in meters) of the circle.</p> required <p>Returns:</p> Type Description <code>npt.NDArray[np.bool_]</code> <p>The 2D boolean mask where gridpoints within the circle are True.</p>"},{"location":"api/utils/#neurotechdevkit.scenarios.make_grid","title":"<code>neurotechdevkit.scenarios.make_grid(extent, dx, extra=50, absorbing=40)</code>","text":"<p>Create a stride Grid.</p> <p>Note that the time component of the grid is not defined here. That is created at simulation time because it depends on simulation parameters.</p> <p>Parameters:</p> Name Type Description Default <code>extent</code> <code>npt.NDArray[np.float_]</code> <p>a 2-tuple or 3-tuple containing the dimensions (in meters) of the simulation.</p> required <code>dx</code> <code>float</code> <p>a float describing the distance (in meters) between grid points.</p> required <code>extra</code> <code>int | Iterable[int]</code> <p>the number of gridpoints to add as boundary layers on each side of the grid. extras are added both before and after the grid on each axis.</p> <code>50</code> <code>absorbing</code> <code>int | Iterable[int]</code> <p>the number of gridpoints within the boundary layers that are absorbing.</p> <code>40</code> <p>Returns:</p> Type Description <code>stride.Grid</code> <p>The stride Grid object.</p>"},{"location":"generated/gallery/","title":"Examples","text":""},{"location":"generated/gallery/#examples","title":"Examples","text":"<p> Plot pulsed simulation </p> <p> Save and load results </p> <p> Plot scenarios </p> <p> Custom source </p> <p> Reading simulation metrics </p> <p> Visualizing 3D results with Napari </p> <p> Adding multiple sources </p> <p> Phased array source </p> <p> Implementing a full scenario </p> <p> Download all examples in Python source code: gallery_python.zip</p> <p> Download all examples in Jupyter notebooks: gallery_jupyter.zip</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"usage/defining_sources/","title":"Sources","text":"<p>NDK provides a simple but flexibly API to control the parameters of sources. Users can specify the parameters and placement of sources, and add them to their simulation.</p> <pre><code>import neurotechdevkit as ndk\nscenario = ndk.make('scenario-2-2d-v0')\nscenario.current_target_id = 'right-inferior-frontal-gyrus'\nsource = ndk.sources.FocusedSource2D(\nposition=np.array([0.19, 0.07]),\ndirection=np.array([-0.5, -1.]),\naperture=0.06,\nfocal_length=0.08,\nnum_points=3000\n)\nscenario.add_source(source)\nscenario.render_layout()\n</code></pre> <p></p> <p>In the visualization of the source, the <code>position</code> parameter of the source corresponds to the point located at the midpoint of the dark arc on the front (concave) edge. The <code>position</code> and <code>direction</code> of the source are accurately shown in the plot, while the <code>aperture</code> and <code>focal_length</code> (radius of curvature) of the rendered source approximately visualize what is defined in the source object. The blue dotted lines indicate the ultrasound waves.</p> <p>Transducer locations are currently not constrained within the scenario or by materials, and so care needs to be taken when configuring a source so that it is embedded inside the skull, for instance, or located outside of the simulation volume.</p> <p>In the future, we plan to implement constraints to avoid overlapping with solid materials or other sources, and to also add helper utilities to assist with placing sources along the surface of the skull using fewer degrees of freedom.</p> <p>If a source is not specified before the scenario is rendered or simulated, then a default source will be used. So you should add the source to the scenario before doing either of these operations (rendering or simulating).</p> <p>Note</p> <p>The visualization of the source in 2D plots currently has some scaling limitations, and transducers with short focal lengths can appear very small. This only affects the visualization and not the simulation, and will be improved in future versions.</p> <p>The implemented source options are:</p> <ul> <li><code>FocusedSource2D</code></li> <li><code>FocusedSource3D</code></li> <li><code>PlanarSource2D</code></li> <li><code>PlanarSource3D</code></li> <li><code>PhasedArraySource2D</code></li> <li><code>PhasedArraySource3D</code></li> </ul> <p>The 2D sources are for 2D scenarios and the 3D sources for 3D scenarios. The parameters to configure the sources are identical between focused and planar sources, except that planar sources have a pre-defined focal length of <code>np.inf</code>.</p> <pre><code>import neurotechdevkit as ndk\nscenario = ndk.make('scenario-2-2d-v0')\nscenario.current_target_id = 'right-inferior-frontal-gyrus'\nsource_position = np.array([0.19, 0.07])\nsource = ndk.sources.PlanarSource2D(\nposition=source_position,\ndirection=scenario.target_center - source_position,\naperture=0.06,\nnum_points=3000\n)\nscenario.add_source(source)\nscenario.render_layout()\n</code></pre> <p></p>"},{"location":"usage/gpu/","title":"GPU support","text":"<p>In order to use your GPU to run NDK simulations you will have to install the NVIDIA HPC SDK.</p> <p>Warning</p> <p>Make sure the HPC SDK environment variables are exported.</p> <p>You will only have to export one environment variable to enable the GPU support for NDK:</p> <pre><code>export PLATFORM=\"nvidia-acc\"\n</code></pre> <p>Now when running NDK simulations you should be able to see <code>platform=nvidiaX</code> in the execution output:</p> <pre><code>import neurotechdevkit as ndk\nscenario = ndk.make('scenario-2-2d-v0')\nresult = scenario.simulate_steady_state()\nresult.render_steady_state_amplitudes()\n</code></pre> <p>Output: <pre><code>...\n\nOperator `acoustic_iso_state` instance configuration:\n     * subs={h_x: 0.0005, h_y: 0.0005}\n* opt=advanced\n     * compiler=pgcc\n     * language=openacc\n     * platform=nvidiaX\n\n...\n</code></pre></p> <p>Warning</p> <p>Simulations with high memory requirement (e.g. 3D simulations) may not fit in the GPU and running them with GPU acceleration might crash the simulation.</p>"},{"location":"usage/loading_scenarios/","title":"Scenarios","text":"<p>Scenarios provide a convenient structure to describe the environment, transcducers, and sensors. A collection of preconfigured scenarios are provided with NDK, and can be loaded using a scenario id.</p> <p>There are currently three scenarios provided with NDK, two of which have both a 2D and 3D version. 2D versions are quick to simulate and are great for testing out ideas quickly before transferring to a 3D simulation.</p> <p>The following is all that's needed to load a pre-defined scenario:</p> <pre><code>import neurotechdevkit as ndk\nscenario = ndk.make('scenario-2-2d-v0')\n</code></pre> <p>The existing scenario ids are:</p> <ul> <li><code>scenario-0-v0</code> (2D) - a simple quickstart toy scenario that enables users to dive in and experiment with their first simulation immediately.</li> <li><code>scenario-1-3d-v0</code> (3D) - a scenario containing a flat 3-layer bone covered by skin, with water above the skin and brain below the bone. This is based on benchmark 4 of Jean-Francois Aubry, et al..</li> <li><code>scenario-2-3d-v0</code> (3D) - a scenario containing a full skull and brain mesh immersed in water. This is based on benchmark 8 of Jean-Francois Aubry, et al..</li> <li><code>scenario-1-2d-v0</code> (2D) - a 2D version of scenario 1.</li> <li><code>scenario-2-2d-v0</code> (2D) - a 2D version of scenario 2.</li> </ul> <p>All of these scenarios are immediately ready for visualization and simulation, with appropriate default parameters used where needed.</p> <pre><code>scenario.render_layout()\n</code></pre> <p></p>"},{"location":"usage/running_simulation/","title":"Simulation","text":"<p>The Neurotech Development Kit provides support for a range of simulation modes, including pulsed simulation and steady-state simulation.</p> <p>Running a simulation takes just a single function call.</p> <pre><code>import neurotechdevkit as ndk\nscenario = ndk.make('scenario-2-2d-v0')\nresult = scenario.simulate_steady_state()\nresult.render_steady_state_amplitudes()\n</code></pre> <p></p>"},{"location":"usage/troubleshooting/","title":"Troubleshooting","text":"<p>This page contains a list of known problems you might face when installing and running NDK and the actions to solve them.</p>"},{"location":"usage/troubleshooting/#error-command-x86_64-linux-gnu-gcc-failed-no-such-file-or-directory-on-linux","title":"<code>error: command 'x86_64-linux-gnu-gcc' failed: No such file or directory</code> on Linux","text":"<p>This error occurs when <code>g++</code> is not installed. You can install it with:</p> <pre><code>apt-get install g++\n</code></pre> <p>and run the installation again.</p>"},{"location":"usage/troubleshooting/#pyrevolveschedulerscrevolvecpp2510-fatal-error-pythonh-no-such-file-or-directory-on-linux","title":"<code>pyrevolve/schedulers/crevolve.cpp:25:10: fatal error: Python.h: No such file or directory</code> on Linux","text":"<p>This error occurs when the <code>python-dev</code> package was not installed. You can install it with: <pre><code>apt-get install python3.10-dev\n</code></pre> replace <code>3.10</code> with your installed python version.</p> <p>And run the installation again.</p>"},{"location":"usage/troubleshooting/#error-legacy-install-failure-on-macos","title":"<code>error: legacy-install-failure</code> on MacOS","text":"<p>This error might occur when <code>brew</code> or <code>pip</code> are outdated.</p> <p>Update brew: <pre><code>brew update\n</code></pre></p> <p>Update pip: <pre><code>pip install --upgrade pip\n</code></pre></p> <p>And run the installation again.</p>"},{"location":"usage/troubleshooting/#error-process-completed-with-exit-code-1-when-installing-stride-on-windows","title":"<code>Error: Process completed with exit code 1.</code> when installing Stride on Windows","text":"<p>Unfortunately Stride can't be installed on a Windows platform, therefore NDK is also unsupported.</p>"},{"location":"usage/troubleshooting/#getting-error-codepycompileerror-module-compilation-failed","title":"Getting error <code>codepy.CompileError: module compilation failed</code>","text":"<p>This error occurs when the compiler wasn't able to perform the compilation, it can be caused by a environment configuration problem. Check the <code>DEVITO_ARCH</code> environment variable, it should be set with the compiler devito will use to compile the code.</p> <p>You can find further information in the Devito documentation.</p>"},{"location":"usage/troubleshooting/#getting-error-codepycompileerror-module-compilation-failed-with-fatal-error-omph-file-not-found","title":"Getting error <code>codepy.CompileError: module compilation failed</code> with <code>fatal error: 'omp.h' file not found</code>","text":"<p>This error occurs when the <code>libomp</code> is not installed or can not be found by the compiler.</p> <p>Make sure to install it and export the environment variable <code>CPATH</code> with the path to the folder containing libomp headers.</p>"},{"location":"usage/troubleshooting/#getting-error-modulenotfounderror-no-module-named-neurotechdevkit","title":"Getting error <code>ModuleNotFoundError: No module named 'neurotechdevkit'</code>","text":"<p>This error is shown when <code>neurotechdevkit</code> is not installed, if you installed it using a virtual environment like poetry you must run the script with <code>poetry run</code> or activate the environment.</p>"},{"location":"usage/troubleshooting/#getting-error-attributeerror-module-napari-has-no-attribute-viewer-when-calling-render_layout_3d","title":"Getting error <code>AttributeError: module 'napari' has no attribute 'Viewer'</code> when calling <code>render_layout_3d</code>","text":"<p>This error is shown when napari is not installed, make sure to run</p> <p><code>pip install \"napari[all]\"</code></p> <p>and try again.</p>"}]}