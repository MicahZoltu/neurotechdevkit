{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Neurotech Development Kit","text":"<p>The Neurotech Development Kit (NDK) is an open-source, community-driven software library designed to lower the barrier of entry to the next generation of neurotechnology for current researchers and companies. It also enables software developers without access to hardware and human subjects to solve open problems in the field. The initial release of NDK provides support for transcranial focused ultrasound stimulation, along with comprehensive documentation, API flexibility, and 2D/3D visualizations. Future areas of interest may include photoacoustic and optical whole-brain imaging.</p> <p>As a community-driven project, we encourage you to contribute code, feedback, and features to help accelerate the development of transformative neurotechnology.</p> <p></p> <p>Check out the NDK documentation page.</p>"},{"location":"#running","title":"Running","text":""},{"location":"#docker","title":"Docker","text":"<p>You can run <code>neurotechdevkit</code> inside a docker container with just a couple of steps:</p> <ol> <li> <p>Install docker</p> </li> <li> <p>Run the following command:</p> <pre><code>docker run -p 8888:8888 -it ghcr.io/agencyenterprise/neurotechdevkit:latest\n</code></pre> <p>The command above will start a Jupyter notebook server with example notebooks you can use to explore <code>neurotechdevkit</code>. Use the printed URL to open it in your browser or connect to it using your IDE.</p> <p>All changes you make to these files will be lost once you stop the docker container.</p> </li> </ol> <p>Note:</p> <p>You can have persisting Jupyter notebooks by running    <pre><code>docker run -p 8888:8888  -v $(pwd)/notebooks:/ndk/notebooks -it ghcr.io/agencyenterprise/neurotechdevkit:latest\n</code></pre>    The command above will create a folder <code>notebooks</code> in your current directory where you can put your jupyter notebooks.</p> <p>We recommend downloading the <code>.zip</code> file with example notebooks from this link, and extracting it into your local <code>notebooks</code> folder so you can access them from the docker.</p>"},{"location":"#local-installation","title":"Local installation","text":"<p>To install and run neurotechdevkit locally check the installation page.</p>"},{"location":"#usage","title":"Usage","text":"<pre><code>import neurotechdevkit as ndk\nscenario = ndk.scenarios.built_in.Scenario0()\nscenario.make_grid()\nscenario.compile_problem()\nresult = scenario.simulate_steady_state()\nresult.render_steady_state_amplitudes(show_material_outlines=False)\n</code></pre>"},{"location":"#acknowledgements","title":"Acknowledgements","text":"<p>Thanks to Fred Ehrsam for supporting this project, Quintin Frerichs and Milan Cvitkovic for providing direction, and to Sumner Norman for his ultrasound and neuroscience expertise. Thanks to Stride for facilitating ultrasound simulations and providing an MIT license for usage within NDK, Devito for providing the backend solver, Napari for great 3D visualization, and to Jean-Francois Aubry, et al. for the basis of the simulation scenarios.</p>"},{"location":"contributing/","title":"Contributing","text":"<p>You can contribute to NDK by creating GitHub issues or by submitting pull requests.</p>"},{"location":"contributing/#reporting-issues","title":"Reporting issues","text":"<p>Feel free to open an issue if you would like to discuss a new feature request or report a bug. When creating a bug report, please include as much information as possible to help us reproduce the bug as well as what the actual and expected behavior is.</p>"},{"location":"contributing/#contributing-code","title":"Contributing code","text":""},{"location":"contributing/#standards","title":"Standards","text":"<p>To ensure efficient collaborative development, a variety of standards are utilized in this project.</p> <ul> <li>Black code formatter is used.</li> <li>Flake8 is used for linting.</li> <li>isort is used for sorting the imports.</li> <li>pyright is used for static type checking.</li> <li>Type hinting is used.<ul> <li>And checked using mypy.</li> </ul> </li> <li>Pylint is used for spell checking.</li> </ul>"},{"location":"contributing/#preparing-your-environment","title":"Preparing your environment","text":"<p>Start by cloning the repository:</p> <pre><code>git clone https://github.com/agencyenterprise/neurotechdevkit.git\ncd neurotechdevkit\n</code></pre>"},{"location":"contributing/#running-on-docker","title":"Running on docker","text":"<p>If you don't want to install NDK's dependencies on your machine, you can run it in a container:</p> <ul> <li> <p>Install Docker.</p> </li> <li> <p>Run the container, which will start a jupyter notebook server:    <pre><code>docker compose up\n</code></pre></p> </li> <li> <p>Connect to the jupyter notebook directly in your browser or with your IDE.</p> </li> </ul>"},{"location":"contributing/#running-locally","title":"Running locally","text":"<p>This project requires Python <code>&gt;=3.9</code> and <code>&lt;3.11</code> to be installed. You can find the Python version you have installed by running <code>python --version</code> in a terminal. If you don't have Python installed or are running an unsupported version, you can download a supported version from python.org.</p> <p>We use poetry to manage dependencies and virtual environments. Follow the instructions from poetry's documentation to install it if you don't have it on your system.</p> <p>Install the dependencies by running the following command in a shell within the project directory:</p> <pre><code>poetry install\n</code></pre> <p>This will resolve and install the dependencies from <code>poetry.lock</code> and will install the <code>neurotechdevkit</code> package in editable mode.</p> <p>Install stride with:</p> <pre><code>$ poetry run pip install git+https://github.com/trustimaging/stride\n</code></pre> <p>Follow the steps described in Setting up a compiler.</p>"},{"location":"contributing/#using-the-environment","title":"Using the environment","text":"<p>If you are not already using a virtual environment, <code>poetry</code> will create one for you by default. You will need to use this virtual env when using or working on the package.</p> <p>Activate the environment directly via:</p> <pre><code>poetry shell\n</code></pre> <p>If you are already using your own virtual environment, you should not need to change anything.</p>"},{"location":"contributing/#code-requirements-and-conventions","title":"Code requirements and conventions","text":"<p>Note</p> <p>The following commands require <code>GNU make</code> to be installed, on Windows you can install it with Chocolatey:</p> <p><code>choco install make</code></p> <p>Before opening a pull request, please make sure that all of the following requirements are met:</p> <ol> <li>all unit and integration tests are passing:    <pre><code>make test\n</code></pre></li> <li>the code is linted and formatted:    <pre><code>make lint\n</code></pre></li> <li>type hinting is used on all function and method parameters and return values, excluding tests</li> <li>docstring usage conforms to the following:<ol> <li>all docstrings should follow PEP257 Docstring Conventions</li> <li>all public API classes, functions, methods, and properties have docstrings and follow the Google Python Style Guide</li> <li>docstrings on private objects are not required, but are encouraged where they would significantly aid understanding</li> </ol> </li> <li>testing is done using the pytest library, and test coverage should not unnecessarily decrease.</li> </ol>"},{"location":"contributing/#process","title":"Process","text":""},{"location":"contributing/#versioning","title":"Versioning","text":"<p>NDK uses semantic versioning to identify its releases.</p> <p>We use the release on push github action to generate the new version for each release. This github action generates the version based on a pull request label assigned before merge. The supported labels are:</p> <ul> <li><code>release-patch</code></li> <li><code>release-minor</code></li> <li><code>release-major</code></li> <li><code>norelease</code></li> </ul>"},{"location":"contributing/#automatic-release","title":"Automatic release","text":"<p>Merged pull requests with one of the labels <code>release-patch</code>, <code>release-minor</code> or <code>release-major</code> will trigger a release job on CI.</p> <p>The release job will:</p> <ol> <li>generate a new package version using semantic versioning provided by release on push</li> <li>update the <code>pyproject.toml</code> version using <code>poetry</code></li> <li>commit the updated <code>pyproject.toml</code> file using the git-auto-commit action</li> <li>push the package to pypi using poetry publish</li> <li>build a new docker image and tag it with the previously generated semantic version</li> </ol> <p>Pull requests merged with the tag <code>norelease</code> will not trigger any of the actions listed above.</p>"},{"location":"contributing/#gallery-of-examples","title":"Gallery of examples","text":"<p>The examples you can find in the official documentation are python scripts executed in CI.</p> <p>Running these scripts is a resource intensive and time consuming task, for this reason we are using CircleCI instead of Github Actions (as we can choose a more powerful machine to execute the job).</p>"},{"location":"contributing/#checking-ndk-documentation-on-ci","title":"Checking NDK documentation on CI","text":"<p>All pull requests trigger a CI job that builds the documentation and makes the built files available.</p> <p>To check the generated documentation in a pull request:</p> <ol> <li>Scroll to the bottom of the page and click on the <code>Show all checks</code> link.</li> <li>Click on the details link of the <code>Check the rendered docs here!</code> job.        </li> </ol> <p>Note</p> <p>The <code>Examples</code> section is not properly rendered when the documentation is built   on CI. The links of the thumbnails in <code>gallery/index.html</code> point to broken paths,   in order to check one of the examples you will have to click on the left panel,   as shown in the image below:       Within each example, the outputs of cells are also not properly displayed.</p>"},{"location":"conventions/","title":"Conventions","text":"<p>Below are some of the conventions that we are or would like to follow in NDK. This page should be considered incomplete as there are conventions being followed in the codebase which are not described here. We should add to this doc incrementally as part of relevant PRs.</p>"},{"location":"conventions/#units-of-measurement","title":"Units of Measurement","text":"<p>Unit of measurement (uom) labels should be used wherever relevant throughout docstrings, documentation, plots, and textual output.</p> <p>For internal methods and computation steps, always express values using uom without scale prefixes (eg. m rather than mm or km). When values are provided by the user (via parameters) or shown directly to the user (via plots or textual output) scaling prefixes can be used if there is a clear convention in the ultrasound community for which prefix should be used.</p>"},{"location":"conventions/#in-docstrings","title":"In docstrings","text":"<ul> <li>include units for all parameters and return values that have meaningful units<ul> <li>put the uom in parentheses after \"in\". Eg: \"distance (in meters)\"</li> </ul> </li> <li>when the uom has an SI name, write out the name fully with the correct capitalization (eg. seconds, meters, pascals)</li> <li>when the uom does not have an SI name, use the equation specifying the uom (eg. m/s, W/cm\u00b2)</li> </ul>"},{"location":"conventions/#in-plots","title":"In plots","text":"<ul> <li>for axis labels, use the uom abbreviation in parentheses. eg: \"Pressure (Pa)\"</li> </ul>"},{"location":"conventions/#for-metrics","title":"For metrics","text":"<ul> <li>include a specific uom in the output for each metric</li> </ul>"},{"location":"conventions/#adding-to-conventions","title":"Adding to Conventions","text":"<p>Whenever new conventions are used, they should be added to this document within the PR where the conventions were first added.</p> <p>Whenever existing conventions are discovered or refined (such as through PR review discussion), the conventions should be added or updated in this document as part of that PR.</p>"},{"location":"installation/","title":"Installation","text":"<p>You can run NDK without installing the package using docker, as shown here. However, if you'd like to install it, please follow the instructions below.</p> Before installing on Windows <ol> <li> <p>Install Ubuntu on WSL.</p> </li> <li> <p>Follow the the <code>Linux</code> steps described in this page inside your Ubuntu shell.</p> </li> </ol> <p><code>neurotechdevkit</code> requires Python <code>&gt;=3.9</code> and <code>&lt;3.11</code> to be installed. You can find which Python version you have installed by running <code>python --version</code> in a terminal.</p> <p>If you don't have Python installed, or you are running an unsupported version, you can download it from python.org. Python environment managers like pyenv, conda, and poetry are all perfectly suitable as well.</p> Before installing on Linux <ol> <li> <p>In order to install <code>neurotechdevkit</code> you must first install <code>g++</code> and the <code>python-dev</code> package for your python version.</p> <p>Both packages can be installed with: <pre><code>apt-get install -y g++ python3.10-dev\n</code></pre></p> <p>Important: You must replace <code>3.10</code> with your python version when running the command above.</p> </li> </ol> <p>You can install the <code>neurotechdevkit</code> package using:</p> <pre><code>pip install neurotechdevkit\n</code></pre> <p>You also have to install stride, it can be done running:</p> <pre><code>pip install git+https://github.com/trustimaging/stride\n</code></pre>"},{"location":"installation/#setting-up-a-compiler","title":"Setting up a compiler","text":"<p>NDK uses devito to perform the heavy computational operations. Devito generates, compiles and runs C code to achieve better performance. The compiler used by Devito has to be selected, and paths for the linker might also be added as environment variables.</p> <p>As a last step before running NDK, follow the instructions below depending on your OS.</p> Before running on MacOS <p>The two main compiler options for MacOS are clang and gcc.</p> Before running on Linux <ol> <li> <p>Export the <code>DEVITO_ARCH</code> environment variable, or add it to your shell profile:</p> <pre><code>export DEVITO_ARCH=\"gcc\"\n</code></pre> <p>The supported values for <code>DEVITO_ARCH</code> are: <code>'custom', 'gnu', 'gcc', 'clang', 'aomp', 'pgcc', 'pgi', 'nvc', 'nvc++', 'nvidia', 'cuda', 'osx', 'intel', 'icpc', 'icc', 'intel-knl', 'knl', 'dpcpp', 'gcc-4.9', 'gcc-5', 'gcc-6', 'gcc-7', 'gcc-8', 'gcc-9', 'gcc-10', 'gcc-11'</code>.</p> </li> </ol> <p>Note</p> <p>After installing <code>neurotechdevkit</code> you can use Jupyter to explore the package.</p> <p>To get started, we recommend downloading the example notebooks from this link.</p> <p>On Linux you can download and extract the notebooks running the following commands:</p> <ol> <li><code>sudo apt-get update &amp;&amp; sudo apt-get install -y unzip wget</code></li> <li><code>wget \"https://agencyenterprise.github.io/neurotechdevkit/generated/gallery/gallery_jupyter.zip\" -O temp.zip &amp;&amp; unzip temp.zip &amp;&amp; rm temp.zip</code></li> </ol>"},{"location":"installation/#clang","title":"clang","text":"<p>If you prefer to use clang you will have to install <code>libomp</code> and <code>llvm</code>, you will also have to export a few environment variables needed by the compiler.</p> <ol> <li> <p>Install libomp</p> <pre><code>brew install libomp\n</code></pre> </li> <li> <p>Run the following command to export a new environment variable <code>CPATH</code> with the path for <code>libomp</code> headers:</p> <pre><code>echo 'export CPATH=\"'$(brew --prefix)'/opt/libomp/include\"' &gt;&gt; ~/.zshrc\n</code></pre> </li> <li> <p>Install <code>llvm</code>:</p> <pre><code>brew install llvm\n</code></pre> </li> <li> <p>Run the following commands to export the <code>llvm</code> environment variables:</p> <pre><code>echo 'export PATH=\"'$(brew --prefix)'/opt/llvm/bin:$PATH\"' &gt;&gt; ~/.zshrc\necho 'export LDFLAGS=\"-L'$(brew --prefix)'/opt/llvm/lib\"' &gt;&gt; ~/.zshrc\necho 'export CPPFLAGS=\"-I'$(brew --prefix)'/opt/llvm/include\"' &gt;&gt; ~/.zshrc\n</code></pre> </li> <li> <p>The following command will export the <code>DEVITO_ARCH</code> environment variable:</p> <pre><code>echo 'export DEVITO_ARCH=\"clang\"' &gt;&gt; ~/.zshrc\n</code></pre> </li> <li> <p>Load the modified zsh configuration file:</p> <pre><code>source ~/.zshrc\n</code></pre> </li> </ol>"},{"location":"installation/#gcc","title":"gcc","text":"<p>On MacOS the <code>gcc</code> executable is a symbolic link to <code>clang</code>, so by defining DEVITO_ARCH=gcc devito will try to add <code>gcc</code> flags to the <code>clang</code> compiler, and the compilation will most probably fail.</p> <p>You can tell devito to use the correct <code>gcc</code> compiler doing the following:</p> <ol> <li> <p>Install gcc-11</p> <pre><code>brew install gcc@11\n</code></pre> </li> <li> <p>Run the command that exports the <code>DEVITO_ARCH</code> environment variable:</p> <pre><code>echo 'export DEVITO_ARCH=\"gcc-11\"' &gt;&gt; ~/.zshrc\n</code></pre> </li> <li> <p>Load the modified zsh configuration file:</p> <pre><code>source ~/.zshrc\n</code></pre> </li> </ol>"},{"location":"api/grid/","title":"Grid","text":""},{"location":"api/grid/#neurotechdevkit.grid.Grid","title":"<code>Grid</code>","text":"<p>         Bases: <code>stride.Grid</code></p> <p>Grid class for neurotechdevkit. It is a subclass of stride.Grid.</p> <p>The grid is a container for the spatial and temporal grids. It is used to define the simulation domain and the grid spacing.</p>"},{"location":"api/grid/#neurotechdevkit.grid.Grid.make_grid","title":"<code>make_grid(extent, speed_water, center_frequency, ppw, extra=50, absorbing=40)</code>  <code>staticmethod</code>","text":"<p>Create an NDK Grid.</p> <p>Note that the time component of the grid is not defined here. That is created at simulation time because it depends on simulation parameters.</p> <p>Parameters:</p> Name Type Description Default <code>extent</code> <code>Union[Tuple[float, float], Tuple[float, float, float]]</code> <p>a tuple of two or three floats representing the dimensions (in meters) of the simulation.</p> required <code>speed_water</code> <code>float</code> <p>a float representing the speed of sound in water (in m/s).</p> required <code>center_frequency</code> <code>float</code> <p>a float representing the center frequency of the source (in Hz).</p> required <code>ppw</code> <code>int</code> <p>an integer representing the number of points per wavelength.</p> required <code>extra</code> <code>Union[int, Iterable[int]]</code> <p>an integer or an iterable of integers representing the number of gridpoints to add as boundary layers on each side of the grid. Extras are added both before and after the grid on each axis. Default is 50.</p> <code>50</code> <code>absorbing</code> <code>Union[int, Iterable[int]]</code> <p>an integer or an iterable of integers representing the number of gridpoints within the boundary layers that are absorbing. Default is 40.</p> <code>40</code> <p>Returns:</p> Name Type Description <code>Grid</code> <code>Grid</code> <p>the Grid object.</p>"},{"location":"api/grid/#neurotechdevkit.grid.Grid.make_shaped_grid","title":"<code>make_shaped_grid(shape, spacing)</code>  <code>staticmethod</code>","text":"<p>Create an NDK Grid with the given shape.</p> <p>Parameters:</p> Name Type Description Default <code>shape</code> <code>Tuple[int, int]</code> <p>a tuple of two integers representing the shape of the grid.</p> required <code>spacing</code> <code>float</code> <p>a float representing the axis-wise spacing of the grid, in meters.</p> required <p>Returns:</p> Name Type Description <code>Grid</code> <code>Grid</code> <p>the Grid object.</p>"},{"location":"api/materials/","title":"Materials","text":""},{"location":"api/materials/#neurotechdevkit.materials.AttenuationConstant","title":"<code>AttenuationConstant</code>  <code>dataclass</code>","text":"<p>The parameters of the attenuation constant.</p>"},{"location":"api/materials/#neurotechdevkit.materials.AttenuationConstant.calculate_absorption","title":"<code>calculate_absorption(frequency)</code>","text":"<p>Calculate the absorption coefficient for a given center frequency.</p> The absorption coefficient is calculated using the following formula <p>\u03b1(f) = \u03b10 * f^b</p> <p>We convert the absorption coefficient from Np/m/Hz to dB/m/Hz multiplying it by 8.6860000037.</p> <p>Parameters:</p> Name Type Description Default <code>frequency</code> <code>float</code> <p>in Hz</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>attenuation in dB/cm/MHz</p>"},{"location":"api/materials/#neurotechdevkit.materials.Material","title":"<code>Material</code>  <code>dataclass</code>","text":"<p>         Bases: <code>_BaseMaterial</code></p> <p>An NDK Material with an attenuation coefficient.</p>"},{"location":"api/materials/#neurotechdevkit.materials.Material.to_struct","title":"<code>to_struct()</code>","text":"<p>Return a Struct representation of the material.</p> <p>Returns:</p> Name Type Description <code>Struct</code> <code>Struct</code> <p>a Struct representation of the material.</p>"},{"location":"api/materials/#neurotechdevkit.materials.get_material","title":"<code>get_material(material_name, center_frequency=500000.0)</code>","text":"<p>Get a material with properties used in the neurotechdevkit scenarios.</p> <p>Parameters:</p> Name Type Description Default <code>material_name</code> <code>str</code> <p>the name of the material. E.g. \"water\"</p> required <code>center_frequency</code> <code>float</code> <p>The center frequency of the transducer. Defaults to 5.0e5.</p> <code>500000.0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>raised if the material is not supported.</p> <p>Returns:</p> Name Type Description <code>Material</code> <code>Material</code> <p>a material with properties used in the neurotechdevkit.</p>"},{"location":"api/materials/#neurotechdevkit.materials.get_render_color","title":"<code>get_render_color(material_name)</code>","text":"<p>Get the render color for a material.</p> <p>Parameters:</p> Name Type Description Default <code>material_name</code> <code>str</code> <p>the name of the material. E.g. \"water\"</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>raised if the material is not supported.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>the render color of the material.</p>"},{"location":"api/problem/","title":"Problem","text":""},{"location":"api/problem/#neurotechdevkit.problem.Problem","title":"<code>Problem(grid, *args, **kwargs)</code>","text":"<p>         Bases: <code>stride.Problem</code></p> <p>Problem class for NDK. It is a subclass of stride.Problem.</p> <p>The problem defines a medium with a set of fields (such as Vp or density), some transducers (such as a series of scalar point transducers), a geometry where those transducers are located in space, and the acquisitions that happen given that geometry.</p> <p>Parameters:</p> Name Type Description Default <code>grid</code> <code>Grid</code> <p>the grid to use for the problem.</p> required"},{"location":"api/problem/#neurotechdevkit.problem.Problem.add_material_fields","title":"<code>add_material_fields(materials, masks)</code>","text":"<p>Add material fields as media to the problem.</p> <p>Included fields are:</p> <ul> <li>the speed of sound (in m/s)</li> <li>density (in kg/m^3)</li> <li>absorption (in dB/cm)</li> </ul> <p>Parameters:</p> Name Type Description Default <code>materials</code> <code>Mapping[str, Struct]</code> <p>a mapping from material names to Structs containing the material properties.</p> required <code>masks</code> <code>Mapping[str, npt.NDArray[np.bool_]]</code> <p>a mapping from material names to boolean masks indicating the gridpoints.</p> required"},{"location":"api/results/","title":"Results","text":""},{"location":"api/results/#neurotechdevkit.results.PulsedResult","title":"<code>PulsedResult</code>  <code>dataclass</code>","text":"<p>         Bases: <code>Result</code></p> <p>A base container for holding the results of a pulsed simulation.</p> <p>This class should not be instantiated, use PulsedResult2D or PulsedResult3D.</p> <p>Parameters:</p> Name Type Description Default <code>scenario</code> <code>scenario.Scenario</code> <p>the scenario from which this result came.</p> required <code>center_frequency</code> <code>float</code> <p>the center frequency (in hertz) of the sources.</p> required <code>effective_dt</code> <code>float</code> <p>the effective time step (in seconds) along the time axis of the wavefield. This can differ from the simulation dt if the recording undersampling factor is larger than 1.</p> required <code>pde</code> <code>stride.Operator</code> <p>the stride Operator that was executed to run the simulation.</p> required <code>shot</code> <code>stride.Shot</code> <p>the stride Shot which was used for the simulation.</p> required <code>wavefield</code> <code>npt.NDArray[np.float_]</code> <p>an array containing the resulting simulation data.</p> required <code>traces</code> <code>stride.Traces</code> <p>the stride Traces object returned from executing the pde.</p> required"},{"location":"api/results/#neurotechdevkit.results.PulsedResult2D","title":"<code>PulsedResult2D</code>","text":"<p>         Bases: <code>PulsedResult</code></p> <p>A container for holding the results of a 2D pulsed simulation.</p> <p>Parameters:</p> Name Type Description Default <code>scenario</code> <code>scenarios.Scenario2D</code> <p>the 2D scenario from which this result came.</p> required <code>center_frequency</code> <code>float</code> <p>the center frequency (in hertz) of the sources.</p> required <code>effective_dt</code> <code>float</code> <p>the effective time step (in seconds) along the time axis of the wavefield. This can differ from the simulation dt if the recording downsampling factor is larger than 1.</p> required <code>pde</code> <code>stride.Operator</code> <p>the stride Operator that was executed to run the simulation.</p> required <code>shot</code> <code>stride.Shot</code> <p>the stride Shot which was used for the simulation.</p> required <code>wavefield</code> <code>npt.NDArray[np.float_]</code> <p>a 3 dimensional array (two axes for space and one for time) containing the resulting simulation data.</p> required <code>traces</code> <code>stride.Traces</code> <p>the stride Traces object returned from executing the pde.</p> required"},{"location":"api/results/#neurotechdevkit.results._results.PulsedResult2D.create_video_file","title":"<code>create_video_file(file_name, show_sources=True, show_target=True, show_material_outlines=True, n_frames_undersampling=1, time_lim=None, norm='linear', fps=25, dpi=100, bitrate=2500, overwrite=False)</code>","text":"<p>Save a <code>mp4</code> animation file to disk with the results of the simulation.</p> <p>Currently only mp4 format supported. <code>ffmpeg</code> command line tools needs to be installed.</p> <p>Parameters:</p> Name Type Description Default <code>file_name</code> <code>str</code> <p>the file with path an extension where the animation would be saved. Currently only supports mp4 extension.</p> required <code>show_sources</code> <code>bool</code> <p>whether or not to show the source transducer layer.</p> <code>True</code> <code>show_target</code> <code>bool</code> <p>whether or not to show the target layer.</p> <code>True</code> <code>show_material_outlines</code> <code>bool</code> <p>whether or not to display a thin white outline of the transition between different materials.</p> <code>True</code> <code>n_frames_undersampling</code> <code>int</code> <p>the number of time steps to be skipped when creating the animation.</p> <code>1</code> <code>time_lim</code> <code>tuple[np.float_, np.float_] | None</code> <p>the input time limit tuple to validate. The expected format is (minimum_time, maximum_time).</p> <code>None</code> <code>norm</code> <code>str</code> <p>the normalization method used to scale scalar data to the [0, 1] range before mapping to colors using cmap. For a list of available scales, call <code>matplotlib.scale.get_scale_names()</code>.</p> <code>'linear'</code> <code>fps</code> <code>int</code> <p>the frames per second in the animation.</p> <code>25</code> <code>dpi</code> <code>int</code> <p>the number of dots per inch in the frames of the animation.</p> <code>100</code> <code>bitrate</code> <code>int</code> <p>the bitrate for the saved movie file, which is one way to control the output file size and quality.</p> <code>2500</code> <code>overwrite</code> <code>bool</code> <p>a boolean that allows the animation to be saved with the same file name that is already exists.</p> <code>False</code>"},{"location":"api/results/#neurotechdevkit.results._results.PulsedResult2D.render_pulsed_simulation_animation","title":"<code>render_pulsed_simulation_animation(show_sources=True, show_target=True, show_material_outlines=True, n_frames_undersampling=1, time_lim=None, norm='linear')</code>","text":"<p>Create a matplotlib animation with the time evolution of the wavefield.</p> <p>The created animation will be displayed as an interactive widget in a IPython or Jupyter Notebook environment. In a non-interactive environment (script) the result of this animation would be lost. Use <code>create_video_file</code> method instead.</p> <p>Parameters:</p> Name Type Description Default <code>show_sources</code> <code>bool</code> <p>whether or not to show the source transducer layer.</p> <code>True</code> <code>show_target</code> <code>bool</code> <p>whether or not to show the target layer.</p> <code>True</code> <code>show_material_outlines</code> <code>bool</code> <p>whether or not to display a thin white outline of the transition between different materials.</p> <code>True</code> <code>n_frames_undersampling</code> <code>int</code> <p>the number of time steps to be skipped when creating the animation.</p> <code>1</code> <code>time_lim</code> <code>tuple[np.float_, np.float_] | None</code> <p>the input time limit tuple to validate. The expected format is (minimum_time, maximum_time).</p> <code>None</code> <code>norm</code> <code>str</code> <p>the normalization method used to scale scalar data to the [0, 1] range before mapping to colors using cmap. For a list of available scales, call <code>matplotlib.scale.get_scale_names()</code>.</p> <code>'linear'</code> <p>Returns:</p> Type Description <code>FuncAnimation</code> <p>An matplotlib animation object.</p>"},{"location":"api/results/#neurotechdevkit.results.PulsedResult3D","title":"<code>PulsedResult3D</code>","text":"<p>         Bases: <code>PulsedResult</code></p> <p>A container for holding the results of a 3D pulsed simulation.</p> <p>Parameters:</p> Name Type Description Default <code>scenario</code> <code>scenarios.Scenario3D</code> <p>the 3D scenario from which this result came.</p> required <code>center_frequency</code> <code>float</code> <p>the center frequency (in hertz) of the sources.</p> required <code>effective_dt</code> <code>float</code> <p>the effective time step (in seconds) along the time axis of the wavefield. This can differ from the simulation dt if the recording downsampling factor is larger than 1.</p> required <code>pde</code> <code>stride.Operator</code> <p>the stride Operator that was executed to run the simulation.</p> required <code>shot</code> <code>stride.Shot</code> <p>the stride Shot which was used for the simulation.</p> required <code>wavefield</code> <code>npt.NDArray[np.float_]</code> <p>a 4 dimensional array (three axes for space and one for time) containing the resulting simulation data.</p> required <code>traces</code> <code>stride.Traces</code> <p>the stride Traces object returned from executing the pde.</p> required"},{"location":"api/results/#neurotechdevkit.results._results.PulsedResult3D.create_video_file","title":"<code>create_video_file(file_name, show_sources=True, show_target=True, show_material_outlines=True, n_frames_undersampling=1, slice_axis=None, slice_position=None, time_lim=None, norm='linear', fps=25, dpi=100, bitrate=2500, overwrite=False)</code>","text":"<p>Save a <code>mp4</code> animation file to disk with the results of the simulation.</p> <p>Currently only mp4 format supported. <code>ffmpeg</code> command line tools needs to be installed.</p> <p>Parameters:</p> Name Type Description Default <code>file_name</code> <code>str</code> <p>the file with path an extension where the animation would be saved. Currently only supports mp4 extension.</p> required <code>show_sources</code> <code>bool</code> <p>whether or not to show the source transducer layer.</p> <code>True</code> <code>show_target</code> <code>bool</code> <p>whether or not to show the target layer.</p> <code>True</code> <code>show_material_outlines</code> <code>bool</code> <p>whether or not to display a thin white outline of the transition between different materials.</p> <code>True</code> <code>n_frames_undersampling</code> <code>int</code> <p>the number of time steps to be skipped when creating the animation.</p> <code>1</code> <code>slice_axis</code> <code>int | None</code> <p>the axis along which to slice.</p> <code>None</code> <code>slice_position</code> <code>float | None</code> <p>the position (in meters) along the slice axis at which the slice should be made.</p> <code>None</code> <code>time_lim</code> <code>tuple[np.float_, np.float_] | None</code> <p>the input time limit tuple to validate. The expected format is (minimum_time, maximum_time).</p> <code>None</code> <code>norm</code> <code>str</code> <p>the normalization method used to scale scalar data to the [0, 1] range before mapping to colors using cmap. For a list of available scales, call <code>matplotlib.scale.get_scale_names()</code>.</p> <code>'linear'</code> <code>fps</code> <code>int</code> <p>the frames per second in the animation.</p> <code>25</code> <code>dpi</code> <code>int</code> <p>the number of dots per inch in the frames of the animation.</p> <code>100</code> <code>bitrate</code> <code>int</code> <p>the bitrate for the saved movie file, which is one way to control the output file size and quality.</p> <code>2500</code> <code>overwrite</code> <code>bool</code> <p>a boolean that allows the animation to be saved with the same file name that is already exists.</p> <code>False</code>"},{"location":"api/results/#neurotechdevkit.results._results.PulsedResult3D.render_pulsed_simulation_animation","title":"<code>render_pulsed_simulation_animation(show_sources=True, show_target=True, show_material_outlines=True, n_frames_undersampling=1, time_lim=None, norm='linear')</code>","text":"<p>Create a matplotlib animation with the time evolution of the wavefield.</p> <p>The created animation will be displayed as an interactive widget in a IPython or Jupyter Notebook environment. In a non-interactive environment (script) the result of this animation would be lost. Use <code>create_video_file</code> method instead.</p> <p>Parameters:</p> Name Type Description Default <code>show_sources</code> <code>bool</code> <p>whether or not to show the source transducer layer.</p> <code>True</code> <code>show_target</code> <code>bool</code> <p>whether or not to show the target layer.</p> <code>True</code> <code>show_material_outlines</code> <code>bool</code> <p>whether or not to display a thin white outline of the transition between different materials.</p> <code>True</code> <code>n_frames_undersampling</code> <code>int</code> <p>the number of time steps to be skipped when creating the animation.</p> <code>1</code> <code>time_lim</code> <code>tuple[np.float_, np.float_] | None</code> <p>the input time limit tuple to validate. The expected format is (minimum_time, maximum_time).</p> <code>None</code> <code>norm</code> <code>str</code> <p>the normalization method used to scale scalar data to the [0, 1] range before mapping to colors using cmap. For a list of available scales, call <code>matplotlib.scale.get_scale_names()</code>.</p> <code>'linear'</code> <p>Returns:</p> Type Description <code>FuncAnimation</code> <p>An matplotlib animation object.</p>"},{"location":"api/results/#neurotechdevkit.results.Result","title":"<code>Result</code>  <code>dataclass</code>","text":"<p>         Bases: <code>abc.ABC</code></p> <p>A base container for holding the results of a simulation.</p> <p>This class should not be instantiated, use SteadyStateResult2D, SteadyStateResult3D, PulsedResult2D, or PulsedResult3D.</p> <p>Parameters:</p> Name Type Description Default <code>scenario</code> <code>scenarios.Scenario</code> <p>the scenario from which this result came.</p> required <code>center_frequency</code> <code>float</code> <p>the center frequency (in hertz) of the sources.</p> required <code>effective_dt</code> <code>float</code> <p>the effective time step (in seconds) along the time axis of the wavefield. This can differ from the simulation dt if the recording undersampling factor is larger than 1.</p> required <code>pde</code> <code>stride.Operator</code> <p>the stride Operator that was executed to run the simulation.</p> required <code>shot</code> <code>stride.Shot</code> <p>the stride Shot which was used for the simulation.</p> required <code>wavefield</code> <code>npt.NDArray[np.float_]</code> <p>an array containing the resulting simulation data.</p> required <code>traces</code> <code>stride.Traces</code> <p>the stride Traces object returned from executing the pde.</p> required"},{"location":"api/results/#neurotechdevkit.results._results.Result.save_to_disk","title":"<code>save_to_disk(filepath)</code>","text":"<p>Save the result to a tarball containing the data as a gzip compressed file.</p> <p>The resulting tarball will contain two files:</p> <ul> <li><code>data.gz</code>: gzip compressed file which is a pickle object.</li> <li><code>VERSION</code>: a text file containing the <code>neurotechdevkit</code> version.</li> </ul> <p>Warning</p> <p>This functionality is experimental, so do do not be surprised if you encounter issues calling this function.</p> <p>This function is particularly useful if simulation is performed in the cloud but the user would like to download the results in order to visualize them locally in 3D.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str | pathlib.Path</code> <p>the path to the file where the results should be exported. Usually a .tar.gz file.</p> required"},{"location":"api/results/#neurotechdevkit.results.SteadyStateResult","title":"<code>SteadyStateResult</code>  <code>dataclass</code>","text":"<p>         Bases: <code>Result</code></p> <p>A base container for holding the results of a steady-state simulation.</p> <p>This class should not be instantiated, use SteadyStateResult2D or SteadyStateResult3D.</p> <p>Parameters:</p> Name Type Description Default <code>scenario</code> <code>scenario.Scenario</code> <p>the scenario from which this result came.</p> required <code>center_frequency</code> <code>float</code> <p>the center frequency (in hertz) of the sources.</p> required <code>effective_dt</code> <code>float</code> <p>the effective time step (in seconds) along the time axis of the wavefield. This can differ from the simulation dt if the recording undersampling factor is larger than 1.</p> required <code>pde</code> <code>stride.Operator</code> <p>the stride Operator that was executed to run the simulation.</p> required <code>shot</code> <code>stride.Shot</code> <p>the stride Shot which was used for the simulation.</p> required <code>wavefield</code> <code>npt.NDArray[np.float_]</code> <p>an array containing the resulting simulation data.</p> required <code>traces</code> <code>stride.Traces</code> <p>the stride Traces object returned from executing the pde.</p> required"},{"location":"api/results/#neurotechdevkit.results._results.SteadyStateResult.metrics","title":"<code>metrics: dict[str, dict[str, str | float]]</code>  <code>property</code>","text":"<p>A dictionary containing metrics and their descriptions.</p> <p>The keys for the dictionary are the names of the metrics. The value for each metric is another dictionary containing the following:</p> <ul> <li>value: the value of the metric.</li> <li>unit-of-measurement: the unit of measurement for the metric.</li> <li>description: A text description of the metric.</li> </ul>"},{"location":"api/results/#neurotechdevkit.results._results.SteadyStateResult.get_steady_state","title":"<code>get_steady_state()</code>","text":"<p>Return the steady-state array and while computing it if necessary.</p> <p>Returns:</p> Type Description <code>npt.NDArray[np.float_]</code> <p>An array containing steady-state pressure wave amplitudes (in pascals).</p>"},{"location":"api/results/#neurotechdevkit.results.SteadyStateResult2D","title":"<code>SteadyStateResult2D</code>","text":"<p>         Bases: <code>SteadyStateResult</code></p> <p>A container for holding the results of a 2D steady-state simulation.</p> <p>Parameters:</p> Name Type Description Default <code>scenario</code> <code>scenarios.Scenario2D</code> <p>the 2D scenario from which this result came.</p> required <code>center_frequency</code> <code>float</code> <p>the center frequency (in hertz) of the sources.</p> required <code>effective_dt</code> <code>float</code> <p>the effective time step (in seconds) along the time axis of the wavefield. This can differ from the simulation dt if the recording downsampling factor is larger than 1.</p> required <code>pde</code> <code>stride.Operator</code> <p>the stride Operator that was executed to run the simulation.</p> required <code>shot</code> <code>stride.Shot</code> <p>the stride Shot which was used for the simulation.</p> required <code>wavefield</code> <code>npt.NDArray[np.float_]</code> <p>a 3 dimensional array (two axes for space and one for time) containing the resulting simulation data.</p> required <code>traces</code> <code>stride.Traces</code> <p>the stride Traces object returned from executing the pde.</p> required"},{"location":"api/results/#neurotechdevkit.results._results.SteadyStateResult2D.render_steady_state_amplitudes","title":"<code>render_steady_state_amplitudes(show_sources=True, show_target=True, show_material_outlines=True)</code>","text":"<p>Create a matplotlib figure with the steady-state pressure wave amplitude.</p> <p>The grid can be turned on via: <code>plt.grid(True)</code></p> <p>Parameters:</p> Name Type Description Default <code>show_sources</code> <code>bool</code> <p>whether or not to show the source transducer layer.</p> <code>True</code> <code>show_target</code> <code>bool</code> <p>whether or not to show the target layer.</p> <code>True</code> <code>show_material_outlines</code> <code>bool</code> <p>whether or not to display a thin white outline of the transition between different materials.</p> <code>True</code>"},{"location":"api/results/#neurotechdevkit.results.SteadyStateResult3D","title":"<code>SteadyStateResult3D</code>","text":"<p>         Bases: <code>SteadyStateResult</code></p> <p>A container for holding the results of a 3D steady-state simulation.</p> <p>Parameters:</p> Name Type Description Default <code>scenario</code> <code>scenarios.Scenario3D</code> <p>the 3D scenario from which this result came.</p> required <code>center_frequency</code> <code>float</code> <p>the center frequency (in hertz) of the sources.</p> required <code>effective_dt</code> <code>float</code> <p>the effective time step (in seconds) along the time axis of the wavefield. This can differ from the simulation dt if the recording downsampling factor is larger than 1.</p> required <code>pde</code> <code>stride.Operator</code> <p>the stride Operator that was executed to run the simulation.</p> required <code>shot</code> <code>stride.Shot</code> <p>the stride Shot which was used for the simulation.</p> required <code>wavefield</code> <code>npt.NDArray[np.float_]</code> <p>a 4 dimensional array (three axes for space and one for time) containing the resulting simulation data.</p> required <code>traces</code> <code>stride.Traces</code> <p>the stride Traces object returned from executing the pde.</p> required"},{"location":"api/results/#neurotechdevkit.results._results.SteadyStateResult3D.render_steady_state_amplitudes","title":"<code>render_steady_state_amplitudes(show_sources=True, show_target=True, show_material_outlines=True)</code>","text":"<p>Create a matplotlib figure with the steady-state pressure wave amplitude.</p> <p>In order to visualize the 3D scenario in a 2D plot, a slice through the scenario needs to be specified via <code>slice_axis</code> and <code>slice_position</code>. Eg. to take a slice at z=0.01 m, use <code>slice_axis=2</code> and <code>slice_position=0.01</code>.</p> <p>The grid can be turned on via: <code>plt.grid(True)</code></p> <p>Parameters:</p> Name Type Description Default <code>show_sources</code> <code>bool</code> <p>whether or not to show the source transducer layer.</p> <code>True</code> <code>show_target</code> <code>bool</code> <p>whether or not to show the target layer.</p> <code>True</code> <code>show_material_outlines</code> <code>bool</code> <p>whether or not to display a thin white outline of the transition between different materials.</p> <code>True</code>"},{"location":"api/results/#neurotechdevkit.results._results.SteadyStateResult3D.render_steady_state_amplitudes_3d","title":"<code>render_steady_state_amplitudes_3d()</code>","text":"<p>Render the steady-state simulation results in 3D using napari.</p> <p>This function requires the napari package to be installed.</p> <p>Warning</p> <p>Integration with napari is experimental, and do not be surprised if you encounter issues calling this function.</p> <p>This will open up the napari interactive GUI in a separate window. The GUI contains many different controls for controlling the view of the data as well as the rendering of the layers. Among these, you can drag the scenario to view it from different angles, zoom in our out, and turn layers on or off.</p> <p>See the napari documentation for more information on the GUI.</p>"},{"location":"api/results/#neurotechdevkit.results.create_pulsed_result","title":"<code>create_pulsed_result(scenario, center_frequency, effective_dt, pde, shot, wavefield, traces, recorded_slice=None)</code>","text":"<p>Create results from pulsed simulations.</p> <p>Creates a PulsedResult2D or PulsedResult3D depending on the number of wavefield spatial dimensions. If the ndim of the wavefield is N, then the wavefield has N-1 spatial dimensions and 1 time dimension.</p> <p>Parameters:</p> Name Type Description Default <code>scenario</code> <code>Union[scenarios.Scenario2D, scenarios.Scenario3D]</code> <p>the scenario from which this result came.</p> required <code>center_frequency</code> <code>float</code> <p>the center frequency (in hertz) of the sources.</p> required <code>effective_dt</code> <code>float</code> <p>the effective time step (in seconds) along the time axis of the wavefield. This can differ from the simulation dt if the recording downsampling factor is larger than 1.</p> required <code>pde</code> <code>stride.Operator</code> <p>the stride Operator that was executed to run the simulation.</p> required <code>shot</code> <code>stride.Shot</code> <p>the stride Shot which was used for the simulation.</p> required <code>wavefield</code> <code>npt.NDArray[np.float_]</code> <p>an array containing the resulting simulation data.</p> required <code>traces</code> <code>stride.Traces</code> <p>the stride Traces object returned from executing the pde.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if the ndim of the wavefield is less than 3 or more than 4.</p> <p>Returns:</p> Name Type Description <code>Result</code> <code>Union[PulsedResult2D, PulsedResult3D]</code> <p>a PulsedResult2D or PulsedResult3D, depending on the wavefield shape.</p>"},{"location":"api/results/#neurotechdevkit.results.create_steady_state_result","title":"<code>create_steady_state_result(scenario, center_frequency, effective_dt, pde, shot, wavefield, traces)</code>","text":"<p>Create a steady state result.</p> <p>Creates a SteadyStateResult2D or SteadyStateResult3D depending on the number of wavefield spatial dimensions. If the ndim of the wavefield is N, then the wavefield has N-1 spatial dimensions and 1 time dimension.</p> <p>Parameters:</p> Name Type Description Default <code>scenario</code> <code>Union[scenarios.Scenario2D, scenarios.Scenario3D]</code> <p>the scenario from which this result came.</p> required <code>center_frequency</code> <code>float</code> <p>the center frequency (in hertz) of the sources.</p> required <code>effective_dt</code> <code>float</code> <p>the effective time step (in seconds) along the time axis of the wavefield. This can differ from the simulation dt if the recording downsampling factor is larger than 1.</p> required <code>pde</code> <code>stride.Operator</code> <p>the stride Operator that was executed to run the simulation.</p> required <code>shot</code> <code>stride.Shot</code> <p>the stride Shot which was used for the simulation.</p> required <code>wavefield</code> <code>npt.NDArray[np.float_]</code> <p>an array containing the resulting simulation data.</p> required <code>traces</code> <code>stride.Traces</code> <p>the stride Traces object returned from executing the pde.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if the ndim of the wavefield is less than 3 or more than 4.</p> <p>Returns:</p> Name Type Description <code>Result</code> <code>SteadyStateResult</code> <p>a SteadyStateResult2D or SteadyStateResult3D, depending on the wavefield shape.</p>"},{"location":"api/results/#neurotechdevkit.results.load_result_from_disk","title":"<code>load_result_from_disk(filepath)</code>","text":"<p>Load a result from the tarball file stored on disk.</p> <p>Warning</p> <p>This functionality is experimental, so do do not be surprised if you encounter issues calling this function.</p> <p>Load a file that was saved to disk via <code>Result.save_to_disk</code>.</p> <p>If the object saved in <code>filepath</code> is the result from a steady-state simulation the results will contain only the steady-state amplitudes. Instead, for pulsed simulations the result object will contain the original wavefield.</p> <p>This function is particularly useful if simulation is performed in the cloud but the user would like to download the results in order to visualize them locally in 3D.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str | pathlib.Path</code> <p>the path to an existing result file previously saved via Result.save_to_disk.</p> required <p>Returns:</p> Type Description <code>Result</code> <p>A Results object (SteadyStateResult or PulsedResult)</p>"},{"location":"api/scenarios/","title":"Scenarios","text":""},{"location":"api/scenarios/#neurotechdevkit.scenarios.Scenario","title":"<code>neurotechdevkit.scenarios.Scenario(center_frequency=None, material_properties=None, material_masks=None, origin=None, sources=None, material_outline_upsample_factor=None, target=None, problem=None, grid=None)</code>","text":"<p>         Bases: <code>abc.ABC</code></p> <p>The base scenario.</p> <p>All arguments are optional and can be set after initialization.</p> <p>Parameters:</p> Name Type Description Default <code>center_frequency</code> <code>Optional[float]</code> <p>The center frequency (in hertz) of the scenario. Defaults to None.</p> <code>None</code> <code>material_properties</code> <code>Optional[dict[str, Material]]</code> <p>A map between material name and material properties. Defaults to None.</p> <code>None</code> <code>material_masks</code> <code>Optional[Mapping[str, npt.NDArray[np.bool_]]]</code> <p>A map between material name and a boolean mask indicating which grid points are in that material. Defaults to None.</p> <code>None</code> <code>origin</code> <code>Optional[list[float]]</code> <p>The location of the origin of the scenario (in meters). Defaults to None.</p> <code>None</code> <code>sources</code> <code>Optional[list[Source]]</code> <p>The list of sources in the scenario. Defaults to None.</p> <code>None</code> <code>material_outline_upsample_factor</code> <code>Optional[int]</code> <p>The factor by which to upsample the material outline when rendering the scenario. Defaults to None.</p> <code>None</code> <code>target</code> <code>Optional[Target]</code> <p>The target in the scenario. Defaults to None.</p> <code>None</code> <code>problem</code> <code>Optional[Problem]</code> <p>The problem definition for the scenario. Defaults to None.</p> <code>None</code> <code>grid</code> <code>Optional[Grid]</code> <p>The grid for the scenario. Defaults to None.</p> <code>None</code>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.center_frequency","title":"<code>center_frequency: float</code>  <code>property</code> <code>writable</code>","text":"<p>The center frequency (in hertz) of the scenario.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.dt","title":"<code>dt: float</code>  <code>property</code>","text":"<p>The spacing (in seconds) between consecutive timesteps of the simulation.</p> <p>Only available once a simulation has been completed.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.dx","title":"<code>dx: float</code>  <code>property</code>","text":"<p>The spacing (in meters) between spatial grid points.</p> <p>Spacing is the same in each spatial direction.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.extent","title":"<code>extent: npt.NDArray[np.float_]</code>  <code>property</code>","text":"<p>The extent of the spatial grid (in meters).</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.grid","title":"<code>grid: Grid</code>  <code>property</code> <code>deletable</code> <code>writable</code>","text":"<p>The grid for the scenario.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.layer_ids","title":"<code>layer_ids: Mapping[str, int]</code>  <code>property</code>","text":"<p>A map between material names and their layer id.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.material_colors","title":"<code>material_colors: dict[str, str]</code>  <code>property</code>","text":"<p>A map between material name and material render color.</p> <p>Returns:</p> Type Description <code>dict[str, str]</code> <p>dict[str, str]: keys are material names and values are the hex color</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.material_layer_ids","title":"<code>material_layer_ids: npt.NDArray[np.int_]</code>  <code>property</code>","text":"<p>Return the layer id for each grid point in the scenario.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.material_layers","title":"<code>material_layers: list[str]</code>  <code>property</code>","text":"<p>The list of material layers in the scenario.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.materials","title":"<code>materials: Mapping[str, Struct]</code>  <code>property</code>","text":"<p>Return a map between material name and material properties.</p> <ul> <li>vp: the speed of sound (in m/s).</li> <li>rho: the mass density (in kg/m\u00b3).</li> <li>alpha: the absorption (in dB/cm).</li> <li>render_color: the color used when rendering this material in the scenario layout plot.</li> </ul>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.problem","title":"<code>problem: Problem</code>  <code>property</code> <code>deletable</code> <code>writable</code>","text":"<p>The problem definition for the scenario.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.shape","title":"<code>shape: npt.NDArray[np.int_]</code>  <code>property</code>","text":"<p>The shape of the spatial grid (in number of grid points).</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.t_max","title":"<code>t_max: float</code>  <code>property</code>","text":"<p>The maximum time (in seconds) of the simulation.</p> <p>Only available once a simulation has been completed.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.t_min","title":"<code>t_min: float</code>  <code>property</code>","text":"<p>The starting time (in seconds) of the simulation.</p> <p>Only available once a simulation has been completed.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.target","title":"<code>target: Target</code>  <code>property</code> <code>writable</code>","text":"<p>The target in the scenario.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.target_center","title":"<code>target_center: npt.NDArray[np.float_]</code>  <code>property</code>","text":"<p>The coordinates of the center of the target region (in meters).</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.target_radius","title":"<code>target_radius: float</code>  <code>property</code>","text":"<p>The radius of the target region (in meters).</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.compile_problem","title":"<code>compile_problem()</code>","text":"<p>Compiles the problem for the scenario.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.get_field_data","title":"<code>get_field_data(field)</code>","text":"<p>Return the array of field values across the scenario for a particular field.</p> <p>Common fields include:</p> <ul> <li>vp: the speed of sound (in m/s)</li> <li>rho: the density (in kg/m\u00b3)</li> <li>alpha: absorption (in dB/cm)</li> </ul> <p>Parameters:</p> Name Type Description Default <code>field</code> <code>str</code> <p>the name of the field to return.</p> required <p>Returns:</p> Type Description <code>npt.NDArray[np.float_]</code> <p>An array containing the field data.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario.simulate_steady_state","title":"<code>simulate_steady_state(points_per_period=24, n_cycles_steady_state=10, time_to_steady_state=None, recording_time_undersampling=4, n_jobs=None)</code>","text":"<p>Execute a steady-state simulation.</p> <p>In this simulation, the sources will emit pressure waves with a continuous waveform until steady-state has been reached. The steady-state wave amplitude is found by taking the Fourier transform of the last <code>n_cycles_steady_state</code> cycles of data and taking the amplitude of the component at the <code>center_frequency</code>.</p> <p>Warning</p> <p>A poor choice of arguments to this function can lead to a failed simulation. Make sure you understand the impact of supplying parameter values other than the default if you chose to do so.</p> <p>Parameters:</p> Name Type Description Default <code>points_per_period</code> <code>int</code> <p>the number of points in time to simulate for each cycle of the wave.</p> <code>24</code> <code>n_cycles_steady_state</code> <code>int</code> <p>the number of complete cycles to use when calculating the steady-state wave amplitudes.</p> <code>10</code> <code>time_to_steady_state</code> <code>float | None</code> <p>the amount of time (in seconds) the simulation should run before measuring the steady-state amplitude. If the value is None, this time will automatically be set to the amount of time it would take to propagate from one corner to the opposite and back in the medium with the slowest speed of sound in the scenario.</p> <code>None</code> <code>recording_time_undersampling</code> <code>int</code> <p>the undersampling factor to apply to the time axis when recording simulation results. One out of every this many consecutive time points will be recorded and all others will be dropped.</p> <code>4</code> <code>n_jobs</code> <code>int | None</code> <p>the number of threads to be used for the computation. Use None to leverage Devito automatic tuning.</p> <code>None</code> <p>Returns:</p> Type Description <code>results.SteadyStateResult</code> <p>An object containing the result of the steady-state simulation.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios.Scenario2D","title":"<code>neurotechdevkit.scenarios.Scenario2D</code>","text":"<p>         Bases: <code>Scenario</code></p> <p>A 2D scenario.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario2D.get_target_mask","title":"<code>get_target_mask()</code>","text":"<p>Return the mask for the target region.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario2D.render_layout","title":"<code>render_layout(show_sources=True, show_target=True, show_material_outlines=False)</code>","text":"<p>Create a matplotlib figure showing the 2D scenario layout.</p> <p>The grid can be turned on via: <code>plt.grid(True)</code></p> <p>Parameters:</p> Name Type Description Default <code>show_sources</code> <code>bool</code> <p>whether or not to show the source transducer layer.</p> <code>True</code> <code>show_target</code> <code>bool</code> <p>whether or not to show the target layer.</p> <code>True</code> <code>show_material_outlines</code> <code>bool</code> <p>whether or not to display a thin white outline of the transition between different materials.</p> <code>False</code>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario2D.simulate_pulse","title":"<code>simulate_pulse(points_per_period=24, simulation_time=None, recording_time_undersampling=4, n_jobs=None)</code>","text":"<p>Execute a pulsed simulation in 2D.</p> <p>In this simulation, the sources will emit a pulse containing a few cycles of oscillation and then let the pulse propagate out to all edges of the scenario.</p> <p>Warning</p> <p>A poor choice of arguments to this function can lead to a failed simulation. Make sure you understand the impact of supplying parameter values other than the default if you chose to do so.</p> <p>Parameters:</p> Name Type Description Default <code>points_per_period</code> <code>int</code> <p>the number of points in time to simulate for each cycle of the wave.</p> <code>24</code> <code>simulation_time</code> <code>float | None</code> <p>the amount of time (in seconds) the simulation should run. If the value is None, this time will automatically be set to the amount of time it would take to propagate from one corner to the opposite in the medium with the slowest speed of sound in the scenario.</p> <code>None</code> <code>recording_time_undersampling</code> <code>int</code> <p>the undersampling factor to apply to the time axis when recording simulation results. One out of every this many consecutive time points will be recorded and all others will be dropped.</p> <code>4</code> <code>n_jobs</code> <code>int | None</code> <p>the number of threads to be used for the computation. Use None to leverage Devito automatic tuning.</p> <code>None</code> <p>Returns:</p> Type Description <code>results.PulsedResult2D</code> <p>An object containing the result of the 2D pulsed simulation.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios.Scenario3D","title":"<code>neurotechdevkit.scenarios.Scenario3D(center_frequency=None, material_properties=None, material_masks=None, origin=None, sources=None, material_outline_upsample_factor=None, target=None, problem=None, grid=None, slice_axis=None, slice_position=None, viewer_config_3d=None)</code>","text":"<p>         Bases: <code>Scenario</code></p> <p>A 3D scenario.</p> <p>All arguments are optional and can be set after initialization.</p> <p>Parameters:</p> Name Type Description Default <code>center_frequency</code> <code>Optional[float]</code> <p>The center frequency (in hertz) of the scenario. Defaults to None.</p> <code>None</code> <code>material_properties</code> <code>Optional[dict[str, Material]]</code> <p>A map between material name and material properties. Defaults to None.</p> <code>None</code> <code>material_masks</code> <code>Optional[Mapping[str, npt.NDArray[np.bool_]]]</code> <p>A map between material name and a boolean mask indicating which grid points are in that material. Defaults to None.</p> <code>None</code> <code>origin</code> <code>Optional[list[float]]</code> <p>The location of the origin of the scenario (in meters). Defaults to None.</p> <code>None</code> <code>sources</code> <code>Optional[list[Source]]</code> <p>The list of sources in the scenario. Defaults to None.</p> <code>None</code> <code>material_outline_upsample_factor</code> <code>Optional[int]</code> <p>The factor by which to upsample the material outline when rendering the scenario. Defaults to None.</p> <code>None</code> <code>target</code> <code>Optional[Target]</code> <p>The target in the scenario. Defaults to None.</p> <code>None</code> <code>problem</code> <code>Optional[Problem]</code> <p>The problem definition for the scenario. Defaults to None.</p> <code>None</code> <code>grid</code> <code>Optional[Grid]</code> <p>The grid for the scenario. Defaults to None.</p> <code>None</code> <code>slice_axis</code> <code>Optional[SliceAxis]</code> <p>The axis along which to slice the 3D field to be recorded. If None, then the complete field will be recorded. Use 0 for X axis, 1 for Y axis and 2 for Z axis. Defaults to None.</p> <code>None</code> <code>slice_position</code> <code>Optional[float]</code> <p>The position (in meters) along the slice axis at which the slice of the 3D field should be made. Defaults to None.</p> <code>None</code> <code>viewer_config_3d</code> <code>Optional[rendering.ViewerConfig3D]</code> <p>The configuration to use when rendering the 3D scenario. Defaults to None.</p> <code>None</code>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario3D.get_target_mask","title":"<code>get_target_mask()</code>","text":"<p>Return the mask for the target region.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario3D.render_layout","title":"<code>render_layout(show_sources=True, show_target=True, show_material_outlines=False)</code>","text":"<p>Create a matplotlib figure showing a 2D slice of the scenario layout.</p> <p>In order to visualize the 3D scenario in a 2D plot, a slice through the scenario needs to be specified via <code>slice_axis</code> and <code>slice_position</code>. Eg. to take a slice at z=0.01 m, use <code>slice_axis=2</code> and <code>slice_position=0.01</code>.</p> <p>The grid can be turned on via: <code>plt.grid(True)</code></p> <p>Parameters:</p> Name Type Description Default <code>show_sources</code> <code>bool</code> <p>whether or not to show the source transducer layer.</p> <code>True</code> <code>show_target</code> <code>bool</code> <p>whether or not to show the target layer.</p> <code>True</code> <code>show_material_outlines</code> <code>bool</code> <p>whether or not to display a thin white outline of the transition between different materials.</p> <code>False</code>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario3D.render_layout_3d","title":"<code>render_layout_3d()</code>","text":"<p>Render the scenario layout in 3D using napari.</p> <p>This function requires the napari package to be installed.</p> <p>Warning</p> <p>Integration with napari is experimental, so do not be surprised if you encounter issues calling this function.</p> <p>This will open up the napari interactive GUI in a separate window. The GUI contains many different controls for controlling the view of the data as well as the rendering of the layers. Among these, you can drag the scenario to view it from different angles, zoom in our out, and turn layers on or off.</p> <p>See napari documentation for more information on the GUI: documentation</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios._base.Scenario3D.simulate_pulse","title":"<code>simulate_pulse(points_per_period=24, simulation_time=None, recording_time_undersampling=4, n_jobs=None, slice_axis=None, slice_position=None)</code>","text":"<p>Execute a pulsed simulation in 3D.</p> <p>In this simulation, the sources will emit a pulse containing a few cycles of oscillation and then let the pulse propagate out to all edges of the scenario.</p> <p>Warning</p> <p>A poor choice of arguments to this function can lead to a failed simulation. Make sure you understand the impact of supplying parameter values other than the default if you chose to do so.</p> <p>Parameters:</p> Name Type Description Default <code>points_per_period</code> <code>int</code> <p>the number of points in time to simulate for each cycle of the wave.</p> <code>24</code> <code>simulation_time</code> <code>float | None</code> <p>the amount of time (in seconds) the simulation should run. If the value is None, this time will automatically be set to the amount of time it would take to propagate from one corner to the opposite in the medium with the slowest speed of sound in the scenario.</p> <code>None</code> <code>recording_time_undersampling</code> <code>int</code> <p>the undersampling factor to apply to the time axis when recording simulation results. One out of every this many consecutive time points will be recorded and all others will be dropped.</p> <code>4</code> <code>n_jobs</code> <code>int | None</code> <p>the number of threads to be used for the computation. Use None to leverage Devito automatic tuning.</p> <code>None</code> <code>slice_axis</code> <code>int | None</code> <p>the axis along which to slice the 3D field to be recorded. If None, then the complete field will be recorded. Use 0 for X axis, 1 for Y axis and 2 for Z axis. Only valid if <code>slice_position</code> is not None.</p> <code>None</code> <code>slice_position</code> <code>float | None</code> <p>the position (in meters) along the slice axis at which the slice of the 3D field should be made. Only valid if <code>slice_axis</code> is not None.</p> <code>None</code> <p>Returns:</p> Type Description <code>results.PulsedResult3D</code> <p>An object containing the result of the 3D pulsed simulation.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios.built_in.Scenario0","title":"<code>neurotechdevkit.scenarios.built_in.Scenario0</code>","text":"<p>         Bases: <code>Scenario2D</code></p> <p>Scenario 0.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios.built_in._scenario_0.Scenario0.make_grid","title":"<code>make_grid()</code>","text":"<p>Make the grid for scenario 0.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios.built_in.Scenario1_2D","title":"<code>neurotechdevkit.scenarios.built_in.Scenario1_2D</code>","text":"<p>         Bases: <code>Scenario1</code>, <code>Scenario2D</code></p> <p>A 2D implementation of scenario 1.</p> Scenario 1 is based on benchmark 4 of the following paper <p>Jean-Francois Aubry, Oscar Bates, Christian Boehm, et al., \"Benchmark problems for transcranial ultrasound simulation: Intercomparison of compressional wave models\", The Journal of the Acoustical Society of America 152, 1003 (2022); doi: 10.1121/10.0013426 https://asa.scitation.org/doi/pdf/10.1121/10.0013426</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios.built_in._scenario_1.Scenario1_2D.make_grid","title":"<code>make_grid()</code>","text":"<p>Make the grid for scenario 1 2D.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios.built_in.Scenario1_3D","title":"<code>neurotechdevkit.scenarios.built_in.Scenario1_3D</code>","text":"<p>         Bases: <code>Scenario1</code>, <code>Scenario3D</code></p> <p>A 3D implementation of scenario 1.</p> Scenario 1 is based on benchmark 4 of the following paper <p>Jean-Francois Aubry, Oscar Bates, Christian Boehm, et al., \"Benchmark problems for transcranial ultrasound simulation: Intercomparison of compressional wave models\", The Journal of the Acoustical Society of America 152, 1003 (2022); doi: 10.1121/10.0013426 https://asa.scitation.org/doi/pdf/10.1121/10.0013426</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios.built_in._scenario_1.Scenario1_3D.make_grid","title":"<code>make_grid()</code>","text":"<p>Make the grid for scenario 1 3D.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios.built_in.Scenario2_2D","title":"<code>neurotechdevkit.scenarios.built_in.Scenario2_2D</code>","text":"<p>         Bases: <code>Scenario2D</code>, <code>Scenario2</code></p> <p>A 2D implementation of scenario 2.</p> Scenario 2 is based on benchmark 8 of the following paper <p>Jean-Francois Aubry, Oscar Bates, Christian Boehm, et al., \"Benchmark problems for transcranial ultrasound simulation: Intercomparison of compressional wave models\", The Journal of the Acoustical Society of America 152, 1003 (2022); doi: 10.1121/10.0013426 https://asa.scitation.org/doi/pdf/10.1121/10.0013426</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios.built_in._scenario_2.Scenario2_2D.make_grid","title":"<code>make_grid()</code>","text":"<p>Make the grid for scenario 2 2D.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios.built_in.Scenario2_3D","title":"<code>neurotechdevkit.scenarios.built_in.Scenario2_3D</code>","text":"<p>         Bases: <code>Scenario2</code>, <code>Scenario3D</code></p> <p>A 3D implementation of scenario 2.</p> Scenario 2 is based on benchmark 8 of the following paper <p>Jean-Francois Aubry, Oscar Bates, Christian Boehm, et al., \"Benchmark problems for transcranial ultrasound simulation: Intercomparison of compressional wave models\", The Journal of the Acoustical Society of America 152, 1003 (2022); doi: 10.1121/10.0013426 https://asa.scitation.org/doi/pdf/10.1121/10.0013426</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios.built_in._scenario_2.Scenario2_3D.make_grid","title":"<code>make_grid()</code>","text":"<p>Make the grid for scenario 2 3D.</p>"},{"location":"api/scenarios/#neurotechdevkit.scenarios.Target","title":"<code>neurotechdevkit.scenarios.Target</code>  <code>dataclass</code>","text":"<p>A class for containing metadata for a target.</p> <p>Attributes:</p> Name Type Description <code>target_id</code> <code>str</code> <p>the string id of the target.</p> <code>center</code> <code>list[float]</code> <p>the location of the center of the target (in meters).</p> <code>radius</code> <code>float</code> <p>the radius of the target (in meters).</p> <code>description</code> <code>str</code> <p>a text describing the target.</p>"},{"location":"api/sources/","title":"Sources","text":""},{"location":"api/sources/#neurotechdevkit.sources.FocusedSource2D","title":"<code>FocusedSource2D</code>","text":"<p>         Bases: <code>Source</code></p> <p>A focused source in 2D.</p> <p>This source is shaped like an arc and has a circular focus. It is created by taking an arc of a circle and distributing point sources evenly along that arc.</p> <p>See Circular arc for relevant geometrical calculations.</p>"},{"location":"api/sources/#neurotechdevkit.sources.FocusedSource2D.calculate_waveform_scale","title":"<code>calculate_waveform_scale(dx)</code>","text":"<p>Calculate the scale factor to apply to waveforms from this source.</p> <p>The scale is equal to the ratio between the density of grid points along a line and the density of source points along the arc.</p> <p>Parameters:</p> Name Type Description Default <code>dx</code> <code>float</code> <p>the separation between gridpoints (in meters). Assumed to be the same in both directions.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The scale factor to apply to the waveform.</p>"},{"location":"api/sources/#neurotechdevkit.sources.FocusedSource3D","title":"<code>FocusedSource3D</code>","text":"<p>         Bases: <code>Source</code></p> <p>A focused source in 3D.</p> <p>This source is shaped like a bowl and has a spherical focus. It is created by taking a section of a spherical shell and distributing source points over the surface. Points are distributed according to Fibonacci spirals.</p> <p>See Spherical cap for relevant geometrical calculations.</p>"},{"location":"api/sources/#neurotechdevkit.sources.FocusedSource3D.calculate_waveform_scale","title":"<code>calculate_waveform_scale(dx)</code>","text":"<p>Calculate the scale factor to apply to waveforms from this source.</p> <p>The scale is equal to the ratio between the density of grid points in a plane and the density of source points along the bowl surface.</p> <p>Parameters:</p> Name Type Description Default <code>dx</code> <code>float</code> <p>the separation between gridpoints (in meters). Assumed to be the same in all 3 directions.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The scale factor to apply to the waveform.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource","title":"<code>PhasedArraySource(*, position, direction, num_points, num_elements, pitch, element_width, tilt_angle=0.0, focal_length=np.inf, delay=0.0, element_delays=None)</code>","text":"<p>         Bases: <code>Source</code></p> <p>A base class for phased array sources.</p> <p>Parameters:</p> Name Type Description Default <code>position</code> <code>list[float]</code> <p>a float array indicating the coordinates (in meters) of the point at the center of the source, which is the point that bisects the line segment source.</p> required <code>direction</code> <code>list[float]</code> <p>a float array representing a vector located at position that is perpendicular to the plane of the source. Only the orientation of <code>direction</code> affects the source, the length of the vector has no affect. See the <code>unit_direction</code> property.</p> required <code>num_points</code> <code>int</code> <p>the number of point sources to use when simulating the source.</p> required <code>num_elements</code> <code>int</code> <p>the number of elements of the phased array.</p> required <code>pitch</code> <code>float</code> <p>the distance (in meters) between the centers of neighboring elements in the phased array.</p> required <code>element_width</code> <code>float</code> <p>the width (in meters) of each individual element of the array.</p> required <code>tilt_angle</code> <code>float</code> <p>the desired tilt angle (in degrees) of the wavefront. The angle is measured between the direction the wavefront travels and the normal to the surface of the transducer, with positive angles resulting in a counter-clockwise tilt away from the normal.</p> <code>0.0</code> <code>focal_length</code> <code>float</code> <p>the distance (in meters) from <code>position</code> to the focal point.</p> <code>np.inf</code> <code>delay</code> <code>float</code> <p>the delay (in seconds) that the source will wait before emitting.</p> <code>0.0</code> <code>element_delays</code> <code>npt.NDArray[np.float_] | None</code> <p>an 1D array with the delays (in seconds) for each element of the phased array. Delays from <code>element_delays</code> take precedence; No other argument affected the delays (<code>tilt_angle</code>, <code>focal_length</code> or <code>delay</code>) would be considered. ValueError will be raised if provided values for either <code>tilt_angle</code>, <code>focal_length</code> or <code>delay</code> are non-default.</p> <code>None</code>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource.aperture","title":"<code>aperture: float</code>  <code>property</code>","text":"<p>The width (in meters) of the source.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource.element_delays","title":"<code>element_delays: npt.NDArray[np.float_]</code>  <code>property</code>","text":"<p>The delay (in seconds) that each element should wait before emitting.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource.element_positions","title":"<code>element_positions: npt.NDArray[np.float_]</code>  <code>property</code>","text":"<p>An array with the position of the center of each element of the array.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource.element_width","title":"<code>element_width: float</code>  <code>property</code>","text":"<p>The width (in meters) of each element of the array.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource.num_elements","title":"<code>num_elements: int</code>  <code>property</code>","text":"<p>The number of elements in the source array.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource.pitch","title":"<code>pitch: float</code>  <code>property</code>","text":"<p>The <code>pitch</code> (in meters) of the source.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource.point_mapping","title":"<code>point_mapping: tuple[slice, ...]</code>  <code>property</code>","text":"<p>A tuple with the slices of source point indexes comprising each element.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource.point_source_delays","title":"<code>point_source_delays: npt.NDArray[np.float_]</code>  <code>property</code>","text":"<p>The delay before emitting (in seconds) for each point source.</p> <p>The delays are computed at the element level. All source points within an element will have the same delay.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource.spacing","title":"<code>spacing: float</code>  <code>property</code>","text":"<p>The separation (in meters) between elements of the array.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource.tilt_angle","title":"<code>tilt_angle: float</code>  <code>property</code>","text":"<p>The angle (in degrees) that the wave front is tilted.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource.focal_point","title":"<code>focal_point()</code>","text":"<p>Get or set the coordinates (in meters) of the focal point of the source.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource.txdelay","title":"<code>txdelay(tilt_angle, pitch, speed=1500)</code>  <code>staticmethod</code>","text":"<p>Compute the delay (in seconds) required to tilt the wavefront.</p> <p>The delays from element n to element n+1 to achieve a wavefront with <code>tilt_angle</code> respect to the normal. Positive angles lead to counter-clockwise rotations.</p> <p>Parameters:</p> Name Type Description Default <code>tilt_angle</code> <code>float</code> <p>angle (in degrees) between the vector normal to the source         and the wavefront.</p> required <code>pitch</code> <code>float</code> <p>the pitch (in meters) of the source.</p> required <code>speed</code> <code>float</code> <p>the speed of sound (in meters/second) of the material where    the source is placed.</p> <code>1500</code> <p>Returns:</p> Type Description <code>float</code> <p>The delay (in seconds) between two consecutive elements.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource2D","title":"<code>PhasedArraySource2D</code>","text":"<p>         Bases: <code>PhasedArraySource</code></p> <p>A phased array source in 2D.</p> <p>This source is shaped like multiple segments in a line. Each segment can emit waves independently. It has no focus currently. A focused implementation will be supported in the future. This source is composed of <code>num_points</code> point sources. Distributed evenly in <code>num_elements</code>.</p> <p>If the number of points can not be evenly distributed in the number of elements, the remainder number of points from the even division will be discarded.</p> <p>See Phased array ultras... for detailed explanation.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource2D.focal_point","title":"<code>focal_point: npt.NDArray[np.float_]</code>  <code>property</code>","text":"<p>The coordinates (in meters) of the point where the array focuses.</p> <p>If the array is unfocused it will return the focal point (inf, inf).</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource2D.calculate_waveform_scale","title":"<code>calculate_waveform_scale(dx)</code>","text":"<p>Calculate the scale factor to apply to waveforms from this source.</p> <p>The scale is equal to the ratio between the density of grid points along a line and the density of source points along the line segment source.</p> <p>Parameters:</p> Name Type Description Default <code>dx</code> <code>float</code> <p>the separation between gridpoints (in meters). Assumed to be the same in both directions.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The scale factor to apply to the waveform.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource3D","title":"<code>PhasedArraySource3D(*, position, direction, center_line, num_points, num_elements, pitch, height, element_width, tilt_angle=0.0, focal_length=np.inf, delay=0.0, element_delays=None)</code>","text":"<p>         Bases: <code>PhasedArraySource</code></p> <p>A linear phased array source in 3D.</p> <p>This source is shaped like multiple rectangular segments in a line. Each segment can emit waves independently. It has no focus currently. A focused implementation will be supported in the future. This source is composed of <code>num_points</code> point sources distributed evenly in <code>num_elements</code>.</p> <p>If the number of points can not be evenly distributed in the number of elements, the remainder number of points from the even division will be discarded.</p> <p>See Phased array ultras... for detailed explanation.</p> <p>Parameters:</p> Name Type Description Default <code>position</code> <code>list[float]</code> <p>a float array in 3D indicating the coordinates (in meters) of the point at the center of the source, which is the point that bisects both the height and the aperture of the source.</p> required <code>direction</code> <code>list[float]</code> <p>a float array in 3D representing a vector located at position that is perpendicular to the plane of the source. Only the orientation of <code>direction</code> affects the source, the length of the vector has no affect. See the <code>unit_direction</code> property.</p> required <code>center_line</code> <code>npt.NDArray[np.float_]</code> <p>A 3D vector which is parallel to the line through the centers of the elements in the linear array. This vector must be perpendicular to <code>direction</code>. If the vector is not perpendicular, only the perpendicular component will be considered. Only the orientation affects the source, the length of the vector has no effect. See <code>unit_center_line</code> property.</p> required <code>num_points</code> <code>int</code> <p>the number of point sources to use when simulating the source. If the number of points is not divisible evenly by the number of elements, the number of points would be truncated to a multiple of the maximum even divisor.</p> required <code>num_elements</code> <code>int</code> <p>the number of elements of the phased array.</p> required <code>pitch</code> <code>float</code> <p>the distance (in meters) between the centers of neighboring elements in the phased array.</p> required <code>height</code> <code>float</code> <p>the height (in meters) of the elements of the array. <code>height</code> is measured along the direction in the plane of the element that is perpendicular to <code>center_line</code>.</p> required <code>element_width</code> <code>float</code> <p>the width (in meters) of each individual element of the array.</p> required <code>tilt_angle</code> <code>float</code> <p>the desired tilt angle (in degrees) of the wavefront. The angle is measured between the direction the wavefront travels and the normal to the surface of the transducer, with positive angles resulting in a counter-clockwise tilt away from the normal.</p> <code>0.0</code> <code>focal_length</code> <code>float</code> <p>the distance (in meters) from <code>position</code> to the focal point.</p> <code>np.inf</code> <code>delay</code> <code>float</code> <p>the delay (in seconds) that the source will wait before emitting.</p> <code>0.0</code> <code>element_delays</code> <code>npt.NDArray[np.float_] | None</code> <p>an 1D array with the delays (in seconds) for each element of the phased array. Delays from <code>element_delays</code> take precedence; No other argument affected the delays (<code>tilt_angle</code>, <code>focal_length</code> or <code>delay</code>) would be considered. ValueError will be raised if provided values for either <code>tilt_angle</code>, <code>focal_length</code> or <code>delay</code> are non-default.</p> <code>None</code>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource3D.focal_point","title":"<code>focal_point: npt.NDArray[np.float_]</code>  <code>property</code>","text":"<p>The coordinates (in meters) of the point where the array focuses.</p> <p>If the array is unfocused it will return the focal point (inf, inf, inf).</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource3D.height","title":"<code>height: float</code>  <code>property</code>","text":"<p>The <code>height</code> (in meters) of the elements of the source.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource3D.unit_center_line","title":"<code>unit_center_line: npt.NDArray[np.float_]</code>  <code>property</code>","text":"<p>The unit direction of the line crossing the center of the array elements.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PhasedArraySource3D.calculate_waveform_scale","title":"<code>calculate_waveform_scale(dx)</code>","text":"<p>Calculate the scale factor to apply to waveforms from this source.</p> <p>The scale is equal to the ratio between the density of grid points along a plane and the density of source points along the planar source.</p> <p>Parameters:</p> Name Type Description Default <code>dx</code> <code>float</code> <p>the separation between gridpoints (in meters). Assumed to be the same in both directions.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The scale factor to apply to the waveform.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PlanarSource2D","title":"<code>PlanarSource2D</code>","text":"<p>         Bases: <code>UnfocusedSource</code></p> <p>A planar source in 2D.</p> <p>This source is shaped like a line segment and has no focus. The source is composed of <code>num_points</code> point sources evenly distributed along the line segment.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PlanarSource2D.calculate_waveform_scale","title":"<code>calculate_waveform_scale(dx)</code>","text":"<p>Calculate the scale factor to apply to waveforms from this source.</p> <p>The scale is equal to the ratio between the density of grid points along a line and the density of source points along the line segment source.</p> <p>Parameters:</p> Name Type Description Default <code>dx</code> <code>float</code> <p>the separation between gridpoints (in meters). Assumed to be the same in both directions.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The scale factor to apply to the waveform.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PlanarSource3D","title":"<code>PlanarSource3D</code>","text":"<p>         Bases: <code>UnfocusedSource</code></p> <p>A planar source in 3D.</p> <p>This source is shaped like a disk and has no focus. It is created by defining a disk and distributing <code>num_points</code> point sources according to Fibonacci spirals.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PlanarSource3D.calculate_waveform_scale","title":"<code>calculate_waveform_scale(dx)</code>","text":"<p>Calculate the scale factor to apply to waveforms from this source.</p> <p>The scale is equal to the ratio between the density of grid points along a plane and the density of source points along the disk source.</p> <p>Parameters:</p> Name Type Description Default <code>dx</code> <code>float</code> <p>the separation between gridpoints (in meters). Assumed to be the same in both directions.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The scale factor to apply to the waveform.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PointSource","title":"<code>PointSource(*, position, num_dim=2, delay=0.0)</code>","text":"<p>         Bases: <code>Source</code></p> <p>Theoretical point source.</p> <p>Automatically sets <code>aperture</code>, <code>focal_length</code>, and <code>direction</code>, and <code>num_points</code>.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PointSource.calculate_waveform_scale","title":"<code>calculate_waveform_scale(dx)</code>","text":"<p>Calculate the scale factor to apply to waveforms from point source.</p> <p>The scale is equal to the ratio between the density of source points and the density of grid points (2D: 1 / dx; 3D: 1 / dx2). Because the aperture is technically zero, we approximate the source density as the smallest grid (2D: 1 / dx; 3D: 1 / dx2).</p> <p>Parameters:</p> Name Type Description Default <code>dx</code> <code>float</code> <p>the separation between gridpoints (in meters). Assumed to be the same in both directions. Unused.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The scale factor to apply to the waveform.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PointSource2D","title":"<code>PointSource2D(*, position, delay=0.0)</code>","text":"<p>         Bases: <code>PointSource</code></p> <p>A point source in 2D.</p>"},{"location":"api/sources/#neurotechdevkit.sources.PointSource3D","title":"<code>PointSource3D(*, position, delay=0.0)</code>","text":"<p>         Bases: <code>PointSource</code></p> <p>A point source in 3D.</p>"},{"location":"api/sources/#neurotechdevkit.sources.Source","title":"<code>Source(*, position, direction, aperture, focal_length, num_points, delay=0.0)</code>","text":"<p>         Bases: <code>abc.ABC</code></p> <p>An abstract class that represents a generic Source object.</p> <p>Sources can be 2D or 3D, which affects the shape of arrays representing coordinates or vectors. Sources are composed of point sources evenly distributed over the appropriate source geometry.</p> <p>Parameters:</p> Name Type Description Default <code>position</code> <code>npt.ArrayLike</code> <p>a float array indicating the coordinates (in meters) of the point at the center of the source.</p> required <code>direction</code> <code>list[float]</code> <p>a float array representing a vector located at position and pointing towards the focal point. Only the orientation of <code>direction</code> affects the source, the length of the vector has no affect. See the <code>unit_direction</code> property.</p> required <code>aperture</code> <code>float</code> <p>the width (in meters) of the source.</p> required <code>focal_length</code> <code>float</code> <p>the distance (in meters) from <code>position</code> to the focal point.</p> required <code>num_points</code> <code>int</code> <p>the number of point sources to use when simulating the source.</p> required <code>delay</code> <code>float</code> <p>the delay (in seconds) that the source will wait before emitting. Defaults to 0.0.</p> <code>0.0</code>"},{"location":"api/sources/#neurotechdevkit.sources.Source.aperture","title":"<code>aperture: float</code>  <code>property</code>","text":"<p>The width (in meters) of the source.</p>"},{"location":"api/sources/#neurotechdevkit.sources.Source.coordinates","title":"<code>coordinates: npt.NDArray[np.float_]</code>  <code>property</code>","text":"<p>A 2D array containing the <code>coordinates</code> (in meters) of the source points.</p> <p>The length of this array along the first dimension is equal to <code>num_points</code>.</p>"},{"location":"api/sources/#neurotechdevkit.sources.Source.delay","title":"<code>delay: float</code>  <code>property</code>","text":"<p>The <code>delay</code> (in seconds) for the source as a whole.</p> <p><code>delay</code> should be non-negative.</p>"},{"location":"api/sources/#neurotechdevkit.sources.Source.focal_length","title":"<code>focal_length: float</code>  <code>property</code>","text":"<p>The distance (in meters) from <code>position</code> to the focal point.</p>"},{"location":"api/sources/#neurotechdevkit.sources.Source.num_points","title":"<code>num_points: int</code>  <code>property</code>","text":"<p>The number of point sources used to simulate the source.</p>"},{"location":"api/sources/#neurotechdevkit.sources.Source.point_source_delays","title":"<code>point_source_delays: npt.NDArray[np.float_]</code>  <code>property</code>","text":"<p>The delay before emitting (in seconds) for each point source.</p>"},{"location":"api/sources/#neurotechdevkit.sources.Source.position","title":"<code>position: npt.NDArray[np.float_]</code>  <code>property</code>","text":"<p>A numpy float array indicating the <code>position</code> (in meters) of the source.</p> <p>The position of the source is defined as the coordinates of the point at the center of symmetry of the source.</p>"},{"location":"api/sources/#neurotechdevkit.sources.Source.unit_direction","title":"<code>unit_direction: npt.NDArray[np.float_]</code>  <code>property</code>","text":"<p>A normalized vector indicating the orientation of the source.</p> <p>The vector is located at <code>position</code>, points towards the focal point, and has unit length. It points in the same direction as the <code>direction</code> parameter in <code>__init__</code>, except it is normalized.</p>"},{"location":"api/sources/#neurotechdevkit.sources.Source.calculate_waveform_scale","title":"<code>calculate_waveform_scale(dx)</code>  <code>abstractmethod</code>","text":"<p>Calculate the scale factor to apply to waveforms from this source.</p> <p>The scale depends on the relative density of source points vs grid points.</p> <p>This method must be implemented by all concrete Source classes.</p> <p>Parameters:</p> Name Type Description Default <code>dx</code> <code>float</code> <p>the separation (in meters) between gridpoints. Assumed to be the same in all directions.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The scale factor to apply to the waveform.</p>"},{"location":"api/sources/#neurotechdevkit.sources.UnfocusedSource","title":"<code>UnfocusedSource(*, position, direction, aperture, num_points, delay=0.0)</code>","text":"<p>         Bases: <code>Source</code>, <code>abc.ABC</code></p> <p>An abstract base class for unfocused sources.</p> <p>Automatically sets <code>focal_length</code> to <code>np.inf</code></p>"},{"location":"generated/gallery/","title":"Examples","text":""},{"location":"generated/gallery/#examples","title":"Examples","text":"<p> Plot pulsed simulation </p> <p> Custom source </p> <p> Save and load results </p> <p> Plot scenarios </p> <p> Reading simulation metrics </p> <p> Custom center frequency </p> <p> Adding multiple sources </p> <p> Visualizing 3D results with Napari </p> <p> Scenario 2 predefined target </p> <p> Phased array source </p> <p> Implementing a full scenario </p> <p> Time-reverse simulation for phased array </p> <p> Download all examples in Python source code: gallery_python.zip</p> <p> Download all examples in Jupyter notebooks: gallery_jupyter.zip</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/mg_execution_times/","title":"Computation times","text":"<p>21:03.388 total execution time for generated_gallery files:</p> <p>+-------------------------------------------------------------------------------------------------------------------------------+-----------+--------+ | plot_time_reverse (docs/examples/plot_time_reverse.py)                                              | 07:40.503 | 0.0 MB | +-------------------------------------------------------------------------------------------------------------------------------+-----------+--------+ | plot_phased_array_source (docs/examples/plot_phased_array_source.py)                         | 07:32.989 | 0.0 MB | +-------------------------------------------------------------------------------------------------------------------------------+-----------+--------+ | plot_pulsed_simulation (docs/examples/plot_pulsed_simulation.py)                               | 01:36.486 | 0.0 MB | +-------------------------------------------------------------------------------------------------------------------------------+-----------+--------+ | plot_multiple_sources (docs/examples/plot_multiple_sources.py)                                  | 01:19.810 | 0.0 MB | +-------------------------------------------------------------------------------------------------------------------------------+-----------+--------+ | plot_scenarios (docs/examples/plot_scenarios.py)                                                       | 00:52.375 | 0.0 MB | +-------------------------------------------------------------------------------------------------------------------------------+-----------+--------+ | plot_3d (docs/examples/plot_3d.py)                                                                            | 00:28.147 | 0.0 MB | +-------------------------------------------------------------------------------------------------------------------------------+-----------+--------+ | plot_full_scenario (docs/examples/plot_full_scenario.py)                                           | 00:25.369 | 0.0 MB | +-------------------------------------------------------------------------------------------------------------------------------+-----------+--------+ | plot_customized_center_frequency (docs/examples/plot_customized_center_frequency.py) | 00:16.412 | 0.0 MB | +-------------------------------------------------------------------------------------------------------------------------------+-----------+--------+ | plot_adding_custom_source (docs/examples/plot_adding_custom_source.py)                      | 00:14.691 | 0.0 MB | +-------------------------------------------------------------------------------------------------------------------------------+-----------+--------+ | plot_store_results (docs/examples/plot_store_results.py)                                           | 00:12.540 | 0.0 MB | +-------------------------------------------------------------------------------------------------------------------------------+-----------+--------+ | plot_metrics (docs/examples/plot_metrics.py)                                                             | 00:12.154 | 0.0 MB | +-------------------------------------------------------------------------------------------------------------------------------+-----------+--------+ | plot_scenario2_predefined_target (docs/examples/plot_scenario2_predefined_target.py) | 00:11.910 | 0.0 MB | +-------------------------------------------------------------------------------------------------------------------------------+-----------+--------+</p>"},{"location":"generated/gallery/plot_3d/","title":"Visualizing 3D results with Napari","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/gallery/plot_3d/#visualizing-3d-results-with-napari","title":"Visualizing 3D results with Napari","text":"<p>This example demonstrates how to render a steady state result for a 3D scenario using napari.</p> <p>Running such simulations is computationally expensive and can take a long time to complete. For this reason, we recommend running this simulation on an external machine, store the results in a file and then load them on your local machine for visualization.</p> <p>Check the gallery example Save and load results to learn how to save and load results.</p> <p>The following step downloads and loads a simulation executed on an external machine.</p> <pre><code>import pooch\nimport neurotechdevkit as ndk\nURL = \"https://neurotechdevkit.s3.us-west-2.amazonaws.com/result-scenario-2-3d-v4.tz\"\nknown_hash = \"919edd0f29bcc956a9c2b3c4c56c28af5495dcdbb93d2d4d7f89078827e6db59\"\ndownloaded_file_path = pooch.retrieve(url=URL, known_hash=known_hash, progressbar=True)\nresult = ndk.load_result_from_disk(downloaded_file_path)\n</code></pre> <p>Out:</p> <pre><code>  0%|                                               | 0.00/451M [00:00&lt;?, ?B/s]\n0%|                                       | 56.3k/451M [00:00&lt;16:59, 443kB/s]\n0%|                                       | 248k/451M [00:00&lt;07:03, 1.06MB/s]\n0%|                                      | 1.12M/451M [00:00&lt;02:02, 3.69MB/s]\n1%|\u258e                                     | 3.73M/451M [00:00&lt;00:43, 10.3MB/s]\n1%|\u258c                                     | 6.41M/451M [00:00&lt;00:31, 14.1MB/s]\n2%|\u258a                                     | 9.12M/451M [00:00&lt;00:26, 16.5MB/s]\n3%|\u2589                                     | 11.9M/451M [00:00&lt;00:24, 18.1MB/s]\n3%|\u2588\u258f                                    | 14.6M/451M [00:01&lt;00:21, 20.1MB/s]\n4%|\u2588\u258d                                    | 17.1M/451M [00:01&lt;00:20, 21.4MB/s]\n4%|\u2588\u258b                                    | 19.3M/451M [00:01&lt;00:20, 20.8MB/s]\n5%|\u2588\u258a                                    | 22.0M/451M [00:01&lt;00:20, 21.4MB/s]\n6%|\u2588\u2588                                    | 25.2M/451M [00:01&lt;00:19, 22.4MB/s]\n6%|\u2588\u2588\u258d                                   | 28.3M/451M [00:01&lt;00:18, 23.1MB/s]\n7%|\u2588\u2588\u258b                                   | 31.5M/451M [00:01&lt;00:17, 23.6MB/s]\n8%|\u2588\u2588\u2589                                   | 34.6M/451M [00:01&lt;00:17, 23.9MB/s]\n8%|\u2588\u2588\u2588\u258f                                  | 37.8M/451M [00:01&lt;00:17, 24.1MB/s]\n9%|\u2588\u2588\u2588\u258d                                  | 40.9M/451M [00:02&lt;00:16, 24.2MB/s]\n10%|\u2588\u2588\u2588\u258b                                  | 44.1M/451M [00:02&lt;00:16, 25.0MB/s]\n10%|\u2588\u2588\u2588\u2589                                  | 47.0M/451M [00:02&lt;00:15, 26.0MB/s]\n11%|\u2588\u2588\u2588\u2588\u258f                                 | 49.6M/451M [00:02&lt;00:16, 24.9MB/s]\n12%|\u2588\u2588\u2588\u2588\u258d                                 | 52.1M/451M [00:02&lt;00:16, 23.6MB/s]\n12%|\u2588\u2588\u2588\u2588\u258b                                 | 55.1M/451M [00:02&lt;00:16, 24.6MB/s]\n13%|\u2588\u2588\u2588\u2588\u2589                                 | 58.1M/451M [00:02&lt;00:15, 25.9MB/s]\n13%|\u2588\u2588\u2588\u2588\u2588                                 | 60.7M/451M [00:02&lt;00:15, 25.0MB/s]\n14%|\u2588\u2588\u2588\u2588\u2588\u258e                                | 63.3M/451M [00:03&lt;00:16, 24.1MB/s]\n15%|\u2588\u2588\u2588\u2588\u2588\u258c                                | 66.4M/451M [00:03&lt;00:14, 25.6MB/s]\n15%|\u2588\u2588\u2588\u2588\u2588\u258a                                | 69.0M/451M [00:03&lt;00:15, 25.4MB/s]\n16%|\u2588\u2588\u2588\u2588\u2588\u2588                                | 71.5M/451M [00:03&lt;00:15, 24.4MB/s]\n17%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e                               | 74.6M/451M [00:03&lt;00:14, 26.0MB/s]\n17%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c                               | 77.2M/451M [00:03&lt;00:14, 26.1MB/s]\n18%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b                               | 79.8M/451M [00:03&lt;00:14, 24.9MB/s]\n18%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589                               | 83.0M/451M [00:03&lt;00:13, 26.4MB/s]\n19%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                              | 85.6M/451M [00:03&lt;00:13, 26.4MB/s]\n20%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                              | 88.3M/451M [00:03&lt;00:14, 25.4MB/s]\n20%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                              | 91.5M/451M [00:04&lt;00:13, 26.9MB/s]\n21%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                              | 94.2M/451M [00:04&lt;00:13, 26.8MB/s]\n21%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                             | 96.9M/451M [00:04&lt;00:13, 25.8MB/s]\n22%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                              | 100M/451M [00:04&lt;00:12, 27.3MB/s]\n23%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                              | 103M/451M [00:04&lt;00:12, 27.1MB/s]\n23%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                             | 106M/451M [00:04&lt;00:13, 26.4MB/s]\n24%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                             | 109M/451M [00:04&lt;00:12, 28.0MB/s]\n25%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                             | 112M/451M [00:04&lt;00:12, 27.2MB/s]\n25%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                             | 114M/451M [00:04&lt;00:12, 27.1MB/s]\n26%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                             | 117M/451M [00:05&lt;00:12, 27.1MB/s]\n27%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                            | 120M/451M [00:05&lt;00:12, 26.8MB/s]\n27%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                            | 123M/451M [00:05&lt;00:11, 27.9MB/s]\n28%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                            | 126M/451M [00:05&lt;00:11, 27.4MB/s]\n28%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                            | 129M/451M [00:05&lt;00:11, 27.6MB/s]\n29%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                           | 131M/451M [00:05&lt;00:11, 27.9MB/s]\n30%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                           | 134M/451M [00:05&lt;00:11, 27.3MB/s]\n30%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                           | 137M/451M [00:05&lt;00:10, 28.6MB/s]\n31%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                           | 140M/451M [00:05&lt;00:11, 28.1MB/s]\n32%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                          | 143M/451M [00:05&lt;00:10, 28.1MB/s]\n32%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                          | 146M/451M [00:06&lt;00:10, 28.7MB/s]\n33%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                          | 149M/451M [00:06&lt;00:10, 27.7MB/s]\n34%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                         | 152M/451M [00:06&lt;00:10, 28.5MB/s]\n34%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                         | 155M/451M [00:06&lt;00:10, 28.4MB/s]\n35%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                         | 158M/451M [00:06&lt;00:10, 28.4MB/s]\n36%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                         | 161M/451M [00:06&lt;00:10, 28.8MB/s]\n36%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                        | 164M/451M [00:06&lt;00:10, 28.5MB/s]\n37%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                        | 167M/451M [00:06&lt;00:09, 29.2MB/s]\n38%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                        | 170M/451M [00:06&lt;00:09, 28.6MB/s]\n38%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                        | 173M/451M [00:06&lt;00:09, 28.9MB/s]\n39%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                       | 176M/451M [00:07&lt;00:09, 29.2MB/s]\n40%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                       | 178M/451M [00:07&lt;00:09, 28.9MB/s]\n40%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                       | 182M/451M [00:07&lt;00:09, 29.6MB/s]\n41%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                       | 185M/451M [00:07&lt;00:09, 28.7MB/s]\n42%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                      | 188M/451M [00:07&lt;00:09, 28.9MB/s]\n42%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                      | 191M/451M [00:07&lt;00:08, 29.4MB/s]\n43%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                      | 194M/451M [00:07&lt;00:09, 28.6MB/s]\n44%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                      | 197M/451M [00:07&lt;00:08, 29.3MB/s]\n44%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                     | 200M/451M [00:07&lt;00:08, 29.2MB/s]\n45%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                     | 203M/451M [00:08&lt;00:08, 29.3MB/s]\n46%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                     | 206M/451M [00:08&lt;00:08, 29.5MB/s]\n46%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                     | 209M/451M [00:08&lt;00:08, 29.0MB/s]\n47%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                    | 212M/451M [00:08&lt;00:08, 29.4MB/s]\n48%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                    | 215M/451M [00:08&lt;00:08, 29.2MB/s]\n48%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                    | 218M/451M [00:08&lt;00:07, 29.6MB/s]\n49%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                    | 221M/451M [00:08&lt;00:07, 30.0MB/s]\n50%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                   | 224M/451M [00:08&lt;00:07, 29.6MB/s]\n50%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                   | 227M/451M [00:08&lt;00:07, 30.2MB/s]\n51%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                   | 230M/451M [00:08&lt;00:07, 29.7MB/s]\n52%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                  | 233M/451M [00:09&lt;00:07, 30.0MB/s]\n52%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                  | 236M/451M [00:09&lt;00:07, 30.2MB/s]\n53%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                  | 239M/451M [00:09&lt;00:07, 29.9MB/s]\n54%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                  | 242M/451M [00:09&lt;00:06, 30.6MB/s]\n54%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                 | 246M/451M [00:09&lt;00:06, 29.9MB/s]\n55%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                 | 249M/451M [00:09&lt;00:06, 30.2MB/s]\n56%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                 | 252M/451M [00:09&lt;00:06, 30.5MB/s]\n56%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                 | 255M/451M [00:09&lt;00:06, 29.9MB/s]\n57%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                | 258M/451M [00:09&lt;00:06, 30.7MB/s]\n58%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                | 261M/451M [00:10&lt;00:09, 19.9MB/s]\n59%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                | 264M/451M [00:10&lt;00:08, 21.2MB/s]\n59%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                | 267M/451M [00:10&lt;00:08, 21.8MB/s]\n60%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e               | 270M/451M [00:10&lt;00:09, 19.9MB/s]\n60%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d               | 272M/451M [00:10&lt;00:09, 19.5MB/s]\n61%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b               | 274M/451M [00:10&lt;00:08, 20.2MB/s]\n61%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589               | 277M/451M [00:10&lt;00:08, 21.1MB/s]\n62%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e              | 281M/451M [00:11&lt;00:07, 23.8MB/s]\n63%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b              | 285M/451M [00:11&lt;00:06, 25.6MB/s]\n64%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589              | 288M/451M [00:11&lt;00:06, 25.7MB/s]\n65%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e             | 293M/451M [00:11&lt;00:05, 27.4MB/s]\n66%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c             | 296M/451M [00:11&lt;00:05, 30.2MB/s]\n66%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589             | 299M/451M [00:11&lt;00:05, 29.9MB/s]\n67%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f            | 303M/451M [00:11&lt;00:05, 29.0MB/s]\n68%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d            | 306M/451M [00:11&lt;00:04, 31.0MB/s]\n69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b            | 309M/451M [00:11&lt;00:04, 31.2MB/s]\n69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588            | 313M/451M [00:12&lt;00:04, 29.8MB/s]\n70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e           | 316M/451M [00:12&lt;00:04, 31.7MB/s]\n71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c           | 320M/451M [00:12&lt;00:04, 31.6MB/s]\n72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589           | 323M/451M [00:12&lt;00:04, 30.3MB/s]\n72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f          | 327M/451M [00:12&lt;00:03, 32.3MB/s]\n73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c          | 330M/451M [00:12&lt;00:03, 32.2MB/s]\n74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a          | 333M/451M [00:12&lt;00:03, 30.9MB/s]\n75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588          | 337M/451M [00:12&lt;00:03, 32.6MB/s]\n75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d         | 340M/451M [00:12&lt;00:03, 32.5MB/s]\n76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b         | 343M/451M [00:13&lt;00:03, 31.0MB/s]\n77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588         | 347M/451M [00:13&lt;00:03, 32.7MB/s]\n78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e        | 350M/451M [00:13&lt;00:03, 32.6MB/s]\n78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c        | 354M/451M [00:13&lt;00:03, 31.8MB/s]\n79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589        | 357M/451M [00:13&lt;00:02, 33.4MB/s]\n80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f       | 361M/451M [00:13&lt;00:02, 32.5MB/s]\n81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d       | 364M/451M [00:13&lt;00:02, 32.4MB/s]\n81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a       | 368M/451M [00:13&lt;00:02, 33.1MB/s]\n82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588       | 371M/451M [00:13&lt;00:02, 31.8MB/s]\n83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e      | 374M/451M [00:13&lt;00:02, 32.4MB/s]\n84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b      | 377M/451M [00:14&lt;00:02, 32.3MB/s]\n84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589      | 381M/451M [00:14&lt;00:02, 31.9MB/s]\n85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f     | 384M/451M [00:14&lt;00:02, 33.2MB/s]\n86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c     | 388M/451M [00:14&lt;00:01, 32.0MB/s]\n87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a     | 391M/451M [00:14&lt;00:01, 32.4MB/s]\n87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588     | 394M/451M [00:14&lt;00:01, 32.5MB/s]\n88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e    | 398M/451M [00:14&lt;00:01, 31.7MB/s]\n89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b    | 401M/451M [00:14&lt;00:01, 32.8MB/s]\n90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589    | 404M/451M [00:14&lt;00:01, 32.7MB/s]\n90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 408M/451M [00:14&lt;00:01, 33.1MB/s]\n91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 411M/451M [00:15&lt;00:01, 33.7MB/s]\n92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 415M/451M [00:15&lt;00:01, 32.4MB/s]\n93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 418M/451M [00:15&lt;00:00, 33.3MB/s]\n93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 422M/451M [00:15&lt;00:00, 33.1MB/s]\n94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 425M/451M [00:15&lt;00:00, 33.2MB/s]\n95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 429M/451M [00:15&lt;00:00, 34.0MB/s]\n96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 432M/451M [00:15&lt;00:00, 32.8MB/s]\n97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 436M/451M [00:15&lt;00:00, 33.6MB/s]\n97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 439M/451M [00:15&lt;00:00, 33.5MB/s]\n98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 442M/451M [00:16&lt;00:00, 33.4MB/s]\n99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 446M/451M [00:16&lt;00:00, 33.6MB/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 449M/451M [00:16&lt;00:00, 33.1MB/s]\n0%|                                               | 0.00/451M [00:00&lt;?, ?B/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 451M/451M [00:00&lt;00:00, 402GB/s]\nRecreating the scenario for the result from saved metadata...\n</code></pre> <p>In order to render the 3D results you will need to install Install <code>napari</code> via pip:</p> <pre><code>pip install \"napari[all]\"\n</code></pre> <p>Note for Mac M1 users: Qt5 does not support Mac M1, so you will need to install the Qt6 backend instead: <pre><code>pip install \"napari[pyqt6_experimental]\"\n</code></pre></p> <p>You can also follow the <code>napari</code> installation instructions: link.</p> <pre><code>try:\nimport napari  # noqa: F401\nassert isinstance(result, ndk.results.SteadyStateResult3D)\nresult.render_steady_state_amplitudes_3d()\nexcept ImportError:\nprint(\n\"napari has not been installed. Please install it with: pip install napari[all]\"\n)\n</code></pre> <p>Out:</p> <pre><code>napari has not been installed. Please install it with: pip install napari[all]\n</code></pre> <p>If you have napari installed you should see an output like the following:</p> <pre><code>Opening the napari viewer. The window might not show up on top of your notebook;\nlook through your open applications if it does not.\n</code></pre> <p>If you have napari installed you should have been able to see an image like the following: </p> <p>Total running time of the script: ( 0 minutes  28.147 seconds)</p> <p> Download Python source code: plot_3d.py</p> <p> Download Jupyter notebook: plot_3d.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/plot_adding_custom_source/","title":"Custom source","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/gallery/plot_adding_custom_source/#custom-source","title":"Custom source","text":"<p>Note</p> <p>NDK and its examples are under constant development, more information and content will be added to this example soon!</p> <p>This example demonstrates how to add a source to the simulation.</p> <p>A Source receives the following parameters:</p> <ul> <li>position <code>(npt.NDArray[np.float_])</code>: a numpy float array indicating the   coordinates (in meters) of the point at the center of the source.</li> <li>direction <code>(npt.NDArray[np.float_])</code>: a numpy float array representing a vector   located at position and pointing towards the focal point. Only the   orientation of <code>direction</code> affects the source, the length of the vector has   no affect. See the <code>unit_direction</code> property.</li> <li>aperture <code>(float)</code>: the width (in meters) of the source.</li> <li>focal_length <code>(float)</code>: the distance (in meters) from <code>position</code> to the focal   point.</li> <li>num_points <code>(int)</code>: the number of point sources to use when simulating the source.</li> <li>delay <code>(float, optional)</code>: the delay (in seconds) that the source will wait before   emitting. Defaults to 0.0.</li> </ul> <pre><code>import neurotechdevkit as ndk\nsource = ndk.sources.FocusedSource2D(\nposition=[0.00, 0.0],\ndirection=[0.9, 0.0],\naperture=0.01,\nfocal_length=0.01,\nnum_points=1000,\n)\nscenario = ndk.built_in.Scenario0()\nscenario.sources = [source]\nscenario.make_grid()\nscenario.compile_problem()\nresult = scenario.simulate_steady_state()\nassert isinstance(result, ndk.results.SteadyStateResult2D)\nresult.render_steady_state_amplitudes()\n</code></pre> <p></p> <p>Out:</p> <pre><code>Estimated time to complete simulation: 44 seconds. Memory required is 8.09906664298232 GB (available 73.624408064 GB). These values are approximated.\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\ngcc -O3 -g -fPIC -Wall -std=c99 -march=native -Wno-unused-result -Wno-unused-variable -Wno-unused-but-set-variable -ffast-math -shared -fopenmp /tmp/devito-jitcache-uid1001/4f8ef5056730ae3c7fbdc107b4e51890098e4f0b.c -lm -o /tmp/devito-jitcache-uid1001/4f8ef5056730ae3c7fbdc107b4e51890098e4f0b.so\n</code></pre> <p>Total running time of the script: ( 0 minutes  14.691 seconds)</p> <p> Download Python source code: plot_adding_custom_source.py</p> <p> Download Jupyter notebook: plot_adding_custom_source.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/plot_customized_center_frequency/","title":"Custom center frequency","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/gallery/plot_customized_center_frequency/#custom-center-frequency","title":"Custom center frequency","text":"<p>This example demonstrates how to use a customized center frequency using ndk</p> <p></p> <p>Out:</p> <pre><code>Estimated time to complete simulation: 44 seconds. Memory required is 8.10010166030443 GB (available 73.624408064 GB). These values are approximated.\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\ngcc -O3 -g -fPIC -Wall -std=c99 -march=native -Wno-unused-result -Wno-unused-variable -Wno-unused-but-set-variable -ffast-math -shared -fopenmp /tmp/devito-jitcache-uid1001/5e93aad3fe47b34cc09b102dd111206c20f0f734.c -lm -o /tmp/devito-jitcache-uid1001/5e93aad3fe47b34cc09b102dd111206c20f0f734.so\n</code></pre> <p></p> <pre><code>import neurotechdevkit as ndk\nCENTER_FREQUENCY = 6e5\nscenario = ndk.scenarios.built_in.Scenario0()\n# Customizing material properties\nscenario.material_properties = {\n\"tumor\": ndk.materials.Material(\nvp=1850.0, rho=1250.0, alpha=0.8, render_color=\"#94332F\"\n),\n}\nscenario.center_frequency = CENTER_FREQUENCY\nscenario.make_grid()\nscenario.compile_problem()\nresult = scenario.simulate_steady_state()\nassert isinstance(result, ndk.results.SteadyStateResult2D)\nresult.render_steady_state_amplitudes(show_material_outlines=False)\n</code></pre> <p>Total running time of the script: ( 0 minutes  16.412 seconds)</p> <p> Download Python source code: plot_customized_center_frequency.py</p> <p> Download Jupyter notebook: plot_customized_center_frequency.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/plot_full_scenario/","title":"Implementing a full scenario","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/gallery/plot_full_scenario/#implementing-a-full-scenario","title":"Implementing a full scenario","text":"<p>Note</p> <p>NDK and its examples are under constant development, more information and content will be added to this example soon!</p> <p>The following code is a simplified implementation of NDK's Scenario 1.</p> <p>Implementing a Scenario</p> <pre><code>import numpy as np\nfrom neurotechdevkit import sources\nfrom neurotechdevkit.grid import Grid\nfrom neurotechdevkit.problem import Problem\nfrom neurotechdevkit.results import SteadyStateResult2D\nfrom neurotechdevkit.scenarios import Scenario2D, Target\n</code></pre> <p>Creating the scenario</p> <pre><code>scenario = Scenario2D()\nscenario.center_frequency = 5e5  # Hz\nscenario.target = Target(\ntarget_id=\"target_1\", center=[0.064, 0.0], radius=0.004, description=\"\"\n)\nscenario.material_properties = {}\nscenario.origin = [0.0, -0.035]\nscenario.sources = [\nsources.FocusedSource2D(\nposition=[0.0, 0.0],\ndirection=[1.0, 0.0],\naperture=0.064,\nfocal_length=0.064,\nnum_points=1000,\n)\n]\nscenario.material_outline_upsample_factor = 8\n</code></pre> <p>Creating grid</p> <pre><code>grid = Grid.make_grid(\nextent=(0.12, 0.07),  # m\nspeed_water=1500,\ncenter_frequency=scenario.center_frequency,\nppw=6,\n)\nscenario.grid = grid\n</code></pre> <p>Creating masks</p> <pre><code>def fill_mask(mask, start, end, dx):\n# fill linearly along the x axis\nif end is None:\nn = int(start / dx)\nmask[n:] = True\nelse:\nn = int(start / dx)\nm = int(end / dx)\nmask[n:m] = True\ndef create_masks(grid):\n# layers are defined by X position\ndx = grid.space.spacing[0]\nlayers_m = np.array(\n[\n0.026,  # water\n0.004,  # skin\n0.0015,  # cortical bone\n0.004,  # trabecular bone\n0.001,  # cortical bone\n0.0835,  # brain\n]\n)\nlayers = np.array(\n[\"water\", \"skin\", \"cortical_bone\", \"trabecular_bone\", \"cortical_bone\", \"brain\"]\n)\ninterfaces = np.cumsum(layers_m)\nmask_materials = {}\nfor material in np.unique(layers):\nmask = np.zeros(grid.space.shape, dtype=bool)\nfor index in np.where(layers == material)[0]:\nstart = interfaces[index - 1] if material != \"water\" else 0\nend = interfaces[index] if material != \"brain\" else None\nfill_mask(mask, start=start, end=end, dx=dx)\nmask_materials[material] = mask\nreturn mask_materials\nscenario.material_masks = create_masks(grid)\n</code></pre> <p>Rendering the layout</p> <pre><code>scenario.render_layout()\n</code></pre> <p></p> <p>Creating problem</p> <pre><code>problem = Problem(grid=grid)\nproblem.add_material_fields(\nmaterials=scenario.materials,\nmasks=scenario.material_masks,\n)\nscenario.problem = problem\n</code></pre> <p>Rendering the simulation</p> <pre><code>result = scenario.simulate_steady_state()\nassert isinstance(result, SteadyStateResult2D)\nresult.render_steady_state_amplitudes(show_material_outlines=False)\n</code></pre> <p></p> <p>Out:</p> <pre><code>Estimated time to complete simulation: 47 seconds. Memory required is 8.110059917325207 GB (available 73.624408064 GB). These values are approximated.\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\n</code></pre> <p>Total running time of the script: ( 0 minutes  25.369 seconds)</p> <p> Download Python source code: plot_full_scenario.py</p> <p> Download Jupyter notebook: plot_full_scenario.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/plot_metrics/","title":"Reading simulation metrics","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/gallery/plot_metrics/#reading-simulation-metrics","title":"Reading simulation metrics","text":"<p>Note</p> <p>NDK and its examples are under constant development, more information and content will be added to this example soon!</p> <p>This example demonstrates how to display the metrics collected from the simulation.</p>"},{"location":"generated/gallery/plot_metrics/#rendering-scenario","title":"Rendering scenario","text":"<pre><code>import neurotechdevkit as ndk\nscenario = ndk.built_in.Scenario0()\nscenario.make_grid()\nscenario.compile_problem()\nresult = scenario.simulate_steady_state()\nassert isinstance(result, ndk.results.SteadyStateResult2D)\nresult.render_steady_state_amplitudes(show_material_outlines=False)\n</code></pre> <p>Out:</p> <pre><code>Estimated time to complete simulation: 44 seconds. Memory required is 8.09906664298232 GB (available 73.624408064 GB). These values are approximated.\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\n</code></pre>"},{"location":"generated/gallery/plot_metrics/#printing-metrics","title":"Printing metrics","text":"<pre><code>for metric, metric_value in result.metrics.items():\nprint(f\"{metric}:\")\nprint(f\"\\t {metric_value['description']}\")\nprint(\nf\"\\t Unit: {metric_value['unit-of-measurement']} Value: {metric_value['value']}\"\n)\nprint()\n</code></pre> <p>Out:</p> <pre><code>focal_gain:\n         The ratio between the mean steady-state pressure amplitude inside the target and that of the ambient, expressed in Decibels. The ambient pressure is calculated by the mean steady-state pressure amplitude inside the brain but excluding the target.\n         Unit: dB Value: 0.538355135565572\n\nI_ta_target:\n         The temporal-average intensity (ITA) within the target region. ITA is calculated by integrating the wave intensity over a full period and dividing by the period. An example FDA recommended limit for ITA is 720 mW/cm\u00b2 (the exact value can vary depending on the intended use).\n         Unit: mW/cm\u00b2 Value: 6.44781672429412e-05\n\nI_ta_off_target:\n         The temporal-average intensity (ITA) within the brain but outside of the target. ITA is calculated by integrating the wave intensity over a full period and dividing by the period. An example FDA recommended limit for ITA is 720 mW/cm\u00b2 (the exact value can vary depending on the intended use).\n         Unit: mW/cm\u00b2 Value: 6.258099451927385e-05\n\nI_pa_target:\n         The pulse-average intensity (IPA) within the target region. IPA is calculated by integrating the intensity over the pulse and dividing by the length of the pulse. For steady-state waves, IPA is equal to the temporal-average intensity. An example FDA recommended limit for IPA is 190 W/cm\u00b2 (the exact value can vary depending on the intended use).\n         Unit: W/cm\u00b2 Value: 6.447816724294121e-08\n\nI_pa_off_target:\n         The pulse-average intensity (IPA) within the brain but outside of the target. IPA is calculated by integrating the intensity over the pulse and dividing by the length of the pulse. For steady-state waves, IPA is equal to the temporal-average intensity. An example FDA recommended limit for IPA is 190 W/cm\u00b2 (the exact value can vary depending on the intended use).\n         Unit: W/cm\u00b2 Value: 6.258099451927385e-08\n\nmechanical_index_all:\n         The mechanical index (MI) over all materials in the full simulation volume. MI is defined as peak negative pressure divided by the square root of the frequency of the ultrasound wave. An example FDA recommended limit for MI is 1.9 (the exact value can vary depending on the intended use).\n         Unit: Pa \u221as\u0305 Value: 218.04790744813343\n\nmechanical_index_water:\n         The mechanical index (MI) within the water layer. The MI is defined as peak negative pressure divided by the square root of the frequency of the ultrasound wave. An example FDA recommended limit for MI is 1.9 (the exact value can vary depending on the intended use).\n         Unit: Pa \u221as\u0305 Value: 218.04790744813343\n\nmechanical_index_cortical_bone:\n         The mechanical index (MI) within the cortical_bone layer. The MI is defined as peak negative pressure divided by the square root of the frequency of the ultrasound wave. An example FDA recommended limit for MI is 1.9 (the exact value can vary depending on the intended use).\n         Unit: Pa \u221as\u0305 Value: 185.37573178584742\n\nmechanical_index_brain:\n         The mechanical index (MI) within the brain layer. The MI is defined as peak negative pressure divided by the square root of the frequency of the ultrasound wave. An example FDA recommended limit for MI is 1.9 (the exact value can vary depending on the intended use).\n         Unit: Pa \u221as\u0305 Value: 152.9486645347845\n\nmechanical_index_tumor:\n         The mechanical index (MI) within the tumor layer. The MI is defined as peak negative pressure divided by the square root of the frequency of the ultrasound wave. An example FDA recommended limit for MI is 1.9 (the exact value can vary depending on the intended use).\n         Unit: Pa \u221as\u0305 Value: 92.28863330528029\n</code></pre> <p>Total running time of the script: ( 0 minutes  12.154 seconds)</p> <p> Download Python source code: plot_metrics.py</p> <p> Download Jupyter notebook: plot_metrics.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/plot_multiple_sources/","title":"Adding multiple sources","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/gallery/plot_multiple_sources/#adding-multiple-sources","title":"Adding multiple sources","text":"<p>Note</p> <p>NDK and its examples are under constant development, more information and content will be added to this example soon!</p> <p>Adding multiple sources for transcranial ultrasound stimulation enables greater precision and control in targeting specific areas of the brain.</p> <p>By choosing the phase of ultrasound waves for each source, a combined beam can be created that is focused on the desired target precisely. This allows for complex wave patterns that open up new possibilities for therapies.</p> <p>Out:</p> <pre><code>Estimated time to complete simulation: 2 minutes. Memory required is 27.853101606717864 GB (available 73.624408064 GB). These values are approximated.\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\ngcc -O3 -g -fPIC -Wall -std=c99 -march=native -Wno-unused-result -Wno-unused-variable -Wno-unused-but-set-variable -ffast-math -shared -fopenmp /tmp/devito-jitcache-uid1001/284ade1f61cfd35c1dc7508ee5c551ecfab22af0.c -lm -o /tmp/devito-jitcache-uid1001/284ade1f61cfd35c1dc7508ee5c551ecfab22af0.so\n/home/circleci/project/src/neurotechdevkit/rendering/_animations.py:118: UserWarning: You passed in an explicit save_count=142 which is being ignored in favor of frames=142.\n  anim = FuncAnimation(\n</code></pre> Once Loop Reflect <p></p> <pre><code>import neurotechdevkit as ndk\nscenario = ndk.built_in.Scenario0()\ns1 = ndk.sources.FocusedSource2D(\nposition=[0.01, 0.0],\ndirection=[0.92, 0.25],\naperture=0.01,\nfocal_length=0.022,\nnum_points=1000,\n)\ns2 = ndk.sources.FocusedSource2D(\nposition=[0.04, -0.002],\ndirection=[-0.85, 0.35],\naperture=0.01,\nfocal_length=0.011,\nnum_points=1000,\ndelay=5.1e-6,\n)\nscenario.sources = [s1, s2]\nscenario.make_grid()\nscenario.compile_problem()\nresult = scenario.simulate_pulse()\nassert isinstance(result, ndk.results.PulsedResult2D)\nresult.render_pulsed_simulation_animation()\n</code></pre> <p>Total running time of the script: ( 1 minutes  19.810 seconds)</p> <p> Download Python source code: plot_multiple_sources.py</p> <p> Download Jupyter notebook: plot_multiple_sources.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/plot_phased_array_source/","title":"Phased array source","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/gallery/plot_phased_array_source/#phased-array-source","title":"Phased array source","text":"<p>Phased arrays consist of multiple individual transducer elements arranged in a specific pattern, such as a linear or circle. Each element can be controlled independently, allowing for precise manipulation of the generated ultrasound waves. By adjusting the timing or phase of the signals sent to these elements, the ultrasound waves can be focused, steered, and shaped without mechanically moving the transducer.</p> <p>They are becoming increasingly popular in the field of transcranial ultrasound stimulation as they offer several advantages over traditional ultrasound transducers -- among others are precise targeting and better control over steering and shaping:</p> <ul> <li> <p>Precise targeting: as individual transducer elements can be individually controlled, it allows for the generation of a focused ultrasound beam with high spatial accuracy. This enables the stimulation of specific brain regions without affecting the surrounding healthy tissue and minimizes the risk of potential side effects.</p> </li> <li> <p>Steering and shaping: The phased array technology allows the ultrasound beam to be electronically steered and shaped in real-time without mechanically moving the transducers. This enables targeting of different brain regions or adjusting the stimulation pattern as needed during a session, making the procedure more versatile and adaptable.</p> </li> </ul> <p>These features allow the stimulation to be tailored to suit to more specific requirements. With ongoing research and development, they have the potential to revolutionize the field of brain stimulation and offer new treatment options for a range of neurological and psychiatric disorders.</p> <p>This notebook will show how to define a phased array within NDK and experiment with some of the available features. For more details, checkout the NDK documentation.</p>"},{"location":"generated/gallery/plot_phased_array_source/#phased-arrays-components","title":"Phased Arrays Components","text":"<ul> <li>Elements: A phased array consists of multiple transducer elements that can be individually controlled in terms of phase.</li> <li>Pitch: The pitch of a phased array refers to the distance between adjacent transducer elements, and affects the resolution of the array.</li> <li>Spacing: The spacing between transducer elements affects the width and shape of the ultrasound beam that is produced.</li> <li>Aperture: The aperture of a phased array refers to the total size of the array, and affects the power and focus of the ultrasound beam.</li> <li>Element width: The element width of a phased array refers to the size of each individual transducer element. Wider elements generally result in a more powerful and focused beam, while narrower elements can increase the resolution of the array.</li> <li>Tilt angle: The tilt angle of a phased array refers to the angle at which the ultrasound beam is directed relative to the normal of plane of the array. Tilt angle can be adjusted by controlling the phase (delays) of the individual transducer elements.</li> </ul> <p>The image above shows a schematic representation of a phased array.</p> <p></p> <p>The image above shows the axis definition and the look of a phased array in the real world. Image source link.</p> <p>Below we will go through some examples of how to use the NDK to API to simulate Phased Arrays in the most common settings. Examples we will cover:</p> <ul> <li>Setting up a tilted wavefront</li> <li>Focusing phased arrays</li> <li>Setting up custom delays per element</li> <li>Phased arrays in 3D</li> </ul>"},{"location":"generated/gallery/plot_phased_array_source/#phased-array-ndk-api","title":"Phased Array NDK API","text":"<p>A PhasedArraySource receives the following parameters:</p> <ul> <li>position <code>(npt.NDArray[np.float_])</code>: a numpy float array indicating     the coordinates (in meters) of the point at the center of the     source, which is the point that bisects the line segment source.</li> <li>direction <code>(npt.NDArray[np.float_])</code>: a numpy float array representing     a vector located at position that is perpendicular to the plane     of the source. Only the orientation of <code>direction</code> affects the     source, the length of the vector has no affect. See the     <code>unit_direction</code> property.</li> <li>num_points <code>(int)</code>: the number of point sources to use when simulating     the source.</li> <li>num_elements <code>(int)</code>: the number of elements of the phased array.</li> <li>pitch <code>(float)</code>: the distance (in meters) between the centers of neighboring     elements in the phased array.</li> <li>element_width <code>(float)</code>: the width (in meters) of each individual element of     the array.</li> <li>tilt_angle <code>(float)</code>: the desired tilt angle (in degrees) of the wavefront.     The angle is measured between the direction the wavefront travels and the     normal to the surface of the transducer, with positive angles resulting in a     counter-clockwise tilt away from the normal.</li> <li>focal_length <code>(float)</code>: the distance (in meters) from <code>position</code> to the focal     point.</li> <li>delay <code>(float, optional)</code>: the delay (in seconds) that the source will wait     before emitting.</li> <li>element_delays: an 1D array with the delays (in seconds) for each element of the     phased array. Delays from <code>element_delays</code> take precedence; No other     argument affected the delays (<code>tilt_angle</code>, <code>focal_length</code> or <code>delay</code>)     would be considered. ValueError will be raised if provided values for either     <code>tilt_angle</code>, <code>focal_length</code> or <code>delay</code> are non-default.</li> </ul>"},{"location":"generated/gallery/plot_phased_array_source/#tilting-the-wavefront","title":"Tilting the Wavefront","text":"<p>Tilting the wavefront can be achieved simply by setting the <code>tilt_angle</code> argument different than zero. Positive angles result in counter-clockwise rotations.</p> <pre><code>import numpy as np\nimport neurotechdevkit as ndk\n# define the source\nsource = ndk.sources.PhasedArraySource2D(\nposition=[0.0, 0.0],\ndirection=[1.0, 0.0],\nnum_elements=20,\npitch=1.5e-3,\nelement_width=1.2e-3,\ntilt_angle=30,\nnum_points=1000,\n)\nscenario = ndk.scenarios.built_in.Scenario1_2D()\nscenario.sources = [source]\nscenario.make_grid()\nscenario.compile_problem()\nresult = scenario.simulate_steady_state()\nassert isinstance(result, ndk.results.SteadyStateResult2D)\nresult.render_steady_state_amplitudes()\n</code></pre> <p></p> <p>Out:</p> <pre><code>Estimated time to complete simulation: 46 seconds. Memory required is 8.11064033080535 GB (available 73.624408064 GB). These values are approximated.\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\ngcc -O3 -g -fPIC -Wall -std=c99 -march=native -Wno-unused-result -Wno-unused-variable -Wno-unused-but-set-variable -ffast-math -shared -fopenmp /tmp/devito-jitcache-uid1001/cca4a12a3521ab1de2785369917754e4dc60ea90.c -lm -o /tmp/devito-jitcache-uid1001/cca4a12a3521ab1de2785369917754e4dc60ea90.so\n</code></pre>"},{"location":"generated/gallery/plot_phased_array_source/#focusing","title":"Focusing","text":"<p>Similarly, a phased array can be focused by applying delays in a specific way. Such delays are automatically computed when <code>focal_length</code> is defined. Let's explore how the API looks like:</p> <pre><code>scenario = ndk.scenarios.built_in.Scenario1_2D()\nphased_array = ndk.sources.PhasedArraySource2D(\nposition=[0.0, 0.0],\ndirection=[1.0, 0.0],\nnum_elements=20,\npitch=1.5e-3,\nelement_width=1.2e-3,\nfocal_length=0.03,\nnum_points=1000,\n)\nscenario.sources = [phased_array]\nprint(f\"Focal point is: {phased_array.focal_point}\")\n</code></pre> <p>Out:</p> <pre><code>Focal point is: [0.03 0.  ]\n</code></pre> <p><code>focal_point</code> shows the coordinates (in meters) where the array focuses.</p> <pre><code>scenario.make_grid()\nscenario.compile_problem()\nresult = scenario.simulate_steady_state()\nassert isinstance(result, ndk.results.SteadyStateResult2D)\nresult.render_steady_state_amplitudes()\n</code></pre> <p></p> <p>Out:</p> <pre><code>Estimated time to complete simulation: 47 seconds. Memory required is 8.110192292329451 GB (available 73.624408064 GB). These values are approximated.\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\ngcc -O3 -g -fPIC -Wall -std=c99 -march=native -Wno-unused-result -Wno-unused-variable -Wno-unused-but-set-variable -ffast-math -shared -fopenmp /tmp/devito-jitcache-uid1001/fd8f46a495b0020134ca229700238e7d1d852637.c -lm -o /tmp/devito-jitcache-uid1001/fd8f46a495b0020134ca229700238e7d1d852637.so\n</code></pre> <p>We can see that the arrays focuses at a distance equal to <code>focal_length</code>.</p>"},{"location":"generated/gallery/plot_phased_array_source/#custom-wavefront-shapes","title":"Custom Wavefront Shapes","text":"<p>In the examples shown so far we specified high level arguments and the required delays were automatically computed. The NDK API offers also the possibility to specify delays directly to create arbitrary wavefront shapes.</p> <p>In the example below we apply monotonically increasing delays to mimic a counter-clockwise angle.</p> <pre><code>scenario = ndk.scenarios.built_in.Scenario1_2D()\nphased_array = ndk.sources.PhasedArraySource2D(\nposition=[0.0, 0.0],\ndirection=[1.0, 0.0],\nnum_elements=20,\npitch=1.5e-3,\nelement_width=1.2e-3,\nelement_delays=np.linspace(0, 1e-5, 20),\nnum_points=1000,\n)\nscenario.sources = [phased_array]\nscenario.make_grid()\nscenario.compile_problem()\nresult = scenario.simulate_steady_state()\nassert isinstance(result, ndk.results.SteadyStateResult2D)\nresult.render_steady_state_amplitudes()\n</code></pre> <p></p> <p>Out:</p> <pre><code>Estimated time to complete simulation: 46 seconds. Memory required is 8.110670878883253 GB (available 73.624408064 GB). These values are approximated.\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\ngcc -O3 -g -fPIC -Wall -std=c99 -march=native -Wno-unused-result -Wno-unused-variable -Wno-unused-but-set-variable -ffast-math -shared -fopenmp /tmp/devito-jitcache-uid1001/0055a1babbb73e4e30c2b5026d34deb4bcb07a18.c -lm -o /tmp/devito-jitcache-uid1001/0055a1babbb73e4e30c2b5026d34deb4bcb07a18.so\n</code></pre>"},{"location":"generated/gallery/plot_phased_array_source/#phased-arrays-in-three-dimensions","title":"Phased Arrays In Three Dimensions","text":"<p>There are two extra details to consider when creating 3D phased array sources: the <code>height</code> of the elements and the position of the <code>center_line</code>.</p> <ul> <li>Height: Is the distance (in meters) of the element measured in a straight line   perpendicular to the <code>element_width</code> (see image below)</li> <li>Center line: As the name indicates, is the line that crosses the centers of the   elements. Must be orthogonal to the direction line.</li> </ul> <p></p> <p>The rest of the API is identical for both 2D and 3D scenarios.</p> <pre><code>scenario_3d = ndk.scenarios.built_in.Scenario1_3D()\nphased_3d = ndk.sources.PhasedArraySource3D(\nposition=[0.0, 0.0, 0.0],\ndirection=[1.0, 0.0, 0.0],\ncenter_line=np.array([0.0, 0.0, 1.0]),\nnum_points=20_000,\nnum_elements=16,\npitch=1.5e-3,\nelement_width=1.2e-3,\ntilt_angle=30,\nheight=5.0e-3,\n)\nscenario_3d.sources = [phased_3d]\nscenario_3d.make_grid()\nscenario_3d.compile_problem()\nresults = scenario_3d.simulate_steady_state()\nassert isinstance(results, ndk.results.SteadyStateResult3D)\nresults.render_steady_state_amplitudes()\n</code></pre> <p></p> <p>Out:</p> <pre><code>Estimated time to complete simulation: 17 minutes. Memory required is 10.12265384241533 GB (available 73.624408064 GB). These values are approximated.\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\ngcc -O3 -g -fPIC -Wall -std=c99 -march=native -Wno-unused-result -Wno-unused-variable -Wno-unused-but-set-variable -ffast-math -shared -fopenmp /tmp/devito-jitcache-uid1001/36788220aacf20ede390405a475fe425008c3199.c -lm -o /tmp/devito-jitcache-uid1001/36788220aacf20ede390405a475fe425008c3199.so\n</code></pre> <p>Total running time of the script: ( 7 minutes  32.989 seconds)</p> <p> Download Python source code: plot_phased_array_source.py</p> <p> Download Jupyter notebook: plot_phased_array_source.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/plot_pulsed_simulation/","title":"Plot pulsed simulation","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/gallery/plot_pulsed_simulation/#plot-pulsed-simulation","title":"Plot pulsed simulation","text":"<p>This example demonstrates how to execute a pulsed simulation using ndk</p> <pre><code>import neurotechdevkit as ndk\nscenario = ndk.built_in.Scenario0()\nscenario.make_grid()\nscenario.compile_problem()\nresult = scenario.simulate_pulse()\nassert isinstance(result, ndk.results.PulsedResult2D)\nresult.render_pulsed_simulation_animation()\n</code></pre> <p>Out:</p> <pre><code>/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/types/basic.py:613: DeprecationWarning: invalid escape sequence '\\-'\n\"\"\"\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API\n  warnings.warn(\"pkg_resources is deprecated as an API\", DeprecationWarning)\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.\nImplementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n  declare_namespace(pkg)\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\nImplementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n  declare_namespace(pkg)\nWARNING: DEVITO_ARCH environment variable not set and might cause compilation errors. See NDK documentation for help.\nEstimated time to complete simulation: 2 minutes. Memory required is 28.92546936289519 GB (available 73.624408064 GB). These values are approximated.\nDefault Devito configuration:\n         * autotuning=off\n         * develop-mode=False\n         * mpi=False\n         * log-level=DEBUG\n         * language=openmp\n(ShotID 0) Preparing to run state for shot\n(ShotID 0) Estimated bandwidth for the propagated wavelet 0.257-0.724 MHz\n(ShotID 0) Spatial grid spacing (0.500 mm | 4.145 PPW) is higher than dispersion limit (0.415 mm | 5.000 PPW)\n(ShotID 0) Time grid spacing (0.083 \u03bcs | 46%) is above OT2 limit (0.080 \u03bcs) and below OT4 limit (0.145 \u03bcs)\n(ShotID 0) Selected undersampling level 4\n(ShotID 0) Selected time stepping scheme OT4\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\nOperator `acoustic_iso_state` instance configuration:\n         * subs={h_x: 0.0005, h_y: 0.0005}\n         * opt=advanced\n         * platform=None\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\nOperator `acoustic_iso_state` generated in 9.39 s\n  * lowering.Clusters: 4.14 s (44.2 %)\n     * specializing.Clusters: 2.63 s (28.1 %)\n  * lowering.Expressions: 2.88 s (30.7 %)\nFlops reduction after symbolic optimization: [3457 --&gt; 892]\nrecompiling for non-existent cache dir (/tmp/devito-codepy-uid1001/300b924/ae802b3a0a758d83087b6d6dfec378ed).\ngcc -O3 -g -fPIC -Wall -std=c99 -march=native -Wno-unused-result -Wno-unused-variable -Wno-unused-but-set-variable -ffast-math -shared -fopenmp /tmp/devito-jitcache-uid1001/300b924d7d2dce0732c3931f2d6f9c3293d56c3f.c -lm -o /tmp/devito-jitcache-uid1001/300b924d7d2dce0732c3931f2d6f9c3293d56c3f.so\nOperator `acoustic_iso_state` jit-compiled `/tmp/devito-jitcache-uid1001/300b924d7d2dce0732c3931f2d6f9c3293d56c3f.c` in 3.71 s with `GNUCompiler`\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/numpy/ctypeslib.py:137: DeprecationWarning: \n  `numpy.distutils` is deprecated since NumPy 1.23.0, as a result\n  of the deprecation of `distutils` itself. It will be removed for\n  Python &gt;= 3.12. For older Python versions it will remain present.\n  It is recommended to use `setuptools &lt; 60.0` for those Python versions.\n  For more details, see:\n    https://numpy.org/devdocs/reference/distutils_status_migration.html \n  from numpy.distutils.misc_util import get_shared_lib_extension\n/home/circleci/project/src/neurotechdevkit/rendering/_animations.py:118: UserWarning: You passed in an explicit save_count=127 which is being ignored in favor of frames=127.\n  anim = FuncAnimation(\n</code></pre> Once Loop Reflect"},{"location":"generated/gallery/plot_pulsed_simulation/#generating-a-video-file","title":"Generating a video file","text":"<p>You can also generate a video file of the simulation (which requires ffmpeg installed).</p> <p>To create and save the video as <code>animation.mp4</code> in the current folder, all you need is the execute following command:</p> <pre><code>result.create_video_file(\"animation.mp4\", fps=25, overwrite=True)\n</code></pre> <p>Out:</p> <pre><code>/home/circleci/project/src/neurotechdevkit/rendering/_animations.py:118: UserWarning: You passed in an explicit save_count=127 which is being ignored in favor of frames=127.\n  anim = FuncAnimation(\nSaved to animation.mp4 file.\n</code></pre> <p>Total running time of the script: ( 1 minutes  36.486 seconds)</p> <p> Download Python source code: plot_pulsed_simulation.py</p> <p> Download Jupyter notebook: plot_pulsed_simulation.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/plot_scenario2_predefined_target/","title":"Scenario 2 predefined target","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/gallery/plot_scenario2_predefined_target/#scenario-2-predefined-target","title":"Scenario 2 predefined target","text":"<p>Note</p> <p>NDK and its examples are under constant development, more information and content will be added to this example soon!</p> <p>This example demonstrates how to use one of the predefined targets of scenario 2.</p> <p>The list of supported targets is:</p> <pre><code>import neurotechdevkit as ndk\nscenario_2_2d_targets = (\nndk.scenarios.built_in.Scenario2_2D.PREDEFINED_TARGET_OPTIONS.keys()\n)\nscenario_2_3d_targets = (\nndk.scenarios.built_in.Scenario2_3D.PREDEFINED_TARGET_OPTIONS.keys()\n)\nprint(\"2D predefined targets: \\n\\t\", \", \".join(scenario_2_2d_targets), \"\\n\\n\")\nprint(\"3D predefined targets: \\n\\t\", \", \".join(scenario_2_3d_targets), \"\\n\\n\")\n</code></pre> <p>Out:</p> <pre><code>2D predefined targets: primary-visual-cortex, right-inferior-frontal-gyrus, posterior-cingulate-cortex 3D predefined targets: primary-visual-cortex, right-inferior-frontal-gyrus, posterior-cingulate-cortex, ventral-intermediate-nucleus, left-temporal-lobe </code></pre> <p>Using one of the predefined targets is as simple as:</p> <pre><code>scenario = ndk.built_in.Scenario2_2D()\ntarget_options = ndk.scenarios.built_in.Scenario2_2D.PREDEFINED_TARGET_OPTIONS\nscenario.target = target_options[\"posterior-cingulate-cortex\"]\nscenario.make_grid()\nscenario.render_layout()\n</code></pre> <p></p> <p>The same can be done for the 3D:</p> <pre><code>scenario_3d = ndk.built_in.Scenario2_3D()\ntarget_options = ndk.scenarios.built_in.Scenario2_3D.PREDEFINED_TARGET_OPTIONS\nscenario_3d.target = target_options[\"left-temporal-lobe\"]\nscenario_3d.make_grid()\nscenario_3d.render_layout()\n</code></pre> <p></p> <p>Total running time of the script: ( 0 minutes  11.910 seconds)</p> <p> Download Python source code: plot_scenario2_predefined_target.py</p> <p> Download Jupyter notebook: plot_scenario2_predefined_target.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/plot_scenarios/","title":"Plot scenarios","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/gallery/plot_scenarios/#plot-scenarios","title":"Plot scenarios","text":"<p>This example demonstrates how to execute a steady state simulation using ndk</p> <pre><code>import neurotechdevkit as ndk\ndef plot_scenario(chosen_scenario):\nprint(f\"Simulating scenario: {chosen_scenario.__name__}\")\nscenario = chosen_scenario()\nscenario.make_grid()\nscenario.compile_problem()\nresult = scenario.simulate_steady_state()\nresult.render_steady_state_amplitudes(show_material_outlines=False)\n</code></pre>"},{"location":"generated/gallery/plot_scenarios/#simulating-scenario-scenario-0","title":"Simulating scenario: scenario 0","text":"<pre><code>plot_scenario(ndk.scenarios.built_in.Scenario0)\n</code></pre> <p>Out:</p> <pre><code>Simulating scenario: Scenario0\nEstimated time to complete simulation: 44 seconds. Memory required is 8.09906664298232 GB (available 73.624408064 GB). These values are approximated.\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\n</code></pre>"},{"location":"generated/gallery/plot_scenarios/#simulating-scenario-scenario-1-2d","title":"Simulating scenario: scenario 1 2D","text":"<pre><code>plot_scenario(ndk.scenarios.built_in.Scenario1_2D)\n</code></pre> <p>Out:</p> <pre><code>Simulating scenario: Scenario1_2D\nEstimated time to complete simulation: 47 seconds. Memory required is 8.110059917325207 GB (available 73.624408064 GB). These values are approximated.\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\ngcc -O3 -g -fPIC -Wall -std=c99 -march=native -Wno-unused-result -Wno-unused-variable -Wno-unused-but-set-variable -ffast-math -shared -fopenmp /tmp/devito-jitcache-uid1001/8aed0abf685aca05537adb2a263f72cdb8d7f4cf.c -lm -o /tmp/devito-jitcache-uid1001/8aed0abf685aca05537adb2a263f72cdb8d7f4cf.so\n</code></pre>"},{"location":"generated/gallery/plot_scenarios/#simulating-scenario-scenario-2-2d","title":"Simulating scenario: scenario 2 2D","text":"<pre><code>plot_scenario(ndk.scenarios.built_in.Scenario2_2D)\n</code></pre> <p>Out:</p> <pre><code>Simulating scenario: Scenario2_2D\nEstimated time to complete simulation: 1 minutes. Memory required is 8.207058332240669 GB (available 73.624408064 GB). These values are approximated.\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\ngcc -O3 -g -fPIC -Wall -std=c99 -march=native -Wno-unused-result -Wno-unused-variable -Wno-unused-but-set-variable -ffast-math -shared -fopenmp /tmp/devito-jitcache-uid1001/0ec68a19d4dc4792357f350ee80ee7e46d45a036.c -lm -o /tmp/devito-jitcache-uid1001/0ec68a19d4dc4792357f350ee80ee7e46d45a036.so\n</code></pre> <p>Total running time of the script: ( 0 minutes  52.375 seconds)</p> <p> Download Python source code: plot_scenarios.py</p> <p> Download Jupyter notebook: plot_scenarios.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/plot_store_results/","title":"Save and load results","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/gallery/plot_store_results/#save-and-load-results","title":"Save and load results","text":"<p>Note</p> <p>NDK and its examples are under constant development, more information and content will be added to this example soon!</p> <p>This example demonstrates how a simulation can be executed and stored in one computer and the results can be loaded and rendered later in the same computer or another one.</p> <p>Execute the following code in a computer with ndk installed</p> <pre><code>import neurotechdevkit as ndk\nscenario = ndk.built_in.Scenario0()\nscenario.make_grid()\nscenario.compile_problem()\nresult = scenario.simulate_steady_state()\nresult.save_to_disk(\"scenario-0-results.tar.gz\")\n</code></pre> <p>Out:</p> <pre><code>Estimated time to complete simulation: 44 seconds. Memory required is 8.09906664298232 GB (available 73.624408064 GB). These values are approximated.\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\nA result artifact has been saved to scenario-0-results.tar.gz.\n</code></pre> <p>The output file from the previous step could be copied to another computer with ndk installed or stored for future use. The results can be loaded running the following code:</p> <pre><code>import neurotechdevkit as ndk  # noqa: E402\nresult2 = ndk.load_result_from_disk(\"scenario-0-results.tar.gz\")\nassert isinstance(result2, ndk.results.SteadyStateResult2D)\nresult2.render_steady_state_amplitudes(show_material_outlines=False)\n</code></pre> <p></p> <p>Out:</p> <pre><code>Recreating the scenario for the result from saved metadata...\n</code></pre> <p>Total running time of the script: ( 0 minutes  12.540 seconds)</p> <p> Download Python source code: plot_store_results.py</p> <p> Download Jupyter notebook: plot_store_results.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/plot_time_reverse/","title":"Time-reverse simulation for phased array","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/gallery/plot_time_reverse/#time-reverse-simulation-for-phased-array","title":"Time-reverse simulation for phased array","text":"<p>The skull adds aberrations to the beam propagation; phased arrays can compensate for those by having different delays for each element, but estimating these delays can be challenging. One method to estimate the delays is a \"time reverse\" simulation as described in this Article. This notebook demonstrates the \"time reverse\" method to estimate the delays. The notebook sets up a scenario with a phased array source and a target and then runs a simulation with the source and target reversed to calculate the delays. Finally, it uses the calculated delays to perform a forward-time simulation.</p> <p>Note</p> <p>In this notebook, we refer to the \"true\" target as the eventual brain region we would like to stimulate, and the \"true\" source as the placement of the ultrasound probes. We refer to the \"reversed\" or \"simulated\" target and point-source as the values defined in our simulation, which are reversed from the physical setup to help calculate values.</p> <pre><code>import matplotlib.pyplot as plt\nimport numpy as np\nimport neurotechdevkit as ndk\n# Parameters\nNUM_ELEMENTS = 20\nELEMENT_WIDTH = 1.2e-3\n</code></pre> <p>Helper function to make the scenario with a PhasedArraySource</p> <pre><code>def make_scenario(element_delays=None):\ntrue_scenario = ndk.scenarios.built_in.Scenario2_2D()\n# define a phased-array source\ndefault_source = true_scenario.sources[0]\ntrue_source = ndk.sources.PhasedArraySource2D(\nelement_delays=element_delays,\nposition=default_source.position,\ndirection=default_source.unit_direction,\nnum_elements=NUM_ELEMENTS,\npitch=default_source.aperture / NUM_ELEMENTS,\nelement_width=ELEMENT_WIDTH,\nnum_points=1000,\n)\ntrue_scenario.sources = [true_source]\nreturn true_scenario\n</code></pre>"},{"location":"generated/gallery/plot_time_reverse/#set-up-and-visualize-the-forward-scenario","title":"Set up and visualize the forward scenario","text":"<pre><code>true_scenario = make_scenario()\ntrue_scenario.make_grid()\ntrue_scenario.compile_problem()\ntrue_scenario.render_layout()\n</code></pre>"},{"location":"generated/gallery/plot_time_reverse/#simulate-the-time-reverse-scenario","title":"Simulate the time-reverse scenario","text":"<p>Place a point source at the true target, and simulate a pulse. The point source is visualized as a gray dot.</p> <pre><code># Reinitialize the scenario\nreversed_scenario = ndk.scenarios.built_in.Scenario2_2D()\n# and reverse the source\npoint_source = ndk.sources.PointSource2D(\nposition=true_scenario.target.center,\n)\nreversed_scenario.sources.append(point_source)\nreversed_scenario.make_grid()\nreversed_scenario.compile_problem()\nreversed_scenario.render_layout()\n</code></pre> <p></p> <pre><code>result = reversed_scenario.simulate_pulse()\nassert isinstance(result, ndk.results.PulsedResult2D)\nresult.render_pulsed_simulation_animation()\n</code></pre> <p>Out:</p> <pre><code>Estimated time to complete simulation: 2 minutes. Memory required is 9.898794145189598 GB (available 73.624408064 GB). These values are approximated.\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\ngcc -O3 -g -fPIC -Wall -std=c99 -march=native -Wno-unused-result -Wno-unused-variable -Wno-unused-but-set-variable -ffast-math -shared -fopenmp /tmp/devito-jitcache-uid1001/bc8fb1f60cd9db4d35f8beda3d6ca87c83ea57bd.c -lm -o /tmp/devito-jitcache-uid1001/bc8fb1f60cd9db4d35f8beda3d6ca87c83ea57bd.so\n/home/circleci/project/src/neurotechdevkit/rendering/_animations.py:118: UserWarning: You passed in an explicit save_count=563 which is being ignored in favor of frames=563.\n  anim = FuncAnimation(\n</code></pre> Once Loop Reflect <p>We calculate how long it took for the point-source pulse to reach each of the true array elements. Here, we coarsely approximate these delays by finding the pressure argmax at each element's nearest-neighbor coordinates.</p> <pre><code># Map array elements onto the nearest pixels in our simulation\ndef map_coordinates_to_indices(coordinates, origin, dx):\nindices = np.round((coordinates - origin) / dx).astype(int)\nreturn indices\n# Get the pressure time-series of these elements\n[true_source] = true_scenario.sources\nassert isinstance(true_source, ndk.sources.PhasedArraySource2D)\nelement_indices = map_coordinates_to_indices(\ntrue_source.element_positions,\nreversed_scenario.origin,\nreversed_scenario.dx,\n)\npressure_at_elements = result.wavefield[element_indices[:, 0], element_indices[:, 1]]\n# Calculate the time of arrival for each element\nelement_reverse_delays = np.argmax(pressure_at_elements, axis=1) * result.effective_dt\nplt.plot(element_reverse_delays, marker=\"o\")\nplt.xlabel(\"element index\")\nplt.ylabel(\"delay [s]\")\n</code></pre> <p></p> <p>Out:</p> <pre><code>Text(55.847222222222214, 0.5, 'delay [s]')\n</code></pre> <p>Visually inspecting the earlier scenario layout, these results seem reasonable. The expected delay \\(t_d\\) is approximately:</p> \\[ t_d \\approx \\frac{||x_{source} - x_{target}||_2}{c_{water}} \\approx \\frac{0.07 \\text{ m}}{1500 \\text{ m/s}} \\approx 47 \\mu s \\]"},{"location":"generated/gallery/plot_time_reverse/#use-delays-in-forward-time-simulation","title":"Use delays in forward-time simulation","text":"<p>Next, let's validate these delays by using them in a normal forward-time simulation. We simulate the original scenario, setting the pulse delays as calculated.</p> <pre><code># Elements that took longer to reach should now be pulsed first,\n# so we invert the values\nelement_delays = element_reverse_delays.max() - element_reverse_delays\ntrue_scenario = make_scenario(element_delays=element_delays)\ntrue_scenario.make_grid()\ntrue_scenario.compile_problem()\nresult = true_scenario.simulate_pulse()\nassert isinstance(result, ndk.results.PulsedResult2D)\nresult.render_pulsed_simulation_animation()\n</code></pre> <p>Out:</p> <pre><code>Estimated time to complete simulation: 2 minutes. Memory required is 9.561373097982807 GB (available 73.624408064 GB). These values are approximated.\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\ngcc -O3 -g -fPIC -Wall -std=c99 -march=native -Wno-unused-result -Wno-unused-variable -Wno-unused-but-set-variable -ffast-math -shared -fopenmp /tmp/devito-jitcache-uid1001/5da7bfaf89427ded9a069992e233ac51d18d0505.c -lm -o /tmp/devito-jitcache-uid1001/5da7bfaf89427ded9a069992e233ac51d18d0505.so\n/home/circleci/project/src/neurotechdevkit/rendering/_animations.py:118: UserWarning: You passed in an explicit save_count=577 which is being ignored in favor of frames=577.\n  anim = FuncAnimation(\n</code></pre> Once Loop Reflect <p>The pulse should focus on the true target.</p>"},{"location":"generated/gallery/plot_time_reverse/#simulate-steady-state","title":"Simulate steady-state","text":"<p>Another way to visualize the simulation is to check that the steady-state pressure (within the skull) peaks near the target.</p> <pre><code># Re-initialize scenario to clear previous simulation\ntrue_scenario = make_scenario(element_delays=element_delays)\ntrue_scenario.make_grid()\ntrue_scenario.compile_problem()\nsteady_state_result = true_scenario.simulate_steady_state()\nassert isinstance(steady_state_result, ndk.results.SteadyStateResult2D)\nsteady_state_result.render_steady_state_amplitudes()\n</code></pre> <p></p> <p>Out:</p> <pre><code>Estimated time to complete simulation: 1 minutes. Memory required is 8.20834870572941 GB (available 73.624408064 GB). These values are approximated.\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\n/home/circleci/.cache/pypoetry/virtualenvs/neurotechdevkit-3aSsmiER-py3.10/lib/python3.10/site-packages/devito/finite_differences/differentiable.py:224: DeprecationWarning: NotImplemented should not be used in a boolean context\n  return super(Differentiable, self).__eq__(other) and\\\ngcc -O3 -g -fPIC -Wall -std=c99 -march=native -Wno-unused-result -Wno-unused-variable -Wno-unused-but-set-variable -ffast-math -shared -fopenmp /tmp/devito-jitcache-uid1001/5bf8ef02e4f02f25216f0bdfd93b1ebadae218e0.c -lm -o /tmp/devito-jitcache-uid1001/5bf8ef02e4f02f25216f0bdfd93b1ebadae218e0.so\n</code></pre> <p>We want to visualize and find the maximum pressure within the brain, so let's mask out everything else.</p> <pre><code>steady_state_pressure = steady_state_result.get_steady_state()\n# Only consider the brain region\nsteady_state_pressure[~true_scenario.material_masks[\"brain\"]] = np.nan\nsteady_state_result.steady_state = steady_state_pressure\nsteady_state_result.render_steady_state_amplitudes()\n</code></pre> <p></p> <p>We can also calculate how far the \"time reverse\" estimate is from the true target.</p> <pre><code>max_pressure_flat_idx = np.nanargmax(steady_state_pressure)\nmax_pressure_idx = np.unravel_index(max_pressure_flat_idx, steady_state_pressure.shape)\nmax_pressure_idx\ngrid = steady_state_result.traces.grid.space.grid\nfocal_point = np.array(\n[\ngrid[0][max_pressure_idx[0]],\ngrid[1][max_pressure_idx[1]],\n]\n)\n# The backend grid is in different coordinates from the scenario grid, so we\n# need to shift it.\nfocal_point += true_scenario.origin\nprint(\"target center:\", true_scenario.target.center)\nprint(\"beam focal point:\", focal_point)\nerror_distance = np.linalg.norm(true_scenario.target.center - focal_point)\nprint(\"error [m]:\", error_distance)\nprint(\"error [mm]:\", error_distance * 1000)\n</code></pre> <p>Out:</p> <pre><code>target center: [0.047, 0.002]\nbeam focal point: [ 0.0575 -0.0035]\nerror [m]: 0.011853269917042083\nerror [mm]: 11.853269917042082\n</code></pre>"},{"location":"generated/gallery/plot_time_reverse/#reasons-for-target-mismatch","title":"Reasons for target mismatch","text":"<p>The time-reverse simulation is not an exact solution for the forward-time design. Other factors, like the angle of incidence at the boundary of two materials, will be different in the time reverse vs forward-time.</p>"},{"location":"generated/gallery/plot_time_reverse/#exercise","title":"Exercise","text":"<p>Do you think the time-reverse simulation will work better or worse for deeper targets? How about if the transducer was positioned next to a different part of the skull that is flatter?</p>"},{"location":"generated/gallery/plot_time_reverse/#acknowledgments","title":"Acknowledgments","text":"<p>Thanks to Sergio Jim\u00e9nez-Gamb\u00edn and Samuel Blackman for pointing us to the \"time reverse\" simulation method.</p> <p>Total running time of the script: ( 7 minutes  40.503 seconds)</p> <p> Download Python source code: plot_time_reverse.py</p> <p> Download Jupyter notebook: plot_time_reverse.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"usage/defining_sources/","title":"Sources","text":"<p>NDK provides a simple but flexible API to control the parameters of sources. Users can specify the parameters and placement of sources, and add them to their simulation.</p> <pre><code>import neurotechdevkit as ndk\nimport numpy as np\nscenario = ndk.scenarios.built_in.Scenario2_2D()\nsource = ndk.sources.FocusedSource2D(\nposition=np.array([0.19, 0.07]),\ndirection=np.array([-0.5, -1.]),\naperture=0.06,\nfocal_length=0.08,\nnum_points=3000\n)\nscenario.sources = [source]\nscenario.make_grid()\nscenario.render_layout()\n</code></pre> <p></p> <p>In the visualization of the source, the <code>position</code> parameter of the source corresponds to the point located at the midpoint of the dark arc on the front (concave) edge. The <code>position</code> and <code>direction</code> of the source are accurately shown in the plot, while the <code>aperture</code> and <code>focal_length</code> (radius of curvature) of the rendered source approximately visualize what is defined in the source object. The blue dotted lines indicate the ultrasound waves.</p> <p>Transducer locations are currently not constrained within the scenario or by materials, and so care needs to be taken when configuring a source so that it is not embedded inside the skull, for instance, or located outside of the simulation volume.</p> <p>In the future, we plan to implement constraints to avoid overlapping with solid materials or other sources, and to also add helper utilities to assist with placing sources along the surface of the skull using fewer degrees of freedom.</p> <p>If a source is not specified before the scenario is rendered or simulated, then a default source will be used. So you should add the source to the scenario before doing either of these operations (rendering or simulating).</p> <p>Note</p> <p>The visualization of the source in 2D plots currently has some scaling limitations, and transducers with short focal lengths can appear very small. This only affects the visualization and not the simulation, and will be improved in future versions.</p> <p>The implemented source options are:</p> <ul> <li><code>FocusedSource2D</code></li> <li><code>FocusedSource3D</code></li> <li><code>PlanarSource2D</code></li> <li><code>PlanarSource3D</code></li> <li><code>PhasedArraySource2D</code></li> <li><code>PhasedArraySource3D</code></li> </ul> <p>The 2D sources are for 2D scenarios and the 3D sources for 3D scenarios. The parameters to configure the sources are identical between focused and planar sources, except that planar sources have a pre-defined focal length of <code>np.inf</code>.</p> <pre><code>import neurotechdevkit as ndk\nimport numpy as np\nscenario = ndk.scenarios.built_in.Scenario2_2D()\nsource_position = np.array([0.19, 0.07])\nsource = ndk.sources.PlanarSource2D(\nposition=source_position,\ndirection=scenario.target_center - source_position,\naperture=0.06,\nnum_points=3000\n)\nscenario.sources = [source]\nscenario.make_grid()\nscenario.render_layout()\n</code></pre> <p></p>"},{"location":"usage/gpu/","title":"GPU support","text":"<p>In order to use your GPU to run NDK simulations you will have to install the NVIDIA HPC SDK.</p> <p>Warning</p> <p>Make sure the HPC SDK environment variables are exported.</p> <p>You will only have to export one environment variable to enable the GPU support for NDK:</p> <pre><code>export PLATFORM=\"nvidia-acc\"\n</code></pre> <p>Now when running NDK simulations you should be able to see <code>platform=nvidiaX</code> in the execution output:</p> <pre><code>import neurotechdevkit as ndk\nscenario = ndk.scenarios.built_in.Scenario2_2D()\nscenario.make_grid()\nscenario.compile_problem()\nresult = scenario.simulate_steady_state()\nresult.render_steady_state_amplitudes()\n</code></pre> <p>Output: <pre><code>...\n\nOperator `acoustic_iso_state` instance configuration:\n     * subs={h_x: 0.0005, h_y: 0.0005}\n* opt=advanced\n     * compiler=pgcc\n     * language=openacc\n     * platform=nvidiaX\n\n...\n</code></pre></p> <p>Warning</p> <p>Simulations with high memory requirement (e.g. 3D simulations) may not fit in the GPU and running them with GPU acceleration might crash the simulation.</p>"},{"location":"usage/loading_scenarios/","title":"Scenarios","text":"<p>Scenarios provide a convenient structure to describe the environment, transducers, and sensors. A collection of preconfigured scenarios are provided with NDK, and can be easily loaded.</p> <p>There are currently three scenarios provided with NDK, two of which have both a 2D and 3D version. 2D versions are quick to simulate and are great for testing out ideas quickly before transferring to a 3D simulation.</p> <p>The following is all that's needed to load a pre-defined scenario:</p> <pre><code>import neurotechdevkit as ndk\nscenario = ndk.scenarios.built_in.Scenario2_2D()\nscenario.make_grid()\n</code></pre> <p>The existing scenarios are:</p> <ul> <li><code>SCENARIO_0</code> (2D) - a simple quickstart toy scenario that enables users to dive in and experiment with their first simulation immediately.</li> <li><code>SCENARIO_1_3D</code> (3D) - a scenario containing a flat 3-layer bone covered by skin, with water above the skin and brain below the bone. This is based on benchmark 4 of Jean-Francois Aubry, et al..</li> <li><code>SCENARIO_2_3D</code> (3D) - a scenario containing a full skull and brain mesh immersed in water. This is based on benchmark 8 of Jean-Francois Aubry, et al..</li> <li><code>SCENARIO_1_2D</code> (2D) - a 2D version of scenario 1.</li> <li><code>SCENARIO_2_2D</code> (2D) - a 2D version of scenario 2.</li> </ul> <p>All of these scenarios are immediately ready for visualization and simulation, with appropriate default parameters used where needed.</p> <pre><code>scenario.render_layout()\n</code></pre> <p></p>"},{"location":"usage/running_simulation/","title":"Simulation","text":"<p>The Neurotech Development Kit provides support for a range of simulation modes, including pulsed simulation and steady-state simulation.</p> <p>The following code shows how to run a simulation.</p> <pre><code>import neurotechdevkit as ndk\nscenario = ndk.scenarios.built_in.Scenario2_2D()\nscenario.make_grid()\nscenario.compile_problem()\nresult = scenario.simulate_steady_state()\nresult.render_steady_state_amplitudes()\n</code></pre> <p></p>"},{"location":"usage/troubleshooting/","title":"Troubleshooting","text":"<p>This page contains a list of known problems you might face when installing and running NDK and the actions to solve them.</p>"},{"location":"usage/troubleshooting/#error-command-x86_64-linux-gnu-gcc-failed-no-such-file-or-directory-on-linux","title":"<code>error: command 'x86_64-linux-gnu-gcc' failed: No such file or directory</code> on Linux","text":"<p>This error occurs when <code>g++</code> is not installed. You can install it with:</p> <pre><code>apt-get install g++\n</code></pre> <p>and run the installation again.</p>"},{"location":"usage/troubleshooting/#pyrevolveschedulerscrevolvecpp2510-fatal-error-pythonh-no-such-file-or-directory-on-linux","title":"<code>pyrevolve/schedulers/crevolve.cpp:25:10: fatal error: Python.h: No such file or directory</code> on Linux","text":"<p>This error occurs when the <code>python-dev</code> package was not installed. You can install it with: <pre><code>apt-get install python3.10-dev\n</code></pre> replace <code>3.10</code> with your installed python version.</p> <p>And run the installation again.</p>"},{"location":"usage/troubleshooting/#error-legacy-install-failure-on-macos","title":"<code>error: legacy-install-failure</code> on MacOS","text":"<p>This error might occur when <code>brew</code> or <code>pip</code> are outdated.</p> <p>Update brew: <pre><code>brew update\n</code></pre></p> <p>Update pip: <pre><code>pip install --upgrade pip\n</code></pre></p> <p>And run the installation again.</p>"},{"location":"usage/troubleshooting/#error-process-completed-with-exit-code-1-when-installing-stride-on-windows","title":"<code>Error: Process completed with exit code 1.</code> when installing Stride on Windows","text":"<p>Unfortunately Stride can't be installed on a Windows platform, therefore NDK is also unsupported.</p>"},{"location":"usage/troubleshooting/#error-cannot-install-under-rosetta-2-in-arm-default-prefix-opthomebrew-on-macos","title":"<code>Error: Cannot install under Rosetta 2 in ARM default prefix (/opt/homebrew)!</code> on MacOS","text":"<p>This error occurs when you are not running the native homebrew for an ARM platform. To proceed with the installation you can:</p> <ul> <li>Migrate to native homebrew</li> </ul> <p>or</p> <ul> <li>Prepend the brew install commands with <code>arch -arm64</code>: <pre><code>arch -arm64 brew install ...\n</code></pre></li> </ul>"},{"location":"usage/troubleshooting/#getting-error-codepycompileerror-module-compilation-failed","title":"Getting error <code>codepy.CompileError: module compilation failed</code>","text":"<p>This error occurs when the compiler wasn't able to perform the compilation, it can be caused by a environment configuration problem. Check the <code>DEVITO_ARCH</code> environment variable, it should be set with the compiler devito will use to compile the code.</p> <p>You can find further information in the Devito documentation.</p>"},{"location":"usage/troubleshooting/#getting-error-codepycompileerror-module-compilation-failed-with-fatal-error-omph-file-not-found","title":"Getting error <code>codepy.CompileError: module compilation failed</code> with <code>fatal error: 'omp.h' file not found</code>","text":"<p>This error occurs when the <code>libomp</code> is not installed or can not be found by the compiler.</p> <p>Make sure to install it and export the environment variable <code>CPATH</code> with the path to the folder containing libomp headers.</p>"},{"location":"usage/troubleshooting/#getting-error-modulenotfounderror-no-module-named-neurotechdevkit","title":"Getting error <code>ModuleNotFoundError: No module named 'neurotechdevkit'</code>","text":"<p>This error is shown when <code>neurotechdevkit</code> is not installed, if you installed it using a virtual environment like poetry you must run the script with <code>poetry run</code> or activate the environment.</p>"},{"location":"usage/troubleshooting/#getting-error-attributeerror-module-napari-has-no-attribute-viewer-when-calling-render_layout_3d","title":"Getting error <code>AttributeError: module 'napari' has no attribute 'Viewer'</code> when calling <code>render_layout_3d</code>","text":"<p>This error is shown when napari is not installed, make sure to run</p> <p><code>pip install \"napari[all]\"</code></p> <p>(or <code>pip install \"napari[pyqt6_experimental]\"</code> if running on a Mac M1)</p> <p>and try again.</p>"}]}